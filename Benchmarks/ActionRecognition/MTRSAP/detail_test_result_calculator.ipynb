{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from difflib import SequenceMatcher\n",
    "from scripts.config import DefaultArgsNamespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import editdistance\n",
    "\n",
    "args = DefaultArgsNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task is segmentation\n"
     ]
    }
   ],
   "source": [
    "results_csv = './results/model_id_65302224_on_20241025-112558/preds.csv'\n",
    "\n",
    "task = args.dataloader_params['task']\n",
    "print(\"Task is\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get keysteps dict\n",
    "keysteps_dict = args.dataloader_params['keysteps']\n",
    "# Inverting the dictionary to map keystep_id to natural language description\n",
    "keystep_id_to_desc = {i: v for i, v in enumerate(keysteps_dict.values())}\n",
    "\n",
    "keysteps_dict = keystep_id_to_desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keystep_label</th>\n",
       "      <th>keystep_id</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>start_t</th>\n",
       "      <th>end_t</th>\n",
       "      <th>window_start_frame</th>\n",
       "      <th>window_end_frame</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>pred_keystep_id</th>\n",
       "      <th>all_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[approach_patient, approach_patient, approach_...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[198, 198, 198, 198, 198, 198, 198, 198, 198, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6.608630180358887, 6.608630180358887, 6.60863...</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>ms1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.73012638092041, 0.445463091135025, 0.365629...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[approach_patient, approach_patient, approach_...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[198, 198, 198, 198, 198, 198, 198, 198, 198, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[6.608630180358887, 6.608630180358887, 6.60863...</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>ms1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.831171035766602, 3.5325310230255127, 2.8858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[check_responsiveness, check_responsiveness, c...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[198, 198, 198, 198, 198, 198, 198, 198, 198, ...</td>\n",
       "      <td>[342, 342, 342, 342, 342, 342, 342, 342, 342, ...</td>\n",
       "      <td>[6.609000205993652, 6.609000205993652, 6.60900...</td>\n",
       "      <td>[11.418919563293457, 11.418919563293457, 11.41...</td>\n",
       "      <td>240</td>\n",
       "      <td>360</td>\n",
       "      <td>ms1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[1.7756500244140625, 3.1439244747161865, 3.367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[check_pulse, check_pulse, check_pulse, check_...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[342, 342, 342, 342, 342, 342, 342, 342, 342, ...</td>\n",
       "      <td>[401, 401, 401, 401, 401, 401, 401, 401, 401, ...</td>\n",
       "      <td>[11.418999671936035, 11.418999671936035, 11.41...</td>\n",
       "      <td>[13.395000457763672, 13.395000457763672, 13.39...</td>\n",
       "      <td>360</td>\n",
       "      <td>480</td>\n",
       "      <td>ms1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.43847012519836426, 3.0513341426849365, 4.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[chest_compressions, chest_compressions, chest...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[472, 472, 472, 472, 472, 472, 472, 472, 472, ...</td>\n",
       "      <td>[584, 584, 584, 584, 584, 584, 584, 584, 584, ...</td>\n",
       "      <td>[15.77299976348877, 15.77299976348877, 15.7729...</td>\n",
       "      <td>[19.509029388427734, 19.509029388427734, 19.50...</td>\n",
       "      <td>480</td>\n",
       "      <td>600</td>\n",
       "      <td>ms1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.7568711042404175, -0.2066485583782196, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       keystep_label  \\\n",
       "0  [approach_patient, approach_patient, approach_...   \n",
       "1  [approach_patient, approach_patient, approach_...   \n",
       "2  [check_responsiveness, check_responsiveness, c...   \n",
       "3  [check_pulse, check_pulse, check_pulse, check_...   \n",
       "4  [chest_compressions, chest_compressions, chest...   \n",
       "\n",
       "                                          keystep_id  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
       "\n",
       "                                         start_frame  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
       "3  [342, 342, 342, 342, 342, 342, 342, 342, 342, ...   \n",
       "4  [472, 472, 472, 472, 472, 472, 472, 472, 472, ...   \n",
       "\n",
       "                                           end_frame  \\\n",
       "0  [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
       "1  [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
       "2  [342, 342, 342, 342, 342, 342, 342, 342, 342, ...   \n",
       "3  [401, 401, 401, 401, 401, 401, 401, 401, 401, ...   \n",
       "4  [584, 584, 584, 584, 584, 584, 584, 584, 584, ...   \n",
       "\n",
       "                                             start_t  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [6.609000205993652, 6.609000205993652, 6.60900...   \n",
       "3  [11.418999671936035, 11.418999671936035, 11.41...   \n",
       "4  [15.77299976348877, 15.77299976348877, 15.7729...   \n",
       "\n",
       "                                               end_t  window_start_frame  \\\n",
       "0  [6.608630180358887, 6.608630180358887, 6.60863...                   0   \n",
       "1  [6.608630180358887, 6.608630180358887, 6.60863...                 120   \n",
       "2  [11.418919563293457, 11.418919563293457, 11.41...                 240   \n",
       "3  [13.395000457763672, 13.395000457763672, 13.39...                 360   \n",
       "4  [19.509029388427734, 19.509029388427734, 19.50...                 480   \n",
       "\n",
       "   window_end_frame subject_id trial_id  pred_keystep_id  \\\n",
       "0               120        ms1        0                0   \n",
       "1               240        ms1        0                0   \n",
       "2               360        ms1        0               15   \n",
       "3               480        ms1        0                2   \n",
       "4               600        ms1        0                4   \n",
       "\n",
       "                                           all_preds  \n",
       "0  [5.73012638092041, 0.445463091135025, 0.365629...  \n",
       "1  [5.831171035766602, 3.5325310230255127, 2.8858...  \n",
       "2  [1.7756500244140625, 3.1439244747161865, 3.367...  \n",
       "3  [-0.43847012519836426, 3.0513341426849365, 4.0...  \n",
       "4  [0.7568711042404175, -0.2066485583782196, -0.3...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "unique_actions = np.union1d(np.concatenate(df['keystep_id'].apply(eval).values), df['pred_keystep_id'].values)\n",
    "\n",
    "# Lists to hold ground truth and predicted sequences for all trials\n",
    "all_ground_truth = []\n",
    "all_predicted = []\n",
    "\n",
    "# Convert the lists in subject_id and trial_id columns to single values\n",
    "df['subject_id'] = df['subject_id'].apply(lambda x: eval(x)[0] if isinstance(x, str) else x)\n",
    "df['trial_id'] = df['trial_id'].apply(lambda x: eval(x)[0] if isinstance(x, str) else x)\n",
    "\n",
    "# Show the updated dataframe\n",
    "df.head()\n",
    "\n",
    "# Convert string arrays to actual lists for all relevant columns\n",
    "def convert_to_list(value):\n",
    "    try:\n",
    "        return eval(value) if isinstance(value, str) else value\n",
    "    except:\n",
    "        return value  # If eval fails, return the original value\n",
    "\n",
    "# Apply the conversion to the columns that contain arrays as strings\n",
    "columns_to_convert = ['keystep_label', 'keystep_id', 'start_frame', 'end_frame', 'start_t', 'end_t', 'all_preds']  # Add any other columns if needed\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].apply(convert_to_list)\n",
    "\n",
    "# Show the first few rows to verify the conversion\n",
    "df.head()\n",
    "\n",
    "# Function to convert string arrays and extract the inner array\n",
    "def extract_inner_array(value):\n",
    "    try:\n",
    "        # Convert the string to a Python list\n",
    "        converted_value = eval(value) if isinstance(value, str) else value\n",
    "        # If it's a list of lists, return the first list (the inner array)\n",
    "        if isinstance(converted_value, list) and len(converted_value) > 0 and isinstance(converted_value[0], list):\n",
    "            return converted_value[0]\n",
    "        return converted_value\n",
    "    except:\n",
    "        return value  # If eval fails, return the original value\n",
    "\n",
    "# Apply the conversion to the columns that contain arrays as strings\n",
    "columns_to_convert = ['keystep_label', 'keystep_id', 'start_frame', 'end_frame', 'start_t', 'end_t', 'all_preds']  # Add any other columns if needed\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].apply(extract_inner_array)\n",
    "\n",
    "# Show the first few rows to verify the conversion\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function to calculate edit score\n",
    "def calculate_edit_score(ground_truth, predicted, edit_distance):\n",
    "    max_len = max(len(ground_truth), len(predicted))\n",
    "    if max_len == 0:  # To avoid division by zero\n",
    "        return 1.0\n",
    "    edit_score = 1 - (edit_distance / max_len)\n",
    "    return np.round(edit_score, 4)\n",
    "\n",
    "# Function to calculate Levenshtein distance (edit distance)\n",
    "def calculate_edit_distance(ground_truth, predicted):\n",
    "    edit_distance = editdistance.eval(ground_truth, predicted)\n",
    "    return edit_distance\n",
    "\n",
    "\n",
    "# Function to calculate AP for each action (keystep) and mAP\n",
    "def calculate_ap_mAP(ground_truth, predicted, actions):\n",
    "    aps = []\n",
    "    for action in actions:\n",
    "        # Convert the sequences into binary labels for each action\n",
    "        true_binary = (np.array(ground_truth) == action).astype(int)\n",
    "        pred_binary = (np.array(predicted) == action).astype(int)\n",
    "\n",
    "        # Calculate Average Precision (AP)\n",
    "        if np.sum(true_binary) > 0:  # Avoid calculating AP when no ground truth for action\n",
    "            ap = average_precision_score(true_binary, pred_binary)\n",
    "            aps.append(ap)\n",
    "        else:\n",
    "            aps.append(0.0)  # If no ground truth for this action, AP = 0\n",
    "\n",
    "    # Calculate mean AP (mAP)\n",
    "    mAP = np.mean(aps)\n",
    "    return aps, mAP\n",
    "\n",
    "# Function to calculate final average class-wise accuracy\n",
    "def calculate_final_classwise_accuracy(all_ground_truth, all_predicted, actions):\n",
    "    correct_predictions_per_class = {action: 0 for action in actions}\n",
    "    total_samples_per_class = {action: 0 for action in actions}\n",
    "\n",
    "    for ground_truth, predicted in zip(all_ground_truth, all_predicted):\n",
    "        for action in actions:\n",
    "            true_binary = np.array(ground_truth) == action\n",
    "            pred_binary = np.array(predicted) == action\n",
    "            \n",
    "            correct_predictions = np.sum(true_binary & pred_binary)\n",
    "            total_samples = np.sum(true_binary)\n",
    "\n",
    "            correct_predictions_per_class[action] += correct_predictions\n",
    "            total_samples_per_class[action] += total_samples\n",
    "\n",
    "    # Calculate accuracy for each class\n",
    "    classwise_accuracy = {}\n",
    "    for action in actions:\n",
    "        total_samples = total_samples_per_class[action]\n",
    "        if total_samples > 0:\n",
    "            classwise_accuracy[action] = np.round(correct_predictions_per_class[action] / total_samples, 4)\n",
    "        else:\n",
    "            classwise_accuracy[action] = 0.0  # If no samples for this class\n",
    "\n",
    "    return classwise_accuracy\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(pred_interval, gt_intervals):\n",
    "\n",
    "    intersection = np.minimum(pred_interval[1],gt_intervals[:,1]) - np.maximum(pred_interval[0],gt_intervals[:,0])\n",
    "    union = np.maximum(pred_interval[1],gt_intervals[:,1]) - np.minimum(pred_interval[0],gt_intervals[:,0])\n",
    "    return (intersection / union)\n",
    "\n",
    "def calculate_f1_at_k(ground_truth, prediction, k, n_classes=3):\n",
    "\n",
    "    # Break the ground truth and prediction into segments with start and end indices\n",
    "    gt_intervals = []\n",
    "    pred_intervals = []\n",
    "    \n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    # Find start and end of each ground truth segment\n",
    "    start_idx = 1\n",
    "    for i in range(1, len(ground_truth)):\n",
    "        if ground_truth[i] != ground_truth[i - 1]:\n",
    "            gt_intervals.append((start_idx, i ))\n",
    "            gt_labels.append(ground_truth[i-1])\n",
    "            start_idx = i+1\n",
    "    # Append the last ground truth segment\n",
    "    gt_intervals.append((start_idx, len(ground_truth)))\n",
    "    gt_labels.append(ground_truth[-1])\n",
    "\n",
    "    # Find start and end of each prediction segment\n",
    "    start_idx = 1\n",
    "    for i in range(1, len(prediction)):\n",
    "        if prediction[i] != prediction[i - 1]:\n",
    "            pred_intervals.append((start_idx, i))\n",
    "            pred_labels.append(prediction[i-1])\n",
    "            start_idx = i+1\n",
    "    # Append the last prediction segment\n",
    "    pred_intervals.append((start_idx, len(prediction)))\n",
    "    pred_labels.append(prediction[-1])\n",
    "\n",
    "    gt_intervals = np.array(gt_intervals)\n",
    "    pred_intervals = np.array(pred_intervals)\n",
    "\n",
    "        # We keep track of the per-class TPs, and FPs.\n",
    "    # In the end we just sum over them though.\n",
    "    TP = np.zeros(n_classes+1, float)\n",
    "    FP = np.zeros(n_classes+1, float)\n",
    "\n",
    "\n",
    "    n_pred = len(pred_intervals)\n",
    "    n_true = len(gt_intervals)\n",
    "\n",
    "    true_used = np.zeros(n_true, float)\n",
    "\n",
    "    for i in range(n_pred):\n",
    "        current_pred_interval = pred_intervals[i]\n",
    "        current_pred_label = pred_labels[i]\n",
    "\n",
    "        IoU = calculate_iou(current_pred_interval, gt_intervals)*(np.array(gt_labels) == current_pred_label)\n",
    "\n",
    "        idx = np.argmax(IoU)\n",
    "\n",
    "        # If the IoU is high enough and the true segment isn't already used\n",
    "        # Then it is a true positive. Otherwise is it a false positive.\n",
    "        if IoU[idx] >= k and not true_used[idx]:\n",
    "            TP[pred_labels[i]] += 1\n",
    "            true_used[idx] = 1\n",
    "        else:\n",
    "            FP[pred_labels[i]] += 1\n",
    "\n",
    "\n",
    "    TP = TP.sum()\n",
    "    FP = FP.sum()\n",
    "    # False negatives are any unused true segment (i.e. \"miss\")\n",
    "    FN = n_true - true_used.sum()\n",
    "    \n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1 = 2 * (precision*recall) / (precision+recall)\n",
    "\n",
    "    # If the prec+recall=0, it is a NaN. Set these to 0.\n",
    "    F1 = np.nan_to_num(F1)\n",
    "\n",
    "    return F1, precision, recall, TP, FP, FN\n",
    "\n",
    "# Example usage\n",
    "# prediction =  [1, 1, 2, 2, 3, 3, 3]\n",
    "# ground_truth =[1, 1, 1, 2, 2, 3, 3]\n",
    "# k = 0.2  # IoU threshold (50%)\n",
    "\n",
    "# print(\"prediction: \", prediction)\n",
    "# print(\"ground_truth: \", ground_truth)\n",
    "\n",
    "# f1_score, TP, FP, FN = calculate_f1_at_k(ground_truth, prediction, k)\n",
    "# print(f\"F1@{k}: {f1_score}\")\n",
    "# print(f\"True Positives: {TP}, False Positives: {FP}, False Negatives: {FN}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Subject: ms1, Trial: 0\n",
      "edit_distance:  48\n",
      "edit_score:  0.5985521739130435\n",
      "accuracy:  0.5985507246376811\n",
      "**************************************************\n",
      "Subject: ms1, Trial: 5\n",
      "edit_distance:  77\n",
      "edit_score:  0.35588235294117654\n",
      "accuracy:  0.3558823529411765\n",
      "**************************************************\n",
      "Subject: ms2, Trial: 1\n",
      "edit_distance:  80\n",
      "edit_score:  0.33047714285714286\n",
      "accuracy:  0.3304761904761905\n",
      "**************************************************\n",
      "Subject: ng1, Trial: 0\n",
      "edit_distance:  84\n",
      "edit_score:  0.29426874999999997\n",
      "accuracy:  0.2942708333333333\n",
      "**************************************************\n",
      "Subject: ng2, Trial: 1\n",
      "edit_distance:  76\n",
      "edit_score:  0.3606068181818182\n",
      "accuracy:  0.3606060606060606\n",
      "**************************************************\n",
      "Subject: ng3, Trial: 0\n",
      "edit_distance:  25\n",
      "edit_score:  0.7910618181818181\n",
      "accuracy:  0.791060606060606\n",
      "**************************************************\n",
      "Subject: ng3, Trial: 1\n",
      "edit_distance:  37\n",
      "edit_score:  0.6900000000000001\n",
      "accuracy:  0.69\n",
      "**************************************************\n",
      "Subject: ng3, Trial: 11\n",
      "edit_distance:  57\n",
      "edit_score:  0.5169312500000001\n",
      "accuracy:  0.5169270833333334\n",
      "**************************************************\n",
      "Subject: ng3, Trial: 9\n",
      "edit_distance:  87\n",
      "edit_score:  0.27212413793103446\n",
      "accuracy:  0.2721264367816092\n",
      "**************************************************\n",
      "Subject: ng4, Trial: 4\n",
      "edit_distance:  53\n",
      "edit_score:  0.5518774193548387\n",
      "accuracy:  0.5518817204301075\n",
      "**************************************************\n",
      "Subject: ng5, Trial: 12\n",
      "edit_distance:  32\n",
      "edit_score:  0.7324392857142856\n",
      "accuracy:  0.7324404761904761\n",
      "**************************************************\n",
      "Subject: ng5, Trial: 14\n",
      "edit_distance:  37\n",
      "edit_score:  0.6883892857142858\n",
      "accuracy:  0.6883928571428571\n",
      "**************************************************\n",
      "Subject: ng5, Trial: 16\n",
      "edit_distance:  48\n",
      "edit_score:  0.5988057142857143\n",
      "accuracy:  0.5988095238095238\n",
      "**************************************************\n",
      "Subject: ng5, Trial: 18\n",
      "edit_distance:  63\n",
      "edit_score:  0.4675275862068965\n",
      "accuracy:  0.4675287356321839\n",
      "**************************************************\n",
      "Subject: ng5, Trial: 20\n",
      "edit_distance:  77\n",
      "edit_score:  0.35694666666666663\n",
      "accuracy:  0.35694444444444445\n",
      "**************************************************\n",
      "Subject: ng6, Trial: 2\n",
      "edit_distance:  43\n",
      "edit_score:  0.6400576923076924\n",
      "accuracy:  0.6400641025641025\n",
      "**************************************************\n",
      "Subject: ng6, Trial: 4\n",
      "edit_distance:  22\n",
      "edit_score:  0.8127184210526316\n",
      "accuracy:  0.8127192982456141\n",
      "**************************************************\n",
      "Subject: ng7, Trial: 0\n",
      "edit_distance:  82\n",
      "edit_score:  0.3116625\n",
      "accuracy:  0.31166666666666665\n",
      "**************************************************\n",
      "Subject: ng8, Trial: 0\n",
      "edit_distance:  26\n",
      "edit_score:  0.7762820512820513\n",
      "accuracy:  0.7762820512820513\n",
      "**************************************************\n",
      "Subject: ng8, Trial: 1\n",
      "edit_distance:  39\n",
      "edit_score:  0.674590243902439\n",
      "accuracy:  0.6745934959349593\n",
      "**************************************************\n",
      "Subject: ng8, Trial: 2\n",
      "edit_distance:  22\n",
      "edit_score:  0.8150472222222223\n",
      "accuracy:  0.8150462962962963\n",
      "**************************************************\n",
      "Subject: ng9, Trial: 1\n",
      "edit_distance:  41\n",
      "edit_score:  0.6509277777777778\n",
      "accuracy:  0.6509259259259259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_866608/2991342529.py:141: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision*recall) / (precision+recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Class-wise Accuracy:\n",
      "0: 0.9967\n",
      "1: 0.0\n",
      "2: 0.4071\n",
      "3: 0.4882\n",
      "4: 0.7924\n",
      "5: 0.0\n",
      "6: 0.0\n",
      "7: 0.3649\n",
      "8: 0.3316\n",
      "9: 0.6736\n",
      "10: 0.0\n",
      "11: 0.0288\n",
      "12: 0.0\n",
      "13: 0.3253\n",
      "14: 0.675\n",
      "15: 0.6246\n"
     ]
    }
   ],
   "source": [
    "# Grouping by subject_id and trial_id\n",
    "results = []\n",
    "\n",
    "# Assuming 'results_csv' is defined earlier and points to the path of the results CSV\n",
    "results_dir = results_csv.rsplit('/', 1)[0]\n",
    "\n",
    "# IoU thresholds\n",
    "IoU_thresholds = [0.1, 0.25, 0.5]\n",
    "\n",
    "all_accuracy = []\n",
    "all_edit_distances = []\n",
    "all_edit_scores = []\n",
    "all_precisions = {threshold: [] for threshold in IoU_thresholds}\n",
    "all_recalls = {threshold: [] for threshold in IoU_thresholds}\n",
    "all_f1_k = {threshold: [] for threshold in IoU_thresholds}\n",
    "\n",
    "updated_df = []\n",
    "\n",
    "for (subject, trial), group in df.groupby(['subject_id', 'trial_id']):\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Subject: {subject}, Trial: {trial}\")\n",
    "    \n",
    "    # Extract ground truth and predicted keysteps\n",
    "    ground_truth = group['keystep_id'].tolist()  # Ground truth per frame\n",
    "    predicted = group['pred_keystep_id'].tolist()  # Predicted per frame\n",
    "    \n",
    "    def repeat_elements(arr, Y):\n",
    "        # Use list comprehension to repeat each element Y times\n",
    "        return [[element] * Y for element in arr]\n",
    "\n",
    "    Y = len(ground_truth[0])  # For example, repeat each element 3 times\n",
    "    new_array = repeat_elements(predicted, Y)\n",
    "    predicted = new_array\n",
    "\n",
    "    # make predicte\n",
    "\n",
    "    group['predictions'] = predicted\n",
    "    updated_df.append(group)\n",
    "    edit_distances_for_trial = []\n",
    "    edit_scores_for_trial = []\n",
    "\n",
    "    # Calculate edit distance and edit score for each window and average\n",
    "    for gt, pred in zip(ground_truth, predicted):\n",
    "        edit_distance = calculate_edit_distance(ground_truth=gt, predicted=pred)\n",
    "        edit_score = calculate_edit_score(gt, pred, edit_distance)\n",
    "\n",
    "        edit_distances_for_trial.append(edit_distance)\n",
    "        edit_scores_for_trial.append(edit_score)\n",
    "\n",
    "    # Calculate average edit distance and edit score for the trial\n",
    "    edit_distance = int(np.mean(edit_distances_for_trial))\n",
    "    edit_score = np.mean(edit_scores_for_trial)\n",
    "\n",
    "    all_edit_distances.append(edit_distance)\n",
    "    all_edit_scores.append(edit_score)\n",
    "\n",
    "    print(\"edit_distance: \", edit_distance)\n",
    "    print(\"edit_score: \", edit_score)\n",
    "\n",
    "    # Flatten ground truth and predicted sublists\n",
    "    ground_truth = [item for sublist in ground_truth for item in sublist]\n",
    "    predicted = [item for sublist in predicted for item in sublist]\n",
    "\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    all_predicted.append(predicted)\n",
    "\n",
    "    f1_aggregated_metrics = {}\n",
    "\n",
    "    for threshold in IoU_thresholds:\n",
    "        f1_score, precision, recall, TP, FP, FN = calculate_f1_at_k(ground_truth, predicted, threshold, n_classes=len(unique_actions))\n",
    "        # Store precision, recall, f1 metrics for each threshold\n",
    "        metrics = {\n",
    "            f'precision@{threshold}': precision,\n",
    "            f'recall@{threshold}': recall,\n",
    "            f'f1@{threshold}': f1_score,\n",
    "        }\n",
    "        # Append precision, recall, and f1 to the respective lists\n",
    "        all_precisions[threshold].append(precision)\n",
    "        all_recalls[threshold].append(recall)\n",
    "        all_f1_k[threshold].append(f1_score)\n",
    "\n",
    "        # Merge metrics into a single dictionary for appending to results\n",
    "        f1_aggregated_metrics.update(metrics)\n",
    "\n",
    "\n",
    "    ## Calculate accuracy\n",
    "    accuracy = np.mean(np.array(ground_truth) == np.array(predicted))\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    \n",
    "    all_accuracy.append(accuracy)\n",
    "\n",
    "    # Append ground truth and predicted to global lists\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    all_predicted.append(predicted)\n",
    "\n",
    "    # Append result for this subject and trial\n",
    "    results.append({\n",
    "        'subject_id': subject,\n",
    "        'trial_id': trial,\n",
    "        'accuracy': accuracy,\n",
    "        'edit_distance': edit_distance,\n",
    "        'edit_score': edit_score,\n",
    "        **f1_aggregated_metrics,  # Unpack the aggregated f1 metrics\n",
    "        'ground_truth': ground_truth,\n",
    "        'predicted': predicted,\n",
    "    })\n",
    "\n",
    "# Save the results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{results_dir}/subject_wise_results.csv', index=False)\n",
    "\n",
    "# Calculate average metrics\n",
    "average_accuracy = np.mean(all_accuracy)\n",
    "average_edit_distance = int(np.mean(all_edit_distances))\n",
    "average_edit_score = np.mean(all_edit_scores)\n",
    "\n",
    "# Calculate the average precision, recall, and f1 for each IoU threshold\n",
    "average_precisions = {f'average_precision@{threshold}': np.mean(all_precisions[threshold]) for threshold in IoU_thresholds}\n",
    "average_recalls = {f'average_recall@{threshold}': np.mean(all_recalls[threshold]) for threshold in IoU_thresholds}\n",
    "average_f1_k = {f'average_f1@{threshold}': np.mean(all_f1_k[threshold]) for threshold in IoU_thresholds}\n",
    "\n",
    "# Prepare the dictionary for average metrics\n",
    "average_metrics = {\n",
    "    'accuracy': average_accuracy,\n",
    "    'edit_distance': average_edit_distance,\n",
    "    'edit_score': average_edit_score,\n",
    "}\n",
    "average_metrics.update(average_precisions)\n",
    "average_metrics.update(average_recalls)\n",
    "average_metrics.update(average_f1_k)\n",
    "\n",
    "# Convert the average metrics dictionary to a DataFrame and save it as CSV\n",
    "average_metrics_df = pd.DataFrame(average_metrics, index=[0])\n",
    "average_metrics_df.to_csv(f'{results_dir}/average_metrics.csv', index=False)\n",
    "\n",
    "# Calculate final class-wise accuracy across all trials\n",
    "final_classwise_accuracy = calculate_final_classwise_accuracy(all_ground_truth, all_predicted, unique_actions)\n",
    "print(\"Final Class-wise Accuracy:\")\n",
    "for action, accuracy in final_classwise_accuracy.items():\n",
    "    print(f\"{action}: {accuracy}\")\n",
    "\n",
    "# Save the final class-wise accuracy to CSV\n",
    "classwise_accuracy_df = pd.DataFrame.from_dict(final_classwise_accuracy, orient='index', columns=['accuracy'])\n",
    "classwise_accuracy_csv_path = f'{results_dir}/final_classwise_accuracy.csv'\n",
    "classwise_accuracy_df.to_csv(classwise_accuracy_csv_path, index_label='action')\n",
    "\n",
    "\n",
    "# Save the updated dataframe\n",
    "updated_df = pd.concat(updated_df).sort_index()\n",
    "updated_df.to_csv(f'{results_dir}/updated_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         keystep_label  \\\n",
      "0    [approach_patient, approach_patient, approach_...   \n",
      "1    [approach_patient, approach_patient, approach_...   \n",
      "2    [check_responsiveness, check_responsiveness, c...   \n",
      "3    [check_pulse, check_pulse, check_pulse, check_...   \n",
      "4    [chest_compressions, chest_compressions, chest...   \n",
      "..                                                 ...   \n",
      "717  [no_action, no_action, no_action, no_action, n...   \n",
      "718  [no_action, no_action, no_action, no_action, n...   \n",
      "719  [no_action, no_action, no_action, no_action, n...   \n",
      "720  [no_action, no_action, no_action, no_action, n...   \n",
      "721  [no_action, no_action, no_action, no_action, n...   \n",
      "\n",
      "                                            keystep_id  \\\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "3    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
      "4    [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
      "..                                                 ...   \n",
      "717  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...   \n",
      "718  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 1...   \n",
      "719  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...   \n",
      "720  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...   \n",
      "721  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...   \n",
      "\n",
      "                                           start_frame  \\\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2    [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "3    [342, 342, 342, 342, 342, 342, 342, 342, 342, ...   \n",
      "4    [472, 472, 472, 472, 472, 472, 472, 472, 472, ...   \n",
      "..                                                 ...   \n",
      "717  [1557, 1557, 1557, 1557, 1557, 1557, 1557, 155...   \n",
      "718  [1557, 1557, 1557, 1557, 1557, 1557, 1557, 155...   \n",
      "719  [1756, 1756, 1756, 1756, 1756, 1756, 1756, 175...   \n",
      "720  [1756, 1756, 1756, 1756, 1756, 1756, 1756, 175...   \n",
      "721  [1756, 1756, 1756, 1756, 1756, 1756, 1756, 175...   \n",
      "\n",
      "                                             end_frame  \\\n",
      "0    [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "1    [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "2    [342, 342, 342, 342, 342, 342, 342, 342, 342, ...   \n",
      "3    [401, 401, 401, 401, 401, 401, 401, 401, 401, ...   \n",
      "4    [584, 584, 584, 584, 584, 584, 584, 584, 584, ...   \n",
      "..                                                 ...   \n",
      "717  [1690, 1690, 1690, 1690, 1690, 1690, 1690, 169...   \n",
      "718  [1690, 1690, 1690, 1690, 1690, 1690, 1690, 169...   \n",
      "719  [2137, 2137, 2137, 2137, 2137, 2137, 2137, 213...   \n",
      "720  [2137, 2137, 2137, 2137, 2137, 2137, 2137, 213...   \n",
      "721  [2137, 2137, 2137, 2137, 2137, 2137, 2137, 213...   \n",
      "\n",
      "                                               start_t  \\\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2    [6.609000205993652, 6.609000205993652, 6.60900...   \n",
      "3    [11.418999671936035, 11.418999671936035, 11.41...   \n",
      "4    [15.77299976348877, 15.77299976348877, 15.7729...   \n",
      "..                                                 ...   \n",
      "717  [51.96710968017578, 51.96710968017578, 51.9671...   \n",
      "718  [51.96710968017578, 51.96710968017578, 51.9671...   \n",
      "719  [58.606998443603516, 58.606998443603516, 58.60...   \n",
      "720  [58.606998443603516, 58.606998443603516, 58.60...   \n",
      "721  [58.606998443603516, 58.606998443603516, 58.60...   \n",
      "\n",
      "                                                 end_t  window_start_frame  \\\n",
      "0    [6.608630180358887, 6.608630180358887, 6.60863...                   0   \n",
      "1    [6.608630180358887, 6.608630180358887, 6.60863...                 120   \n",
      "2    [11.418919563293457, 11.418919563293457, 11.41...                 240   \n",
      "3    [13.395000457763672, 13.395000457763672, 13.39...                 360   \n",
      "4    [19.509029388427734, 19.509029388427734, 19.50...                 480   \n",
      "..                                                 ...                 ...   \n",
      "717  [56.405418395996094, 56.405418395996094, 56.40...                1560   \n",
      "718  [56.405418395996094, 56.405418395996094, 56.40...                1680   \n",
      "719  [71.305419921875, 71.305419921875, 71.30541992...                1800   \n",
      "720  [71.305419921875, 71.305419921875, 71.30541992...                1920   \n",
      "721  [71.305419921875, 71.305419921875, 71.30541992...                2040   \n",
      "\n",
      "     window_end_frame subject_id trial_id  pred_keystep_id  \\\n",
      "0                 120        ms1        0                0   \n",
      "1                 240        ms1        0                0   \n",
      "2                 360        ms1        0               15   \n",
      "3                 480        ms1        0                2   \n",
      "4                 600        ms1        0                4   \n",
      "..                ...        ...      ...              ...   \n",
      "717              1680        ng9        1               15   \n",
      "718              1800        ng9        1               15   \n",
      "719              1920        ng9        1               15   \n",
      "720              2040        ng9        1               15   \n",
      "721              2160        ng9        1               15   \n",
      "\n",
      "                                             all_preds  \\\n",
      "0    [5.73012638092041, 0.445463091135025, 0.365629...   \n",
      "1    [5.831171035766602, 3.5325310230255127, 2.8858...   \n",
      "2    [1.7756500244140625, 3.1439244747161865, 3.367...   \n",
      "3    [-0.43847012519836426, 3.0513341426849365, 4.0...   \n",
      "4    [0.7568711042404175, -0.2066485583782196, -0.3...   \n",
      "..                                                 ...   \n",
      "717  [-0.6232931613922119, -0.13340888917446136, -0...   \n",
      "718  [-0.6061549186706543, -0.12960736453533173, -0...   \n",
      "719  [-0.6820847988128662, -0.13912037014961243, -0...   \n",
      "720  [-0.7277299761772156, -0.16012388467788696, -0...   \n",
      "721  [-0.5746918320655823, -0.03030271828174591, -0...   \n",
      "\n",
      "                                           predictions  \n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2    [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "3    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
      "4    [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n",
      "..                                                 ...  \n",
      "717  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "718  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "719  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "720  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "721  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  \n",
      "\n",
      "[722 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_866608/2982615263.py:7: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = cm.get_cmap('tab20')  # Get 'num_colors' evenly spaced colors from the colormap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: (0.12156862745098039, 0.4666666666666667, 0.7058823529411765, 1.0),\n",
       " 1: (0.12156862745098039, 0.4666666666666667, 0.7058823529411765, 1.0),\n",
       " 2: (0.6823529411764706, 0.7803921568627451, 0.9098039215686274, 1.0),\n",
       " 3: (0.6823529411764706, 0.7803921568627451, 0.9098039215686274, 1.0),\n",
       " 4: (1.0, 0.4980392156862745, 0.054901960784313725, 1.0),\n",
       " 5: (1.0, 0.4980392156862745, 0.054901960784313725, 1.0),\n",
       " 6: (1.0, 0.7333333333333333, 0.47058823529411764, 1.0),\n",
       " 7: (0.17254901960784313, 0.6274509803921569, 0.17254901960784313, 1.0),\n",
       " 8: (0.17254901960784313, 0.6274509803921569, 0.17254901960784313, 1.0),\n",
       " 9: (0.596078431372549, 0.8745098039215686, 0.5411764705882353, 1.0),\n",
       " 10: (0.596078431372549, 0.8745098039215686, 0.5411764705882353, 1.0),\n",
       " 11: (0.8392156862745098, 0.15294117647058825, 0.1568627450980392, 1.0),\n",
       " 12: (0.8392156862745098, 0.15294117647058825, 0.1568627450980392, 1.0),\n",
       " 13: (1.0, 0.596078431372549, 0.5882352941176471, 1.0),\n",
       " 14: (0.5803921568627451, 0.403921568627451, 0.7411764705882353, 1.0),\n",
       " 15: (0.5803921568627451, 0.403921568627451, 0.7411764705882353, 1.0),\n",
       " 16: (0.7725490196078432, 0.6901960784313725, 0.8352941176470589, 1.0),\n",
       " 17: (0.7725490196078432, 0.6901960784313725, 0.8352941176470589, 1.0),\n",
       " 18: (0.5490196078431373, 0.33725490196078434, 0.29411764705882354, 1.0),\n",
       " 19: (0.5490196078431373, 0.33725490196078434, 0.29411764705882354, 1.0),\n",
       " 20: (0.7686274509803922, 0.611764705882353, 0.5803921568627451, 1.0),\n",
       " 21: (0.8901960784313725, 0.4666666666666667, 0.7607843137254902, 1.0),\n",
       " 22: (0.8901960784313725, 0.4666666666666667, 0.7607843137254902, 1.0),\n",
       " 23: (0.9686274509803922, 0.7137254901960784, 0.8235294117647058, 1.0),\n",
       " 24: (0.9686274509803922, 0.7137254901960784, 0.8235294117647058, 1.0),\n",
       " 25: (0.4980392156862745, 0.4980392156862745, 0.4980392156862745, 1.0),\n",
       " 26: (0.4980392156862745, 0.4980392156862745, 0.4980392156862745, 1.0),\n",
       " 27: (0.7803921568627451, 0.7803921568627451, 0.7803921568627451, 1.0),\n",
       " 28: (0.7372549019607844, 0.7411764705882353, 0.13333333333333333, 1.0),\n",
       " 29: (0.7372549019607844, 0.7411764705882353, 0.13333333333333333, 1.0),\n",
       " 30: (0.8588235294117647, 0.8588235294117647, 0.5529411764705883, 1.0),\n",
       " 31: (0.8588235294117647, 0.8588235294117647, 0.5529411764705883, 1.0),\n",
       " 32: (0.09019607843137255, 0.7450980392156863, 0.8117647058823529, 1.0),\n",
       " 33: (0.09019607843137255, 0.7450980392156863, 0.8117647058823529, 1.0),\n",
       " 34: (0.6196078431372549, 0.8549019607843137, 0.8980392156862745, 1.0)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "# Function to generate a color map for keystep IDs with distinct colors, excluding red shades\n",
    "def get_unique_colors(num_colors):\n",
    "    # Use a base colormap (e.g., hsv)\n",
    "    cmap = cm.get_cmap('tab20')  # Get 'num_colors' evenly spaced colors from the colormap\n",
    "    \n",
    "    # Generate the list of colors by sampling the colormap\n",
    "    colors = [cmap(i / num_colors) for i in range(num_colors)]\n",
    "    return colors\n",
    "\n",
    "# Get unique colors for the number of keysteps\n",
    "num_keysteps = len(keysteps_dict)\n",
    "colors = get_unique_colors(num_keysteps)\n",
    "\n",
    "# Create a color dictionary mapping keystep IDs to colors\n",
    "keystep_color_dict = {keystep_id: colors[i] for i, keystep_id in enumerate(keysteps_dict.keys())}\n",
    "\n",
    "# Output the dictionary for reference\n",
    "keystep_color_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Keysteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Function to generate a color map for keystep IDs with distinct colors\n",
    "def get_unique_colors(num_colors):\n",
    "    return cm.get_cmap('tab20', num_colors)  # Using 'hsv' for distinct colors\n",
    "\n",
    "# Function to plot keystep sequences with unique colors and a legend at the bottom\n",
    "def plot_keystep_sequences(ground_truth, predicted, subject, trial, keystep_dict, results_dir):\n",
    "    # Get unique keystep IDs for ground truth and predicted keysteps\n",
    "    all_keysteps = list(set(ground_truth).union(set(predicted)))\n",
    "    print(len(all_keysteps))\n",
    "    # Generate a color map with as many unique colors as there are keysteps\n",
    "    color_map = get_unique_colors(len(all_keysteps))\n",
    "    color_dict = {keystep_id: color_map(i) for i, keystep_id in enumerate(all_keysteps)}\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))  # Increased height and width for better spacing\n",
    "\n",
    "    # Plot ground truth keysteps\n",
    "    y_pos_gt = 0  # Position for ground truth timeline\n",
    "    for i, (start, end, keystep_id) in enumerate(zip(ground_truth['window_start_frame'], ground_truth['window_end_frame'], ground_truth['keystep_id'])):\n",
    "        width = max(end - start, 5)  # Ensure a minimum width for short keysteps\n",
    "        rect = patches.Rectangle((start, y_pos_gt), width, 1, edgecolor=color_dict[keystep_id], facecolor=color_dict[keystep_id], linewidth=2, alpha=0.85)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Plot predicted keysteps with mismatch highlighting\n",
    "    y_pos_pred = 2  # Increased vertical space between ground truth and prediction\n",
    "    for i, (start, end, pred_keystep_id) in enumerate(zip(predicted['window_start_frame'], predicted['window_end_frame'], predicted['pred_keystep_id'])):\n",
    "        width = max(end - start, 5)  # Ensure a minimum width for short keysteps\n",
    "        gt_keystep_id = ground_truth['keystep_id'].iloc[i] if i < len(ground_truth) else None\n",
    "        if pred_keystep_id != gt_keystep_id:\n",
    "            # Mismatch: use thicker red boundary\n",
    "            rect = patches.Rectangle((start, y_pos_pred), width, 1, edgecolor='black', facecolor=color_dict[pred_keystep_id], linewidth=3, alpha=0.85)\n",
    "            # print(\"Mismatch\")\n",
    "            # print(f\"Predicted: {pred_keystep_id}, Ground Truth: {gt_keystep_id}, Start: {start}, End: {end}\")\n",
    "        else:\n",
    "            # Match: use normal boundary color\n",
    "            rect = patches.Rectangle((start, y_pos_pred), width, 1, edgecolor=color_dict[pred_keystep_id], facecolor=color_dict[pred_keystep_id], linewidth=2, alpha=0.85)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Add labels for the timelines\n",
    "    ax.text(-300, y_pos_gt + 0.5, 'Ground Truth', va='center', fontsize=10, color='blue')\n",
    "    ax.text(-300, y_pos_pred + 0.5, 'Prediction', va='center', fontsize=10, color='red')\n",
    "\n",
    "    # Create a horizontal legend at the bottom\n",
    "    legend_elements = [patches.Patch(facecolor=color_dict[k], edgecolor=color_dict[k], label=f\"{k}: {keystep_dict[k]}\") for k in all_keysteps]\n",
    "    ax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=4, title=\"Keysteps\")\n",
    "\n",
    "    # Set axis limits and labels\n",
    "    ax.set_xlim([0, max(ground_truth['end_frame'].max(), predicted['end_frame'].max())])\n",
    "    ax.set_ylim([-1, 4])\n",
    "    ax.set_xlabel('Frame Number')\n",
    "    ax.set_title(f'Keystep Sequences for Subject {subject} Trial {trial}')\n",
    "\n",
    "    # Hide y-axis\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # hide top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    # save figure\n",
    "    plt.savefig(f'{plots_dir}/subject_{subject}_trial_{trial}_keystep_sequence.png', bbox_inches='tight')\n",
    "    # Show plot\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation\n",
      "Ground Truth:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 15, 15, 15, 15, 15, 15, 15, 15, 15, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m ground_truth \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[1;32m     19\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m predicted \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mplot_keystep_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeysteps_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m, in \u001b[0;36mplot_keystep_sequences\u001b[0;34m(ground_truth, predicted, subject, trial, keystep_dict, results_dir)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround Truth: \u001b[39m\u001b[38;5;124m\"\u001b[39m, ground_truth)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mground_truth\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindow_start_frame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get unique keystep IDs for ground truth and predicted keysteps\u001b[39;00m\n\u001b[1;32m     17\u001b[0m all_keysteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(ground_truth)\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mset\u001b[39m(predicted)))\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "\n",
    "plots_dir = f'{results_dir}/plots'\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Example usage with one subject's trial data\n",
    "for (subject, trial), group in updated_df.groupby(['subject_id', 'trial_id']):\n",
    "    ground_truth_data = group[['keystep_id', 'start_frame', 'end_frame']]\n",
    "    predicted_data = group[['pred_keystep_id', 'start_frame', 'end_frame']]\n",
    "\n",
    "\n",
    "    if(task == \"segmentation\"):\n",
    "        print(\"Segmentation\")\n",
    "        \n",
    "                # Extract ground truth and predicted keysteps\n",
    "        ground_truth = group['keystep_id'].tolist()  # Ground truth per frame\n",
    "        predicted = group['predictions'].tolist()  # Predicted per frame\n",
    "\n",
    "        # Flatten ground truth and predicted sublists\n",
    "        ground_truth = [item for sublist in ground_truth for item in sublist]\n",
    "        predicted = [item for sublist in predicted for item in sublist]\n",
    "\n",
    "        plot_keystep_sequences(ground_truth, predicted, subject, trial, keysteps_dict, plots_dir)\n",
    "\n",
    "\n",
    "    elif(task == \"classification\"):\n",
    "        print(\"Classification\")\n",
    "    else:\n",
    "        print(\"Task not recognized\")\n",
    "  \n",
    "    # print(\"ground_truth_data: \", ground_truth_data)\n",
    "    # print(\"predicted_data: \", predicted_data)\n",
    "    # # save figure\n",
    "    # # Plot using the keystep IDs with unique colors, thicker boundaries, and a horizontal legend\n",
    "    # plot_keystep_sequences(ground_truth_data, predicted_data, subject, trial, keysteps_dict, plots_dir)\n",
    "    # # break  # Only plot the first subject's trial for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approach_patient': 'Approach the patient', 'check_responsiveness': 'Check for responsiveness', 'check_pulse': \"Check patient's pulse\", 'check_breathing': 'Check if patient is breathing', 'chest_compressions': 'Perform chest compressions', 'request_aed': 'Request an AED', 'request_assistance': 'Request additional assistance', 'turn_on_aed': 'Turn on the AED', 'attach_defib_pads': 'Attach defibrillator pads', 'clear_for_analysis': 'Clear for analysis', 'clear_for_shock': 'Clear for shock', 'administer_shock_aed': 'Administer shock using AED', 'open_airway': \"Open patient's airway\", 'place_bvm': 'Place bag valve mask (BVM)', 'ventilate_patient': 'Ventilate patient', 'no_action': 'No action', 'assess_patient': 'Assess the patient', 'explain_procedure': 'Explain the ECG procedure to the patient', 'shave_patient': 'Shave/Cleanse the patient for ECG', 'place_left_arm_lead': 'Place the lead on left arm for ECG', 'place_right_arm_lead': 'Place the lead on right arm for ECG', 'place_left_leg_lead': 'Place the lead on left leg for ECG', 'place_right_leg_lead': 'Place the lead on right leg for ECG', 'place_v1_lead': 'Place the V1 lead on the patient', 'place_v2_lead': 'Place the V2 lead on the patient', 'place_v3_lead': 'Place the V3 lead on the patient', 'place_v4_lead': 'Place the V4 lead on the patient', 'place_v5_lead': 'Place the V5 lead on the patient', 'place_v6_lead': 'Place the V6 lead on the patient', 'ask_patient_age_sex': 'Ask the age and or sex of the patient', 'request_patient_to_not_move': 'Request the patient to not move', 'turn_on_ecg': 'Turn on the ECG machine', 'connect_leads_to_ecg': 'Verify all ECG leads are properly connected', 'obtain_ecg_recording': 'Obtain the ECG recording', 'interpret_and_report': 'Interpret the ECG and report findings'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_866608/1479235139.py:6: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  return cm.get_cmap('tab20', num_colors)  # Using 'hsv' for distinct colors\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(plots_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Plot using the keystep IDs with horizontal bar plot and color legend\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[43mplot_keystep_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeysteps_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# break  # Only plot the first subject's trial for now\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mplot_keystep_bars\u001b[0;34m(ground_truth, predicted, subject, trial, keystep_dict, plots_dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m y_pos_gt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Position for ground truth timeline\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (start, end, keystep_id) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(ground_truth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_frame\u001b[39m\u001b[38;5;124m'\u001b[39m], ground_truth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_frame\u001b[39m\u001b[38;5;124m'\u001b[39m], ground_truth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeystep_id\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 23\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m, \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Ensure a minimum width of 5 for visibility\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     ax\u001b[38;5;241m.\u001b[39mbarh(y_pos_gt, width, left\u001b[38;5;241m=\u001b[39mstart, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, color\u001b[38;5;241m=\u001b[39mcolor_dict[keystep_id], edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m,  linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m     25\u001b[0m     y_pos_gt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Move to next row for ground truth\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Function to generate a color map for keystep IDs with distinct colors\n",
    "def get_unique_colors(num_colors):\n",
    "    return cm.get_cmap('tab20', num_colors)  # Using 'hsv' for distinct colors\n",
    "\n",
    "# Function to plot keystep sequences using horizontal bar plot\n",
    "def plot_keystep_bars(ground_truth, predicted, subject, trial, keystep_dict, plots_dir):\n",
    "    # Get unique keystep IDs for ground truth and predicted keysteps\n",
    "    all_keysteps = list(set(ground_truth['keystep_id'].unique()).union(set(predicted['pred_keystep_id'].unique())))\n",
    "    \n",
    "    # Generate a color map with as many unique colors as there are keysteps\n",
    "    color_map = get_unique_colors(len(all_keysteps))\n",
    "    color_dict = {keystep_id: color_map(i) for i, keystep_id in enumerate(all_keysteps)}\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))  # Increased height for better spacing\n",
    "\n",
    "    # Plot horizontal bars for ground truth keysteps\n",
    "    y_pos_gt = 0  # Position for ground truth timeline\n",
    "    for i, (start, end, keystep_id) in enumerate(zip(ground_truth['start_frame'], ground_truth['end_frame'], ground_truth['keystep_id'])):\n",
    "        width = max(end - start, 5)  # Ensure a minimum width of 5 for visibility\n",
    "        ax.barh(y_pos_gt, width, left=start, height=0.6, color=color_dict[keystep_id], edgecolor='black',  linewidth=0.25)\n",
    "        y_pos_gt += 1  # Move to next row for ground truth\n",
    "\n",
    "    # Plot horizontal bars for predicted keysteps\n",
    "    y_pos_pred = y_pos_gt + 1  # Leave a gap between ground truth and predicted\n",
    "    for i, (start, end, pred_keystep_id) in enumerate(zip(predicted['start_frame'], predicted['end_frame'], predicted['pred_keystep_id'])):\n",
    "        width = max(end - start, 5)  # Ensure a minimum width of 5 for visibility\n",
    "        if pred_keystep_id != ground_truth['keystep_id'].iloc[i]:\n",
    "            ax.barh(y_pos_pred, width, left=start, height=0.6, color=color_dict[pred_keystep_id], edgecolor='black', linewidth=2, hatch='//')  # Highlight mismatches\n",
    "            # ax.barh(y_pos_pred, width, left=start, height=0.6, color=color_dict[pred_keystep_id], edgecolor='black', linewidth=2)  # Highlight mismatches\n",
    "\n",
    "        else:\n",
    "            ax.barh(y_pos_pred, width, left=start, height=0.6, color=color_dict[pred_keystep_id], edgecolor='black', linewidth=0.25)\n",
    "        y_pos_pred += 1  # Move to next row for predicted\n",
    "\n",
    "    # Create a horizontal legend at the bottom\n",
    "    legend_elements = [plt.Line2D([0], [0], color=color_dict[k], lw=4, label=f\"{k}: {keystep_dict[k]}\") for k in all_keysteps]\n",
    "    ax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=4, title=\"Keysteps\")\n",
    "\n",
    "    # Add labels for the timelines\n",
    "    ax.text(-300, y_pos_gt - 7, 'Ground Truth', va='center', fontsize=10, color='blue')\n",
    "    ax.text(-300, y_pos_pred - 6, 'Prediction', va='center', fontsize=10, color='red')\n",
    "\n",
    "    # hide top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "    # Set axis limits and labels\n",
    "    ax.set_xlim([0, max(ground_truth['end_frame'].max(), predicted['end_frame'].max())])\n",
    "    ax.set_yticks([])  # Hide y-axis labels\n",
    "    ax.set_xlabel('Frame Number')\n",
    "    ax.set_title(f'Keystep Sequences for Subject {subject} Trial {trial}')\n",
    "\n",
    "    # save figure\n",
    "    plt.savefig(f'{plots_dir}/subject_{subject}_trial_{trial}_keystep_bars.png', bbox_inches='tight')\n",
    "    # Show plot\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "keysteps_dict = args.dataloader_params['keysteps']\n",
    "print(keysteps_dict)\n",
    "\n",
    "# Inverting the dictionary to map keystep_id to natural language description\n",
    "keystep_id_to_desc = {i: v for i, v in enumerate(keysteps_dict.values())}\n",
    "\n",
    "# Adding a new column to the dataframe that maps keystep_id to the corresponding natural language description\n",
    "df['keystep_description'] = df['keystep_id'].map(keystep_id_to_desc)\n",
    "df['pred_keystep_description'] = df['pred_keystep_id'].map(keystep_id_to_desc)\n",
    "\n",
    "# Display the updated dataframe\n",
    "df.head()\n",
    "\n",
    "# get keysteps dict\n",
    "keysteps_dict = args.dataloader_params['keysteps']\n",
    "# Inverting the dictionary to map keystep_id to natural language description\n",
    "keystep_id_to_desc = {i: v for i, v in enumerate(keysteps_dict.values())}\n",
    "\n",
    "keysteps_dict = keystep_id_to_desc\n",
    "\n",
    "# Example usage with one subject's trial data\n",
    "for (subject, trial), group in df.groupby(['subject_id', 'trial_id']):\n",
    "    ground_truth_data = group[['keystep_id', 'start_frame', 'end_frame']]\n",
    "    predicted_data = group[['pred_keystep_id', 'start_frame', 'end_frame']]\n",
    "\n",
    "    plots_dir = f'{results_dir}/plots/bar_plots'\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    # Plot using the keystep IDs with horizontal bar plot and color legend\n",
    "    plot_keystep_bars(ground_truth_data, predicted_data, subject, trial, keysteps_dict, plots_dir)\n",
    "    # break  # Only plot the first subject's trial for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail result plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data from the table\n",
    "data = {\n",
    "    'Model': ['ICRA Model']*18,\n",
    "    'Modality': ['Video (Resnet50)']*6 + ['I3D (RGB,Flow)']*6 + ['IMU (Smartwatch)']*6,\n",
    "    'Window': ['4s']*3 + ['Full']*3 + ['4s']*3 + ['Full']*3 + ['4s']*3 + ['Full']*3,\n",
    "    'IOU': ['0', '0.25', '0.5']*6,\n",
    "    'Precision': [0.658, 0.658, 0.567, 0.644, 0.640, 0.625, \n",
    "                  0.663, 0.663, 0.636, 0.661, 0.661, 0.651, \n",
    "                  0.556, 0.556, 0.528, 0.490, 0.490, 0.457],\n",
    "    'Recall': [0.701, 0.701, 0.594, 0.683, 0.670, 0.651, \n",
    "               0.715, 0.715, 0.674, 0.703, 0.703, 0.687, \n",
    "               0.614, 0.614, 0.584, 0.551, 0.551, 0.507],\n",
    "    'F1-score': [0.659, 0.659, 0.565, 0.641, 0.634, 0.619, \n",
    "                 0.672, 0.672, 0.640, 0.662, 0.662, 0.651, \n",
    "                 0.571, 0.571, 0.542, 0.500, 0.500, 0.464],\n",
    "    'Accuracy': [0.700, 0.700, 0.700, 0.680, 0.680, 0.680,\n",
    "                 0.711, 0.711, 0.711, 0.701, 0.701, 0.701,\n",
    "                 0.603, 0.603, 0.603, 0.562, 0.562, 0.562],\n",
    "    'Edit Score': [0.862, 0.862, 0.862, 0.798, 0.798, 0.798,\n",
    "                   0.865, 0.865, 0.865, 0.810, 0.810, 0.810,\n",
    "                   0.839, 0.839, 0.839, 0.753, 0.753, 0.753],\n",
    "    'Edit Distance': [4.909, 4.909, 4.909, 3.955, 3.955, 3.955,\n",
    "                      4.909, 4.909, 4.909, 3.682, 3.682, 3.682,\n",
    "                      5.591, 5.591, 5.591, 4.591, 4.591, 4.591]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"hls\", 3))\n",
    "\n",
    "\n",
    "# Plot 1: Precision for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='Precision', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10)\n",
    "plt.title('Precision vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/plots/precision_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Recall for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='Recall', hue='Modality', style='Window', markers=True)\n",
    "plt.title('Recall vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend( loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/plots/recall_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: F1-score for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='F1-score', hue='Modality', style='Window', markers=True)\n",
    "plt.title('F1-score vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend( loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/plots/f1_score_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data from the table\n",
    "data = {\n",
    "    'Model': ['ICRA Model']*18,\n",
    "    'Modality': ['Video (Resnet50)']*6 + ['I3D (RGB,Flow)']*6 + ['IMU (Smartwatch)']*6,\n",
    "    'Window': ['4s']*3 + ['Full']*3 + ['4s']*3 + ['Full']*3 + ['4s']*3 + ['Full']*3,\n",
    "    'IOU': ['0', '0.25', '0.5']*6,\n",
    "    'Precision': [0.658, 0.658, 0.567, 0.644, 0.640, 0.625, \n",
    "                  0.663, 0.663, 0.636, 0.661, 0.661, 0.651, \n",
    "                  0.556, 0.556, 0.528, 0.490, 0.490, 0.457],\n",
    "    'Recall': [0.701, 0.701, 0.594, 0.683, 0.670, 0.651, \n",
    "               0.715, 0.715, 0.674, 0.703, 0.703, 0.687, \n",
    "               0.614, 0.614, 0.584, 0.551, 0.551, 0.507],\n",
    "    'F1-score': [0.659, 0.659, 0.565, 0.641, 0.634, 0.619, \n",
    "                 0.672, 0.672, 0.640, 0.662, 0.662, 0.651, \n",
    "                 0.571, 0.571, 0.542, 0.500, 0.500, 0.464],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"hls\", 3))\n",
    "\n",
    "# Create a figure with three subplots horizontally\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Plot 1: Precision vs IOU\n",
    "sns.lineplot(data=df, x='IOU', y='Precision', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10, ax=axes[0])\n",
    "axes[0].set_title('Precision vs IOU')\n",
    "axes[0].set_xlabel('IOU')\n",
    "axes[0].set_ylabel('Precision')\n",
    "\n",
    "# Plot 2: Recall vs IOU\n",
    "sns.lineplot(data=df, x='IOU', y='Recall', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10, ax=axes[1])\n",
    "axes[1].set_title('Recall vs IOU')\n",
    "axes[1].set_xlabel('IOU')\n",
    "axes[1].set_ylabel('Recall')\n",
    "\n",
    "# Plot 3: F1-score vs IOU\n",
    "sns.lineplot(data=df, x='IOU', y='F1-score', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10, ax=axes[2])\n",
    "axes[2].set_title('F1-score vs IOU')\n",
    "axes[2].set_xlabel('IOU')\n",
    "axes[2].set_ylabel('F1-score')\n",
    "\n",
    "# Remove legends from individual plots\n",
    "axes[0].legend_.remove()\n",
    "axes[1].legend_.remove()\n",
    "axes[2].legend_.remove()\n",
    "\n",
    "# Create a single legend for the entire figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=8)\n",
    "\n",
    "plt.savefig(f'{results_dir}/plots/metrics_vs_iou.png', bbox_inches='tight')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the legend\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the JSON structure into a DataFrame (same as before)\n",
    "rows = []\n",
    "for model in data[\"model\"]:\n",
    "    for exp in model[\"experiments\"]:\n",
    "        if \"iou_results\" in exp:\n",
    "            for iou_result in exp[\"iou_results\"]:\n",
    "                rows.append({\n",
    "                    \"Model\": model[\"model_name\"],\n",
    "                    \"Modality\": exp[\"modality\"],\n",
    "                    \"Window\": exp[\"window_size\"],\n",
    "                    \"IOU\": iou_result[\"iou\"],\n",
    "                    **iou_result[\"results\"]\n",
    "                })\n",
    "        else:\n",
    "            rows.append({\n",
    "                \"Model\": model[\"model_name\"],\n",
    "                \"Modality\": exp[\"modality\"],\n",
    "                \"Window\": exp[\"window_size\"],\n",
    "                \"IOU\": \"N/A\",\n",
    "                **exp[\"results\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Replace 'N/A' with np.nan\n",
    "df.replace(\"N/A\", np.nan, inplace=True)\n",
    "\n",
    "# Now, ensure numeric columns can be properly converted to float\n",
    "df[\"IOU\"] = pd.to_numeric(df[\"IOU\"], errors='coerce')\n",
    "\n",
    "# Now you can handle NaN in several ways\n",
    "# For example, you can drop rows with NaN IOU values or other missing numeric values\n",
    "df.dropna(subset=['IOU'], inplace=True)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"hls\", 3))\n",
    "\n",
    "# Plot 1: Precision for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='precision', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10)\n",
    "plt.title('Precision vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/precision_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Recall for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='recall', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10)\n",
    "plt.title('Recall vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/recall_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: F1-score for each modality and window size\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='IOU', y='f1', hue='Modality', style='Window', markers=True, linewidth=1.5, markersize=10)\n",
    "plt.title('F1-score vs IOU')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=7)\n",
    "plt.savefig(f'{results_dir}/f1_score_vs_iou.png', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egoexoems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
