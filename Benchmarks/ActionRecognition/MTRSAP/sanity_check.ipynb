{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:  5686\n",
      "val dataset size:  1892\n",
      "test dataset size:  2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "from scripts.config import DefaultArgsNamespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from datautils.ems import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Accurate seek is not implemented for pyav backend\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "args = DefaultArgsNamespace()\n",
    "\n",
    "train_loader, val_loader, test_loader = eee_get_dataloaders(args)\n",
    "\n",
    "# # get input feature  size\n",
    "# dataiter = next(iter(train_loader))\n",
    "# batch =  dataiter\n",
    "\n",
    "\n",
    "# # Access the parsed arguments\n",
    "model, optimizer, criterion, device = init_model(args)# verbose_mode = args.verbose\n",
    "model = model.to(device)\n",
    "scheduler = StepLR(optimizer, step_size=args.learning_params[\"lr_drop\"], gamma=0.1)  # adjust parameters as needed\n",
    "\n",
    "dummy_input = torch.randn(1, 30, 1024) # batch, num_frames, channels, height, width\n",
    "\n",
    "dummy_input = dummy_input.to(args.device)\n",
    "\n",
    "dummy_output = model(dummy_input)   \n",
    "\n",
    "print(dummy_output.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, modality, backbone):\n",
    "    # check the shape of the input tensor\n",
    "    # print(x)\n",
    "    feature = None\n",
    "    label = x['keystep_id']\n",
    "    if('video' in modality):\n",
    "        feature = None\n",
    "        x = x['frames']\n",
    "        # extract resnet50 features\n",
    "        x = x.to(device)\n",
    "        x = backbone(x)\n",
    "        feature = x\n",
    "    \n",
    "\n",
    "    elif ( 'flow' in modality and  'rgb' in modality):\n",
    "\n",
    "        # I3D features are already extracted\n",
    "        flow = x['flow'].float()\n",
    "        rgb = x['rgb'].float()\n",
    "        feature = torch.cat((flow, rgb), dim=-1).float()\n",
    "\n",
    "    elif ('rgb' in modality):\n",
    "        # I3D features are already extracted\n",
    "        feature = x['rgb'].float()\n",
    "\n",
    "    elif ('flow' in modality):\n",
    "        # I3D features are already extracted\n",
    "        feature = x['flow'].float()\n",
    "\n",
    "    elif ('audio' in modality):\n",
    "        # Audio features are already extracted\n",
    "        feature = x['audio'].float()\n",
    "\n",
    "    feature_size = feature.shape[-1]\n",
    "\n",
    "    if(feature is not None):\n",
    "        feature = feature.to(device)\n",
    "        label = label.to(device)\n",
    "    return feature, feature_size, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "keysteps = args.dataloader_params['keysteps']\n",
    "out_classes = len(keysteps)\n",
    "print(out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality:  ['video']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size:  2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "modality = args.dataloader_params['modality']\n",
    "print(\"Modality: \", modality)\n",
    "\n",
    "# Find feature dimension\n",
    "input, feature_size, label = preprocess(next(iter(train_loader)), args.dataloader_params['modality'], model.extract_resnet)\n",
    "print(\"Feature size: \", feature_size)\n",
    "\n",
    "args.transformer_params['input_dim'] = feature_size\n",
    "args.transformer_params['output_dim'] = out_classes\n",
    "\n",
    "model, optimizer, criterion, device = init_model(args)# verbose_mode = args.verbose\n",
    "model = model.to(device)\n",
    "scheduler = StepLR(optimizer, step_size=args.learning_params[\"lr_drop\"], gamma=0.1)  # adjust parameters as needed\n",
    "\n",
    "wandb_logger = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"EgoExoEMS\",\n",
    "    group=\"Keystep Recognition\",\n",
    "    mode=\"disabled\",\n",
    "    name=\"Testing on EgoExoEMS with I3D RGB Features - ICRA Model\",\n",
    "    notes=\"initial attempt ICRA model with I3D RGB features\",\n",
    "    config={\n",
    "    \"args\": args,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: tensor([25], device='cuda:0') GT: tensor([4], device='cuda:0')\n",
      "Batch: 0, Loss: 4.087499618530273\n",
      "Epoch: 0, Train Loss: 0.0007188708439202029, Val Loss: 0.0018713998492121949\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # print one batch\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     input,feature_size, label = preprocess(batch, args.dataloader_params['modality'], model.extract_resnet)\n",
    "#     print(\"Model input:\",input.shape)\n",
    "#     output = model(input)\n",
    "#     print(\"Model output:\",output.shape)\n",
    "#     print(\"Label:\",label)\n",
    "#     break\n",
    "\n",
    "results_dir = './results'\n",
    "# # # Train the model\n",
    "for epoch in range(args.learning_params[\"epochs\"]):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, wandb_logger, modality=modality)\n",
    "    val_loss = validate(model, val_loader, criterion, device, wandb_logger, modality=modality)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch: {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "    results = test_model(model, test_loader, criterion, device, wandb_logger, modality=modality, epoch=epoch, results_dir=results_dir)\n",
    "    print(results)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egoexoems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
