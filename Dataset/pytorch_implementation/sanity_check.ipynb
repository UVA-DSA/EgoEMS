{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from EgoExoEMS.EgoExoEMS import EgoExoEMSDataset, collate_fn, transform\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Accurate seek is not implemented for pyav backend\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "root = \"/standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ng9/cardiac_arrest/1/GoPro/GX010346_encoded_trimmed.mp4\"  # Folder in which all videos lie in a specific structure\n",
    "annotation_file = \"../../Annotations/main_annotation_classification.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "annotation_file = \"../../Annotations/splits/trials/test_split_classification.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "\n",
    "# train_annotation_file = \"../../Annotations/splits/keysteps/train_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "# val_annotation_file = \"../../Annotations/splits/keysteps/val_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "# test_annotation_file = \"../../Annotations/splits/keysteps/test_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "\n",
    "\n",
    "train_dataset = EgoExoEMSDataset(annotation_file=annotation_file,\n",
    "                                data_base_path='',\n",
    "                                fps=29.97, frames_per_clip=None, transform=transform, data_types=[ 'resnet'])\n",
    "\n",
    "# Access a sample\n",
    "print(len(train_dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3371, 1024)\n",
      "98\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "flow_path = '/standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ng3/cardiac_arrest/9/i3d_flow/GX010374_encoded_trimmed_flow.npy'\n",
    "gopro_path = '/standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ng3/cardiac_arrest/9/GoPro/GX010374_encoded_trimmed.mp4'\n",
    "\n",
    "# load the flow\n",
    "flow = np.load(flow_path)\n",
    "print(flow.shape)\n",
    "\n",
    "import math\n",
    "\n",
    "print((2724-2626))\n",
    "print(math.ceil((2724-2626)/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision.io import VideoReader\n",
    "# import os\n",
    "# import itertools\n",
    "\n",
    "# start_t = 71.30542\n",
    "# end_t = 72.993\n",
    "# video_path = root\n",
    "# # video_path = \"/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/Sep_2024/Raw/24-09-2024/Bhavik/cardiac_arrest/4/GoPro/GX010399.MP4\"  # Folder in which all videos lie in a specific structure\n",
    "# video_reader = VideoReader(video_path, \"video\")\n",
    "# frames = []\n",
    "\n",
    "\n",
    "# for frame in itertools.takewhile(lambda x: x['pts'] <= end_t, video_reader.seek(start_t)):\n",
    "#     if(frame['pts'] < start_t):\n",
    "#         continue\n",
    "#     print(frame['pts'])\n",
    "#     img_tensor = transform(frame['data'])\n",
    "#     frames.append(img_tensor)\n",
    "\n",
    "# frames = torch.stack(frames)\n",
    "# print(\"Seeking from \", start_t, \" to \", end_t, \"for video \", video_path)\n",
    "# print(\"Frames shape: \", frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "# create a data loader\n",
    "# batch size is 1 for simplicity and to ensure only a full clip related to a key step is given without collating.\n",
    "# if batch size is greater than 1, collate_fn will be called to collate the data.\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 198, 2048]) ['approach_patient'] tensor([0]) tensor([0]) tensor([198]) tensor([0]) tensor([6.6086]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 144, 2048]) ['check_responsiveness'] tensor([1]) tensor([198]) tensor([342]) tensor([6.6090]) tensor([11.4189]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['check_pulse'] tensor([2]) tensor([342]) tensor([472]) tensor([11.4190]) tensor([15.7731]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 71, 2048]) ['check_breathing'] tensor([3]) tensor([401]) tensor([472]) tensor([13.3950]) tensor([15.7731]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 2036, 2048]) ['chest_compressions'] tensor([4]) tensor([472]) tensor([2508]) tensor([15.7730]) tensor([83.7072]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 90, 2048]) ['request_assistance'] tensor([6]) tensor([584]) tensor([674]) tensor([19.5090]) tensor([22.5090]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 78, 2048]) ['request_aed'] tensor([5]) tensor([674]) tensor([752]) tensor([22.5090]) tensor([25.1139]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 162, 2048]) ['no_action'] tensor([15]) tensor([752]) tensor([914]) tensor([25.1139]) tensor([30.5090]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 92, 2048]) ['turn_on_aed'] tensor([7]) tensor([914]) tensor([1006]) tensor([30.5090]) tensor([33.5924]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 9, 2048]) ['no_action'] tensor([15]) tensor([1006]) tensor([1015]) tensor([33.5924]) tensor([33.8840]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 307, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1015]) tensor([1322]) tensor([33.8840]) tensor([44.1307]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 676, 2048]) ['no_action'] tensor([15]) tensor([1322]) tensor([1998]) tensor([44.1307]) tensor([66.6757]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 180, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1998]) tensor([2178]) tensor([66.6757]) tensor([72.6749]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 330, 2048]) ['no_action'] tensor([15]) tensor([2178]) tensor([2508]) tensor([72.6749]) tensor([83.7070]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 134, 2048]) ['no_action'] tensor([15]) tensor([2508]) tensor([2642]) tensor([83.7070]) tensor([88.1881]) ['ms1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 74, 2048]) ['approach_patient'] tensor([0]) tensor([0]) tensor([74]) tensor([0]) tensor([2.4914]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 66, 2048]) ['check_responsiveness'] tensor([1]) tensor([74]) tensor([140]) tensor([2.4910]) tensor([4.6773]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 122, 2048]) ['check_pulse'] tensor([2]) tensor([140]) tensor([262]) tensor([4.6770]) tensor([8.7729]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 104, 2048]) ['check_breathing'] tensor([3]) tensor([171]) tensor([275]) tensor([5.7140]) tensor([9.1920]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 868, 2048]) ['chest_compressions'] tensor([4]) tensor([275]) tensor([1143]) tensor([9.1920]) tensor([38.1474]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 48, 2048]) ['request_assistance'] tensor([6]) tensor([314]) tensor([362]) tensor([10.4814]) tensor([12.1000]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 171, 2048]) ['request_aed'] tensor([5]) tensor([362]) tensor([533]) tensor([12.1000]) tensor([17.7936]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 64, 2048]) ['turn_on_aed'] tensor([7]) tensor([518]) tensor([582]) tensor([17.2939]) tensor([19.4380]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 561, 2048]) ['attach_defib_pads'] tensor([8]) tensor([582]) tensor([1143]) tensor([19.4380]) tensor([38.1474]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 280, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1143]) tensor([1423]) tensor([38.1470]) tensor([47.5037]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 172, 2048]) ['clear_for_shock'] tensor([10]) tensor([1423]) tensor([1595]) tensor([47.5040]) tensor([53.2530]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 165, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1595]) tensor([1760]) tensor([53.2530]) tensor([58.7262]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 632, 2048]) ['chest_compressions'] tensor([4]) tensor([1760]) tensor([2392]) tensor([58.7260]) tensor([79.8460]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 36, 2048]) ['place_bvm'] tensor([13]) tensor([1789]) tensor([1825]) tensor([59.7050]) tensor([60.8980]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 567, 2048]) ['no_action'] tensor([15]) tensor([1825]) tensor([2392]) tensor([60.8980]) tensor([79.8460]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 185, 2048]) ['ventilate_patient'] tensor([14]) tensor([2392]) tensor([2577]) tensor([79.8460]) tensor([86.0054]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 545, 2048]) ['chest_compressions'] tensor([4]) tensor([2577]) tensor([3122]) tensor([86.0050]) tensor([104.2000]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 145, 2048]) ['ventilate_patient'] tensor([14]) tensor([3122]) tensor([3267]) tensor([104.2000]) tensor([109.0400]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 580, 2048]) ['chest_compressions'] tensor([4]) tensor([3267]) tensor([3847]) tensor([109.0400]) tensor([128.3860]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 151, 2048]) ['ventilate_patient'] tensor([14]) tensor([3847]) tensor([3998]) tensor([128.3860]) tensor([133.4333]) ['ms1'] ['5']\n",
      "****==================================================****\n",
      "torch.Size([1, 88, 2048]) ['approach_patient'] tensor([0]) tensor([0]) tensor([88]) tensor([0]) tensor([2.9657]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 63, 2048]) ['check_responsiveness'] tensor([1]) tensor([88]) tensor([151]) tensor([2.9660]) tensor([5.0439]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 120, 2048]) ['check_pulse'] tensor([2]) tensor([151]) tensor([271]) tensor([5.0440]) tensor([9.0553]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 30, 2048]) ['check_breathing'] tensor([3]) tensor([246]) tensor([276]) tensor([8.2270]) tensor([9.2270]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 1046, 2048]) ['chest_compressions'] tensor([4]) tensor([276]) tensor([1322]) tensor([9.2270]) tensor([44.1318]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 21, 2048]) ['request_assistance'] tensor([6]) tensor([329]) tensor([350]) tensor([11.0068]) tensor([11.7030]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 5, 2048]) ['no_action'] tensor([15]) tensor([350]) tensor([355]) tensor([11.7030]) tensor([11.8780]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 30, 2048]) ['request_aed'] tensor([5]) tensor([355]) tensor([385]) tensor([11.8780]) tensor([12.8780]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 325, 2048]) ['no_action'] tensor([15]) tensor([385]) tensor([710]) tensor([12.8780]) tensor([23.6943]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 80, 2048]) ['turn_on_aed'] tensor([7]) tensor([710]) tensor([790]) tensor([23.6943]) tensor([26.3680]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 25, 2048]) ['no_action'] tensor([15]) tensor([790]) tensor([815]) tensor([26.3680]) tensor([27.1943]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 391, 2048]) ['attach_defib_pads'] tensor([8]) tensor([815]) tensor([1206]) tensor([27.1943]) tensor([40.2643]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 116, 2048]) ['no_action'] tensor([15]) tensor([1206]) tensor([1322]) tensor([40.2643]) tensor([44.1320]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 274, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1322]) tensor([1596]) tensor([44.1320]) tensor([53.2681]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 223, 2048]) ['clear_for_shock'] tensor([10]) tensor([1596]) tensor([1819]) tensor([53.2680]) tensor([60.6981]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 71, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1819]) tensor([1890]) tensor([60.6980]) tensor([63.0693]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 64, 2048]) ['place_bvm'] tensor([13]) tensor([1869]) tensor([1933]) tensor([62.3818]) tensor([64.5068]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 682, 2048]) ['chest_compressions'] tensor([4]) tensor([1890]) tensor([2572]) tensor([63.0690]) tensor([85.8230]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['ventilate_patient'] tensor([14]) tensor([2572]) tensor([2702]) tensor([85.8230]) tensor([90.1674]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 596, 2048]) ['chest_compressions'] tensor([4]) tensor([2702]) tensor([3298]) tensor([90.1670]) tensor([110.0508]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 105, 2048]) ['ventilate_patient'] tensor([14]) tensor([3298]) tensor([3403]) tensor([110.0510]) tensor([113.5478]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 589, 2048]) ['chest_compressions'] tensor([4]) tensor([3403]) tensor([3992]) tensor([113.5480]) tensor([133.2190]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 118, 2048]) ['ventilate_patient'] tensor([14]) tensor([3992]) tensor([4110]) tensor([133.2190]) tensor([137.1397]) ['ms2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 172, 2048]) ['chest_compressions'] tensor([4]) tensor([0]) tensor([172]) tensor([0]) tensor([5.7523]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 137, 2048]) ['ventilate_patient'] tensor([14]) tensor([172]) tensor([309]) tensor([5.7520]) tensor([10.3324]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 396, 2048]) ['chest_compressions'] tensor([4]) tensor([309]) tensor([705]) tensor([10.3320]) tensor([23.5439]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 150, 2048]) ['ventilate_patient'] tensor([14]) tensor([705]) tensor([855]) tensor([23.5440]) tensor([28.5357]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 34, 2048]) ['chest_compressions'] tensor([4]) tensor([855]) tensor([889]) tensor([28.5360]) tensor([29.6712]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 75, 2048]) ['turn_on_aed'] tensor([7]) tensor([889]) tensor([964]) tensor([29.6710]) tensor([32.1712]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 172, 2048]) ['no_action'] tensor([15]) tensor([964]) tensor([1136]) tensor([32.1710]) tensor([37.9212]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 278, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1136]) tensor([1414]) tensor([37.9210]) tensor([47.2128]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 204, 2048]) ['clear_for_shock'] tensor([10]) tensor([1414]) tensor([1618]) tensor([47.2130]) tensor([53.9880]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 513, 2048]) ['no_action'] tensor([15]) tensor([1618]) tensor([2131]) tensor([53.9880]) tensor([71.1377]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 79, 2048]) ['check_pulse'] tensor([2]) tensor([1811]) tensor([1890]) tensor([60.4440]) tensor([63.0940]) ['ng1'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 219, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([219]) tensor([0]) tensor([7.3076]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 96, 2048]) ['approach_patient'] tensor([0]) tensor([219]) tensor([315]) tensor([7.3080]) tensor([10.5271]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 110, 2048]) ['check_responsiveness'] tensor([1]) tensor([315]) tensor([425]) tensor([10.5270]) tensor([14.2058]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 48, 2048]) ['check_pulse'] tensor([2]) tensor([425]) tensor([473]) tensor([14.2060]) tensor([15.7947]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 502, 2048]) ['chest_compressions'] tensor([4]) tensor([473]) tensor([975]) tensor([15.7950]) tensor([32.5611]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 81, 2048]) ['place_bvm'] tensor([13]) tensor([502]) tensor([583]) tensor([16.7771]) tensor([19.4747]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 392, 2048]) ['no_action'] tensor([15]) tensor([583]) tensor([975]) tensor([19.4747]) tensor([32.5610]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 119, 2048]) ['ventilate_patient'] tensor([14]) tensor([975]) tensor([1094]) tensor([32.5610]) tensor([36.5143]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 2286, 2048]) ['chest_compressions'] tensor([4]) tensor([1019]) tensor([3305]) tensor([34.0270]) tensor([110.2771]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 111, 2048]) ['ventilate_patient'] tensor([14]) tensor([1484]) tensor([1595]) tensor([49.5270]) tensor([53.2210]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 9, 2048]) ['no_action'] tensor([15]) tensor([1595]) tensor([1604]) tensor([53.2210]) tensor([53.5271]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 279, 2048]) ['request_aed'] tensor([5]) tensor([1604]) tensor([1883]) tensor([53.5271]) tensor([62.8565]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 208, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1851]) tensor([2059]) tensor([61.7771]) tensor([68.7322]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['turn_on_aed'] tensor([7]) tensor([2059]) tensor([2161]) tensor([68.7320]) tensor([72.1166]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 113, 2048]) ['no_action'] tensor([15]) tensor([2161]) tensor([2274]) tensor([72.1166]) tensor([75.8760]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 121, 2048]) ['ventilate_patient'] tensor([14]) tensor([2274]) tensor([2395]) tensor([75.8760]) tensor([79.9188]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 528, 2048]) ['no_action'] tensor([15]) tensor([2395]) tensor([2923]) tensor([79.9188]) tensor([97.5380]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 395, 2048]) ['attach_defib_pads'] tensor([8]) tensor([2923]) tensor([3318]) tensor([97.5380]) tensor([110.7352]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 180, 2048]) ['ventilate_patient'] tensor([14]) tensor([3125]) tensor([3305]) tensor([104.2770]) tensor([110.2771]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 7, 2048]) ['no_action'] tensor([15]) tensor([3305]) tensor([3312]) tensor([110.2771]) tensor([110.5271]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 273, 2048]) ['clear_for_analysis'] tensor([9]) tensor([3312]) tensor([3585]) tensor([110.5271]) tensor([119.6360]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 257, 2048]) ['clear_for_shock'] tensor([10]) tensor([3585]) tensor([3842]) tensor([119.6360]) tensor([128.1989]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 144, 2048]) ['administer_shock_aed'] tensor([11]) tensor([3842]) tensor([3986]) tensor([128.1990]) tensor([133.0271]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 66, 2048]) ['check_pulse'] tensor([2]) tensor([3986]) tensor([4052]) tensor([133.0270]) tensor([135.2182]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 45, 2048]) ['open_airway'] tensor([12]) tensor([4016]) tensor([4061]) tensor([134.0271]) tensor([135.5271]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 83, 2048]) ['place_bvm'] tensor([13]) tensor([4061]) tensor([4144]) tensor([135.5270]) tensor([138.2771]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 434, 2048]) ['chest_compressions'] tensor([4]) tensor([4082]) tensor([4516]) tensor([136.2220]) tensor([150.6977]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 116, 2048]) ['ventilate_patient'] tensor([14]) tensor([4144]) tensor([4260]) tensor([138.2770]) tensor([142.1712]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 228, 2048]) ['no_action'] tensor([15]) tensor([4260]) tensor([4488]) tensor([142.1712]) tensor([149.7770]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 115, 2048]) ['ventilate_patient'] tensor([14]) tensor([4488]) tensor([4603]) tensor([149.7770]) tensor([153.6098]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 445, 2048]) ['chest_compressions'] tensor([4]) tensor([4562]) tensor([5007]) tensor([152.2410]) tensor([167.0733]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 116, 2048]) ['ventilate_patient'] tensor([14]) tensor([4975]) tensor([5091]) tensor([166.0270]) tensor([169.8754]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 12, 2048]) ['no_action'] tensor([15]) tensor([5091]) tensor([5103]) tensor([169.8754]) tensor([170.2860]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 142, 2048]) ['chest_compressions'] tensor([4]) tensor([5103]) tensor([5245]) tensor([170.2860]) tensor([175.0177]) ['ng2'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 69, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([69]) tensor([0]) tensor([2.3100]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 43, 2048]) ['check_responsiveness'] tensor([1]) tensor([69]) tensor([112]) tensor([2.3100]) tensor([3.7553]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 64, 2048]) ['check_pulse'] tensor([2]) tensor([112]) tensor([176]) tensor([3.7550]) tensor([5.8764]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 99, 2048]) ['check_breathing'] tensor([3]) tensor([176]) tensor([275]) tensor([5.8760]) tensor([9.1879]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 26, 2048]) ['request_assistance'] tensor([6]) tensor([275]) tensor([301]) tensor([9.1880]) tensor([10.0531]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 63, 2048]) ['request_aed'] tensor([5]) tensor([301]) tensor([364]) tensor([10.0530]) tensor([12.1771]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 452, 2048]) ['chest_compressions'] tensor([4]) tensor([364]) tensor([816]) tensor([12.1770]) tensor([27.2365]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 46, 2048]) ['place_bvm'] tensor([13]) tensor([816]) tensor([862]) tensor([27.2360]) tensor([28.7857]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 109, 2048]) ['ventilate_patient'] tensor([14]) tensor([862]) tensor([971]) tensor([28.7860]) tensor([32.4120]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 445, 2048]) ['chest_compressions'] tensor([4]) tensor([971]) tensor([1416]) tensor([32.4120]) tensor([47.2568]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 249, 2048]) ['turn_on_aed'] tensor([7]) tensor([971]) tensor([1220]) tensor([32.4120]) tensor([40.7193]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 196, 2048]) ['place_bvm'] tensor([13]) tensor([1220]) tensor([1416]) tensor([40.7190]) tensor([47.2568]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 104, 2048]) ['ventilate_patient'] tensor([14]) tensor([1416]) tensor([1520]) tensor([47.2570]) tensor([50.7311]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 445, 2048]) ['chest_compressions'] tensor([4]) tensor([1520]) tensor([1965]) tensor([50.7310]) tensor([65.5899]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 353, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1547]) tensor([1900]) tensor([51.6200]) tensor([63.3999]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 49, 2048]) ['place_bvm'] tensor([13]) tensor([1900]) tensor([1949]) tensor([63.4000]) tensor([65.0488]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 424, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1900]) tensor([2324]) tensor([63.4000]) tensor([77.5480]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 112, 2048]) ['clear_for_shock'] tensor([10]) tensor([2324]) tensor([2436]) tensor([77.5480]) tensor([81.2974]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 78, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2436]) tensor([2514]) tensor([81.2970]) tensor([83.9014]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 101, 2048]) ['check_pulse'] tensor([2]) tensor([2514]) tensor([2615]) tensor([83.9010]) tensor([87.2652]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 42, 2048]) ['check_breathing'] tensor([3]) tensor([2615]) tensor([2657]) tensor([87.2650]) tensor([88.6624]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 443, 2048]) ['chest_compressions'] tensor([4]) tensor([2619]) tensor([3062]) tensor([87.3900]) tensor([102.1855]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 397, 2048]) ['place_bvm'] tensor([13]) tensor([2665]) tensor([3062]) tensor([88.9260]) tensor([102.1855]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 96, 2048]) ['ventilate_patient'] tensor([14]) tensor([3062]) tensor([3158]) tensor([102.1850]) tensor([105.4050]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 454, 2048]) ['chest_compressions'] tensor([4]) tensor([3158]) tensor([3612]) tensor([105.4050]) tensor([120.5431]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 225, 2048]) ['place_bvm'] tensor([13]) tensor([3387]) tensor([3612]) tensor([113.0310]) tensor([120.5431]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 147, 2048]) ['ventilate_patient'] tensor([14]) tensor([3612]) tensor([3759]) tensor([120.5430]) tensor([125.4260]) ['ng3'] ['11']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['check_responsiveness'] tensor([1]) tensor([0]) tensor([130]) tensor([0]) tensor([4.3516]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 110, 2048]) ['check_pulse'] tensor([2]) tensor([130]) tensor([240]) tensor([4.3520]) tensor([8.0086]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 131, 2048]) ['check_breathing'] tensor([3]) tensor([240]) tensor([371]) tensor([8.0090]) tensor([12.3804]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 454, 2048]) ['chest_compressions'] tensor([4]) tensor([371]) tensor([825]) tensor([12.3800]) tensor([27.5462]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 79, 2048]) ['place_bvm'] tensor([13]) tensor([825]) tensor([904]) tensor([27.5460]) tensor([30.1774]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 160, 2048]) ['ventilate_patient'] tensor([14]) tensor([904]) tensor([1064]) tensor([30.1770]) tensor([35.5336]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 445, 2048]) ['chest_compressions'] tensor([4]) tensor([1064]) tensor([1509]) tensor([35.5340]) tensor([50.3509]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 62, 2048]) ['place_bvm'] tensor([13]) tensor([1509]) tensor([1571]) tensor([50.3510]) tensor([52.4216]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 123, 2048]) ['ventilate_patient'] tensor([14]) tensor([1571]) tensor([1694]) tensor([52.4220]) tensor([56.5417]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['check_pulse'] tensor([2]) tensor([1694]) tensor([1796]) tensor([56.5420]) tensor([59.9401]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 178, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1796]) tensor([1974]) tensor([59.9400]) tensor([65.8699]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 566, 2048]) ['turn_on_aed'] tensor([7]) tensor([1974]) tensor([2540]) tensor([65.8700]) tensor([84.7701]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['attach_defib_pads'] tensor([8]) tensor([2540]) tensor([2670]) tensor([84.7700]) tensor([89.1111]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 119, 2048]) ['turn_on_aed'] tensor([7]) tensor([2670]) tensor([2789]) tensor([89.1110]) tensor([93.0622]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 433, 2048]) ['clear_for_analysis'] tensor([9]) tensor([2789]) tensor([3222]) tensor([93.0620]) tensor([107.5253]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 97, 2048]) ['clear_for_shock'] tensor([10]) tensor([3222]) tensor([3319]) tensor([107.5250]) tensor([110.7561]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 188, 2048]) ['administer_shock_aed'] tensor([11]) tensor([3319]) tensor([3507]) tensor([110.7560]) tensor([117.0259]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 441, 2048]) ['chest_compressions'] tensor([4]) tensor([3507]) tensor([3948]) tensor([117.0260]) tensor([131.7466]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 62, 2048]) ['place_bvm'] tensor([13]) tensor([3948]) tensor([4010]) tensor([131.7470]) tensor([133.8141]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 147, 2048]) ['ventilate_patient'] tensor([14]) tensor([4010]) tensor([4157]) tensor([133.8140]) tensor([138.7093]) ['ng3'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 122, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([122]) tensor([0]) tensor([4.0751]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 57, 2048]) ['check_responsiveness'] tensor([1]) tensor([122]) tensor([179]) tensor([4.0750]) tensor([5.9742]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 95, 2048]) ['check_pulse'] tensor([2]) tensor([179]) tensor([274]) tensor([5.9740]) tensor([9.1582]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 120, 2048]) ['check_breathing'] tensor([3]) tensor([274]) tensor([394]) tensor([9.1580]) tensor([13.1753]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 20, 2048]) ['request_assistance'] tensor([6]) tensor([394]) tensor([414]) tensor([13.1750]) tensor([13.8150]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['request_aed'] tensor([5]) tensor([414]) tensor([474]) tensor([13.8150]) tensor([15.8447]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 455, 2048]) ['chest_compressions'] tensor([4]) tensor([474]) tensor([929]) tensor([15.8450]) tensor([31.0090]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 61, 2048]) ['turn_on_aed'] tensor([7]) tensor([602]) tensor([663]) tensor([20.1080]) tensor([22.1554]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 248, 2048]) ['place_bvm'] tensor([13]) tensor([663]) tensor([911]) tensor([22.1550]) tensor([30.4257]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 145, 2048]) ['ventilate_patient'] tensor([14]) tensor([911]) tensor([1056]) tensor([30.4260]) tensor([35.2417]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 427, 2048]) ['chest_compressions'] tensor([4]) tensor([1056]) tensor([1483]) tensor([35.2420]) tensor([49.5050]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 261, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1068]) tensor([1329]) tensor([35.6580]) tensor([44.3634]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['place_bvm'] tensor([13]) tensor([1329]) tensor([1483]) tensor([44.3630]) tensor([49.5054]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 417, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1483]) tensor([1900]) tensor([49.5050]) tensor([63.4054]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 140, 2048]) ['ventilate_patient'] tensor([14]) tensor([1483]) tensor([1623]) tensor([49.5050]) tensor([54.1800]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 277, 2048]) ['no_action'] tensor([15]) tensor([1623]) tensor([1900]) tensor([54.1800]) tensor([63.4050]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 112, 2048]) ['clear_for_shock'] tensor([10]) tensor([1900]) tensor([2012]) tensor([63.4050]) tensor([67.1395]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 114, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2012]) tensor([2126]) tensor([67.1390]) tensor([70.9554]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 108, 2048]) ['check_pulse'] tensor([2]) tensor([2126]) tensor([2234]) tensor([70.9550]) tensor([74.5554]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 463, 2048]) ['chest_compressions'] tensor([4]) tensor([2209]) tensor([2672]) tensor([73.7220]) tensor([89.1624]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 59, 2048]) ['check_breathing'] tensor([3]) tensor([2234]) tensor([2293]) tensor([74.5550]) tensor([76.5121]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 66, 2048]) ['no_action'] tensor([15]) tensor([2293]) tensor([2359]) tensor([76.5121]) tensor([78.7170]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 325, 2048]) ['place_bvm'] tensor([13]) tensor([2359]) tensor([2684]) tensor([78.7170]) tensor([89.5827]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 136, 2048]) ['ventilate_patient'] tensor([14]) tensor([2684]) tensor([2820]) tensor([89.5830]) tensor([94.1015]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 444, 2048]) ['chest_compressions'] tensor([4]) tensor([2789]) tensor([3233]) tensor([93.0920]) tensor([107.8941]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 175, 2048]) ['place_bvm'] tensor([13]) tensor([3064]) tensor([3239]) tensor([102.2590]) tensor([108.0957]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 123, 2048]) ['ventilate_patient'] tensor([14]) tensor([3239]) tensor([3362]) tensor([108.0960]) tensor([112.1850]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 38, 2048]) ['no_action'] tensor([15]) tensor([3362]) tensor([3400]) tensor([112.1850]) tensor([113.4800]) ['ng3'] ['9']\n",
      "****==================================================****\n",
      "torch.Size([1, 2501, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([2501]) tensor([0.0200]) tensor([83.4554]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 120, 2048]) ['check_responsiveness'] tensor([1]) tensor([2501]) tensor([2621]) tensor([83.4550]) tensor([87.4838]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 95, 2048]) ['check_pulse'] tensor([2]) tensor([2621]) tensor([2716]) tensor([87.4840]) tensor([90.6385]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['check_breathing'] tensor([3]) tensor([2716]) tensor([2818]) tensor([90.6390]) tensor([94.0386]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 57, 2048]) ['request_assistance'] tensor([6]) tensor([2818]) tensor([2875]) tensor([94.0390]) tensor([95.9459]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 458, 2048]) ['chest_compressions'] tensor([4]) tensor([2875]) tensor([3333]) tensor([95.9460]) tensor([111.2119]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 40, 2048]) ['open_airway'] tensor([12]) tensor([3333]) tensor([3373]) tensor([111.2120]) tensor([112.5714]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 45, 2048]) ['place_bvm'] tensor([13]) tensor([3373]) tensor([3418]) tensor([112.5710]) tensor([114.0479]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 211, 2048]) ['ventilate_patient'] tensor([14]) tensor([3418]) tensor([3629]) tensor([114.0480]) tensor([121.1042]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 29, 2048]) ['no_action'] tensor([15]) tensor([3629]) tensor([3658]) tensor([121.1042]) tensor([122.0783]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 30, 2048]) ['check_pulse'] tensor([2]) tensor([3658]) tensor([3688]) tensor([122.0783]) tensor([123.0783]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 191, 2048]) ['attach_defib_pads'] tensor([8]) tensor([3688]) tensor([3879]) tensor([123.0780]) tensor([129.4614]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 249, 2048]) ['turn_on_aed'] tensor([7]) tensor([3879]) tensor([4128]) tensor([129.4610]) tensor([137.7667]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 426, 2048]) ['clear_for_analysis'] tensor([9]) tensor([4128]) tensor([4554]) tensor([137.7670]) tensor([151.9624]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 128, 2048]) ['clear_for_shock'] tensor([10]) tensor([4554]) tensor([4682]) tensor([151.9620]) tensor([156.2251]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 156, 2048]) ['administer_shock_aed'] tensor([11]) tensor([4682]) tensor([4838]) tensor([156.2250]) tensor([161.4610]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 497, 2048]) ['chest_compressions'] tensor([4]) tensor([4838]) tensor([5335]) tensor([161.4610]) tensor([178.0135]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 63, 2048]) ['place_bvm'] tensor([13]) tensor([5335]) tensor([5398]) tensor([178.0140]) tensor([180.1379]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 131, 2048]) ['ventilate_patient'] tensor([14]) tensor([5398]) tensor([5529]) tensor([180.1380]) tensor([184.5048]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 484, 2048]) ['chest_compressions'] tensor([4]) tensor([5529]) tensor([6013]) tensor([184.5050]) tensor([200.6413]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 75, 2048]) ['place_bvm'] tensor([13]) tensor([6013]) tensor([6088]) tensor([200.6410]) tensor([203.1463]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['ventilate_patient'] tensor([14]) tensor([6088]) tensor([6242]) tensor([203.1460]) tensor([208.2761]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 86, 2048]) ['check_responsiveness'] tensor([1]) tensor([6242]) tensor([6328]) tensor([208.2760]) tensor([211.1491]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 205, 2048]) ['chest_compressions'] tensor([4]) tensor([6328]) tensor([6533]) tensor([211.1490]) tensor([218]) ['ng3'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 97, 2048]) ['approach_patient'] tensor([0]) tensor([84]) tensor([181]) tensor([2.8160]) tensor([6.0648]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 7, 2048]) ['no_action'] tensor([15]) tensor([181]) tensor([188]) tensor([6.0648]) tensor([6.2939]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 78, 2048]) ['check_responsiveness'] tensor([1]) tensor([188]) tensor([266]) tensor([6.2939]) tensor([8.8773]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 1, 2048]) ['no_action'] tensor([15]) tensor([266]) tensor([267]) tensor([8.8773]) tensor([8.9189]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 24, 2048]) ['check_pulse'] tensor([2]) tensor([267]) tensor([291]) tensor([8.9189]) tensor([9.7106]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 38, 2048]) ['check_breathing'] tensor([3]) tensor([291]) tensor([329]) tensor([9.7110]) tensor([10.9814]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 3, 2048]) ['no_action'] tensor([15]) tensor([329]) tensor([332]) tensor([10.9814]) tensor([11.1064]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 487, 2048]) ['chest_compressions'] tensor([4]) tensor([332]) tensor([819]) tensor([11.1064]) tensor([27.3564]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 5, 2048]) ['no_action'] tensor([15]) tensor([819]) tensor([824]) tensor([27.3564]) tensor([27.5023]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 55, 2048]) ['place_bvm'] tensor([13]) tensor([824]) tensor([879]) tensor([27.5023]) tensor([29.3348]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 2, 2048]) ['no_action'] tensor([15]) tensor([879]) tensor([881]) tensor([29.3348]) tensor([29.3981]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 100, 2048]) ['ventilate_patient'] tensor([14]) tensor([881]) tensor([981]) tensor([29.3981]) tensor([32.7523]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 4, 2048]) ['no_action'] tensor([15]) tensor([981]) tensor([985]) tensor([32.7523]) tensor([32.8773]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 39, 2048]) ['request_aed'] tensor([5]) tensor([985]) tensor([1024]) tensor([32.8773]) tensor([34.1689]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 53, 2048]) ['turn_on_aed'] tensor([7]) tensor([986]) tensor([1039]) tensor([32.9189]) tensor([34.6689]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 13, 2048]) ['no_action'] tensor([15]) tensor([1039]) tensor([1052]) tensor([34.6689]) tensor([35.1064]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 631, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1052]) tensor([1683]) tensor([35.1064]) tensor([56.1689]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 265, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1683]) tensor([1948]) tensor([56.1690]) tensor([65.0231]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 30, 2048]) ['no_action'] tensor([15]) tensor([1948]) tensor([1978]) tensor([65.0231]) tensor([66.0040]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 65, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1978]) tensor([2043]) tensor([66.0040]) tensor([68.1689]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 145, 2048]) ['clear_for_shock'] tensor([10]) tensor([2010]) tensor([2155]) tensor([67.0970]) tensor([71.9311]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 186, 2048]) ['no_action'] tensor([15]) tensor([2155]) tensor([2341]) tensor([71.9311]) tensor([78.1411]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 74, 2048]) ['check_pulse'] tensor([2]) tensor([2341]) tensor([2415]) tensor([78.1411]) tensor([80.6011]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 23, 2048]) ['check_breathing'] tensor([3]) tensor([2376]) tensor([2399]) tensor([79.2811]) tensor([80.0711]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 38, 2048]) ['no_action'] tensor([15]) tensor([2399]) tensor([2437]) tensor([80.0711]) tensor([81.3411]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 475, 2048]) ['chest_compressions'] tensor([4]) tensor([2437]) tensor([2912]) tensor([81.3411]) tensor([97.1711]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 18, 2048]) ['no_action'] tensor([15]) tensor([2912]) tensor([2930]) tensor([97.1711]) tensor([97.7711]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 33, 2048]) ['place_bvm'] tensor([13]) tensor([2930]) tensor([2963]) tensor([97.7711]) tensor([98.8711]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 103, 2048]) ['ventilate_patient'] tensor([14]) tensor([2963]) tensor([3066]) tensor([98.8710]) tensor([102.3311]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 35, 2048]) ['no_action'] tensor([15]) tensor([3066]) tensor([3101]) tensor([102.3311]) tensor([103.4911]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 478, 2048]) ['chest_compressions'] tensor([4]) tensor([3101]) tensor([3579]) tensor([103.4911]) tensor([119.4211]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 36, 2048]) ['place_bvm'] tensor([13]) tensor([3579]) tensor([3615]) tensor([119.4210]) tensor([120.6311]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 21, 2048]) ['no_action'] tensor([15]) tensor([3615]) tensor([3636]) tensor([120.6311]) tensor([121.3400]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 112, 2048]) ['ventilate_patient'] tensor([14]) tensor([3636]) tensor([3748]) tensor([121.3400]) tensor([125.0711]) ['ng4'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 72, 2048]) ['approach_patient'] tensor([0]) tensor([110]) tensor([182]) tensor([3.7030]) tensor([6.0856]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 83, 2048]) ['check_responsiveness'] tensor([1]) tensor([174]) tensor([257]) tensor([5.8356]) tensor([8.5856]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 6, 2048]) ['no_action'] tensor([15]) tensor([257]) tensor([263]) tensor([8.5856]) tensor([8.7939]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 155, 2048]) ['check_pulse'] tensor([2]) tensor([263]) tensor([418]) tensor([8.7939]) tensor([13.9606]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['check_breathing'] tensor([3]) tensor([265]) tensor([419]) tensor([8.8564]) tensor([14.0023]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 1, 2048]) ['no_action'] tensor([15]) tensor([419]) tensor([420]) tensor([14.0023]) tensor([14.0231]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 462, 2048]) ['chest_compressions'] tensor([4]) tensor([420]) tensor([882]) tensor([14.0231]) tensor([29.4606]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 72, 2048]) ['place_bvm'] tensor([13]) tensor([882]) tensor([954]) tensor([29.4610]) tensor([31.8564]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 124, 2048]) ['ventilate_patient'] tensor([14]) tensor([954]) tensor([1078]) tensor([31.8560]) tensor([36.0023]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 52, 2048]) ['no_action'] tensor([15]) tensor([1078]) tensor([1130]) tensor([36.0023]) tensor([37.7314]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 241, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1130]) tensor([1371]) tensor([37.7314]) tensor([45.7523]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 11, 2048]) ['no_action'] tensor([15]) tensor([1371]) tensor([1382]) tensor([45.7523]) tensor([46.1273]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 268, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1382]) tensor([1650]) tensor([46.1273]) tensor([55.0648]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 61, 2048]) ['no_action'] tensor([15]) tensor([1650]) tensor([1711]) tensor([55.0648]) tensor([57.1064]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 185, 2048]) ['clear_for_shock'] tensor([10]) tensor([1711]) tensor([1896]) tensor([57.1064]) tensor([63.2731]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 5, 2048]) ['no_action'] tensor([15]) tensor([1896]) tensor([1901]) tensor([63.2731]) tensor([63.4606]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 157, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1901]) tensor([2058]) tensor([63.4606]) tensor([68.6898]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 488, 2048]) ['chest_compressions'] tensor([4]) tensor([2058]) tensor([2546]) tensor([68.6900]) tensor([84.9606]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 2, 2048]) ['no_action'] tensor([15]) tensor([2546]) tensor([2548]) tensor([84.9606]) tensor([85.0439]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 56, 2048]) ['place_bvm'] tensor([13]) tensor([2548]) tensor([2604]) tensor([85.0439]) tensor([86.8981]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 126, 2048]) ['ventilate_patient'] tensor([14]) tensor([2604]) tensor([2730]) tensor([86.8980]) tensor([91.1064]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 14, 2048]) ['no_action'] tensor([15]) tensor([2730]) tensor([2744]) tensor([91.1064]) tensor([91.5856]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 479, 2048]) ['chest_compressions'] tensor([4]) tensor([2744]) tensor([3223]) tensor([91.5856]) tensor([107.5648]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 13, 2048]) ['no_action'] tensor([15]) tensor([3223]) tensor([3236]) tensor([107.5648]) tensor([108.0023]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['place_bvm'] tensor([13]) tensor([3236]) tensor([3296]) tensor([108.0023]) tensor([109.9814]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 2, 2048]) ['no_action'] tensor([15]) tensor([3296]) tensor([3298]) tensor([109.9814]) tensor([110.0690]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 125, 2048]) ['ventilate_patient'] tensor([14]) tensor([3298]) tensor([3423]) tensor([110.0690]) tensor([114.2314]) ['ng5'] ['14']\n",
      "****==================================================****\n",
      "torch.Size([1, 50, 2048]) ['approach_patient'] tensor([0]) tensor([101]) tensor([151]) tensor([3.3981]) tensor([5.0648]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 40, 2048]) ['check_responsiveness'] tensor([1]) tensor([151]) tensor([191]) tensor([5.0439]) tensor([6.3981]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 9, 2048]) ['no_action'] tensor([15]) tensor([191]) tensor([200]) tensor([6.3981]) tensor([6.6898]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 131, 2048]) ['check_pulse'] tensor([2]) tensor([200]) tensor([331]) tensor([6.6898]) tensor([11.0648]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 131, 2048]) ['check_breathing'] tensor([3]) tensor([201]) tensor([332]) tensor([6.7106]) tensor([11.1064]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 5, 2048]) ['no_action'] tensor([15]) tensor([332]) tensor([337]) tensor([11.1064]) tensor([11.2523]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 472, 2048]) ['chest_compressions'] tensor([4]) tensor([337]) tensor([809]) tensor([11.2523]) tensor([27.0231]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 21, 2048]) ['no_action'] tensor([15]) tensor([809]) tensor([830]) tensor([27.0231]) tensor([27.7106]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 39, 2048]) ['place_bvm'] tensor([13]) tensor([830]) tensor([869]) tensor([27.7106]) tensor([29.0231]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 4, 2048]) ['no_action'] tensor([15]) tensor([869]) tensor([873]) tensor([29.0231]) tensor([29.1330]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 118, 2048]) ['ventilate_patient'] tensor([14]) tensor([873]) tensor([991]) tensor([29.1330]) tensor([33.0856]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 93, 2048]) ['no_action'] tensor([15]) tensor([991]) tensor([1084]) tensor([33.0856]) tensor([36.1790]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 201, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1084]) tensor([1285]) tensor([36.1790]) tensor([42.8773]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 24, 2048]) ['no_action'] tensor([15]) tensor([1285]) tensor([1309]) tensor([42.8773]) tensor([43.6898]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 290, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1309]) tensor([1599]) tensor([43.6898]) tensor([53.3773]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 66, 2048]) ['no_action'] tensor([15]) tensor([1599]) tensor([1665]) tensor([53.3773]) tensor([55.5856]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 176, 2048]) ['clear_for_shock'] tensor([10]) tensor([1665]) tensor([1841]) tensor([55.5856]) tensor([61.4606]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 10, 2048]) ['no_action'] tensor([15]) tensor([1841]) tensor([1851]) tensor([61.4606]) tensor([61.7939]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 100, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1851]) tensor([1951]) tensor([61.7939]) tensor([65.1064]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 12, 2048]) ['no_action'] tensor([15]) tensor([1951]) tensor([1963]) tensor([65.1064]) tensor([65.5231]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 441, 2048]) ['chest_compressions'] tensor([4]) tensor([1963]) tensor([2404]) tensor([65.5231]) tensor([80.2314]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 22, 2048]) ['no_action'] tensor([15]) tensor([2404]) tensor([2426]) tensor([80.2314]) tensor([80.9606]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 37, 2048]) ['place_bvm'] tensor([13]) tensor([2426]) tensor([2463]) tensor([80.9606]) tensor([82.2106]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 148, 2048]) ['ventilate_patient'] tensor([14]) tensor([2463]) tensor([2611]) tensor([82.2110]) tensor([87.1481]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 27, 2048]) ['no_action'] tensor([15]) tensor([2611]) tensor([2638]) tensor([87.1481]) tensor([88.0231]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 559, 2048]) ['chest_compressions'] tensor([4]) tensor([2638]) tensor([3197]) tensor([88.0231]) tensor([106.6898]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 16, 2048]) ['no_action'] tensor([15]) tensor([3197]) tensor([3213]) tensor([106.6898]) tensor([107.2106]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 46, 2048]) ['place_bvm'] tensor([13]) tensor([3213]) tensor([3259]) tensor([107.2106]) tensor([108.7731]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 126, 2048]) ['ventilate_patient'] tensor([14]) tensor([3259]) tensor([3385]) tensor([108.7730]) tensor([112.9606]) ['ng5'] ['12']\n",
      "****==================================================****\n",
      "torch.Size([1, 183, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([183]) tensor([0]) tensor([6.1343]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 54, 2048]) ['check_responsiveness'] tensor([1]) tensor([183]) tensor([237]) tensor([6.1340]) tensor([7.9221]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 58, 2048]) ['check_pulse'] tensor([2]) tensor([237]) tensor([295]) tensor([7.9220]) tensor([9.8670]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['check_breathing'] tensor([3]) tensor([295]) tensor([425]) tensor([9.8670]) tensor([14.1906]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 448, 2048]) ['chest_compressions'] tensor([4]) tensor([425]) tensor([873]) tensor([14.1910]) tensor([29.1526]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 87, 2048]) ['place_bvm'] tensor([13]) tensor([873]) tensor([960]) tensor([29.1530]) tensor([32.0546]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 145, 2048]) ['ventilate_patient'] tensor([14]) tensor([960]) tensor([1105]) tensor([32.0550]) tensor([36.8919]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 204, 2048]) ['turn_on_aed'] tensor([7]) tensor([1105]) tensor([1309]) tensor([36.8920]) tensor([43.7037]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 613, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1309]) tensor([1922]) tensor([43.7040]) tensor([64.1606]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 435, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1922]) tensor([2357]) tensor([64.1610]) tensor([78.6765]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 107, 2048]) ['clear_for_shock'] tensor([10]) tensor([2357]) tensor([2464]) tensor([78.6760]) tensor([82.2284]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2464]) tensor([2594]) tensor([82.2280]) tensor([86.5583]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 123, 2048]) ['check_pulse'] tensor([2]) tensor([2594]) tensor([2717]) tensor([86.5580]) tensor([90.6707]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 459, 2048]) ['chest_compressions'] tensor([4]) tensor([2717]) tensor([3176]) tensor([90.6710]) tensor([105.9744]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['place_bvm'] tensor([13]) tensor([3176]) tensor([3236]) tensor([105.9740]) tensor([107.9849]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 158, 2048]) ['ventilate_patient'] tensor([14]) tensor([3236]) tensor([3394]) tensor([107.9850]) tensor([113.2667]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 438, 2048]) ['chest_compressions'] tensor([4]) tensor([3394]) tensor([3832]) tensor([113.2670]) tensor([127.8919]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 61, 2048]) ['place_bvm'] tensor([13]) tensor([3832]) tensor([3893]) tensor([127.8920]) tensor([129.9281]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 163, 2048]) ['ventilate_patient'] tensor([14]) tensor([3893]) tensor([4056]) tensor([129.9280]) tensor([135.3617]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 45, 2048]) ['no_action'] tensor([15]) tensor([4056]) tensor([4101]) tensor([135.3620]) tensor([136.8701]) ['ng5'] ['16']\n",
      "****==================================================****\n",
      "torch.Size([1, 216, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([216]) tensor([0]) tensor([7.2314]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 91, 2048]) ['check_responsiveness'] tensor([1]) tensor([216]) tensor([307]) tensor([7.2310]) tensor([10.2723]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 42, 2048]) ['check_pulse'] tensor([2]) tensor([307]) tensor([349]) tensor([10.2720]) tensor([11.6682]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 110, 2048]) ['check_breathing'] tensor([3]) tensor([349]) tensor([459]) tensor([11.6680]) tensor([15.3268]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 1197, 2048]) ['chest_compressions'] tensor([4]) tensor([459]) tensor([1656]) tensor([15.3270]) tensor([55.2568]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['place_bvm'] tensor([13]) tensor([629]) tensor([689]) tensor([21.0068]) tensor([23.0068]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 194, 2048]) ['ventilate_patient'] tensor([14]) tensor([689]) tensor([883]) tensor([23.0070]) tensor([29.4841]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 7, 2048]) ['no_action'] tensor([15]) tensor([883]) tensor([890]) tensor([29.4841]) tensor([29.7120]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 144, 2048]) ['turn_on_aed'] tensor([7]) tensor([890]) tensor([1034]) tensor([29.7120]) tensor([34.5224]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 584, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1034]) tensor([1618]) tensor([34.5220]) tensor([54.0196]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 432, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1618]) tensor([2050]) tensor([54.0200]) tensor([68.4268]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 126, 2048]) ['clear_for_shock'] tensor([10]) tensor([2050]) tensor([2176]) tensor([68.4270]) tensor([72.6368]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 77, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2176]) tensor([2253]) tensor([72.6370]) tensor([75.2023]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 116, 2048]) ['check_pulse'] tensor([2]) tensor([2253]) tensor([2369]) tensor([75.2020]) tensor([79.0681]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 65, 2048]) ['check_breathing'] tensor([3]) tensor([2348]) tensor([2413]) tensor([78.3718]) tensor([80.5262]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 879, 2048]) ['chest_compressions'] tensor([4]) tensor([2379]) tensor([3258]) tensor([79.4050]) tensor([108.7156]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 96, 2048]) ['place_bvm'] tensor([13]) tensor([2400]) tensor([2496]) tensor([80.0924]) tensor([83.3025]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 857, 2048]) ['ventilate_patient'] tensor([14]) tensor([2496]) tensor([3353]) tensor([83.3030]) tensor([111.9045]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['no_action'] tensor([15]) tensor([3353]) tensor([3455]) tensor([111.9040]) tensor([115.2820]) ['ng5'] ['18']\n",
      "****==================================================****\n",
      "torch.Size([1, 212, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([212]) tensor([0]) tensor([7.0928]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 68, 2048]) ['check_responsiveness'] tensor([1]) tensor([212]) tensor([280]) tensor([7.0930]) tensor([9.3564]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 150, 2048]) ['check_pulse'] tensor([2]) tensor([280]) tensor([430]) tensor([9.3560]) tensor([14.3624]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 21, 2048]) ['check_breathing'] tensor([3]) tensor([430]) tensor([451]) tensor([14.3620]) tensor([15.0784]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 24, 2048]) ['request_assistance'] tensor([6]) tensor([451]) tensor([475]) tensor([15.0780]) tensor([15.8510]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 441, 2048]) ['chest_compressions'] tensor([4]) tensor([475]) tensor([916]) tensor([15.8510]) tensor([30.5929]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 197, 2048]) ['place_bvm'] tensor([13]) tensor([524]) tensor([721]) tensor([17.5140]) tensor([24.0755]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 134, 2048]) ['turn_on_aed'] tensor([7]) tensor([721]) tensor([855]) tensor([24.0760]) tensor([28.5431]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 61, 2048]) ['place_bvm'] tensor([13]) tensor([855]) tensor([916]) tensor([28.5430]) tensor([30.5929]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 153, 2048]) ['ventilate_patient'] tensor([14]) tensor([916]) tensor([1069]) tensor([30.5930]) tensor([35.6761]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 433, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1069]) tensor([1502]) tensor([35.6760]) tensor([50.1375]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 455, 2048]) ['chest_compressions'] tensor([4]) tensor([1106]) tensor([1561]) tensor([36.9139]) tensor([52.0941]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 431, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1502]) tensor([1933]) tensor([50.1380]) tensor([64.4993]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 40, 2048]) ['place_bvm'] tensor([13]) tensor([1559]) tensor([1599]) tensor([52.0200]) tensor([53.3727]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 119, 2048]) ['ventilate_patient'] tensor([14]) tensor([1599]) tensor([1718]) tensor([53.3730]) tensor([57.3257]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 215, 2048]) ['no_action'] tensor([15]) tensor([1718]) tensor([1933]) tensor([57.3257]) tensor([64.4990]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 106, 2048]) ['clear_for_shock'] tensor([10]) tensor([1933]) tensor([2039]) tensor([64.4990]) tensor([68.0567]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 89, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2039]) tensor([2128]) tensor([68.0570]) tensor([71.0198]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 98, 2048]) ['check_pulse'] tensor([2]) tensor([2128]) tensor([2226]) tensor([71.0200]) tensor([74.3027]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 31, 2048]) ['check_breathing'] tensor([3]) tensor([2186]) tensor([2217]) tensor([72.9440]) tensor([73.9899]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 9, 2048]) ['no_action'] tensor([15]) tensor([2217]) tensor([2226]) tensor([73.9899]) tensor([74.3030]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 473, 2048]) ['chest_compressions'] tensor([4]) tensor([2226]) tensor([2699]) tensor([74.3030]) tensor([90.0805]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 75, 2048]) ['place_bvm'] tensor([13]) tensor([2238]) tensor([2313]) tensor([74.6943]) tensor([77.2047]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 165, 2048]) ['no_action'] tensor([15]) tensor([2313]) tensor([2478]) tensor([77.2047]) tensor([82.7160]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 221, 2048]) ['place_bvm'] tensor([13]) tensor([2478]) tensor([2699]) tensor([82.7160]) tensor([90.0805]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 133, 2048]) ['ventilate_patient'] tensor([14]) tensor([2699]) tensor([2832]) tensor([90.0810]) tensor([94.5062]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 438, 2048]) ['chest_compressions'] tensor([4]) tensor([2832]) tensor([3270]) tensor([94.5060]) tensor([109.1160]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 153, 2048]) ['place_bvm'] tensor([13]) tensor([3117]) tensor([3270]) tensor([104.0060]) tensor([109.1160]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 159, 2048]) ['ventilate_patient'] tensor([14]) tensor([3270]) tensor([3429]) tensor([109.1160]) tensor([114.4212]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 82, 2048]) ['no_action'] tensor([15]) tensor([3429]) tensor([3528]) tensor([114.4210]) tensor([117.7180]) ['ng5'] ['20']\n",
      "****==================================================****\n",
      "torch.Size([1, 25, 2048]) ['approach_patient'] tensor([0]) tensor([67]) tensor([92]) tensor([2.2660]) tensor([3.0856]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 165, 2048]) ['check_responsiveness'] tensor([1]) tensor([92]) tensor([257]) tensor([3.0860]) tensor([8.5856]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 14, 2048]) ['no_action'] tensor([15]) tensor([257]) tensor([271]) tensor([8.5856]) tensor([9.0648]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 124, 2048]) ['check_pulse'] tensor([2]) tensor([271]) tensor([395]) tensor([9.0648]) tensor([13.1898]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 2, 2048]) ['no_action'] tensor([15]) tensor([395]) tensor([397]) tensor([13.1898]) tensor([13.2523]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 525, 2048]) ['chest_compressions'] tensor([4]) tensor([397]) tensor([922]) tensor([13.2523]) tensor([30.7939]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 4, 2048]) ['no_action'] tensor([15]) tensor([922]) tensor([926]) tensor([30.7939]) tensor([30.9189]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 51, 2048]) ['place_bvm'] tensor([13]) tensor([926]) tensor([977]) tensor([30.9189]) tensor([32.6064]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['ventilate_patient'] tensor([14]) tensor([977]) tensor([1079]) tensor([32.6060]) tensor([36.0231]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 96, 2048]) ['no_action'] tensor([15]) tensor([1079]) tensor([1175]) tensor([36.0231]) tensor([39.2314]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 401, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1175]) tensor([1576]) tensor([39.2314]) tensor([52.6064]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 59, 2048]) ['no_action'] tensor([15]) tensor([1576]) tensor([1635]) tensor([52.6064]) tensor([54.5648]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 280, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1635]) tensor([1915]) tensor([54.5648]) tensor([63.9189]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 73, 2048]) ['no_action'] tensor([15]) tensor([1915]) tensor([1988]) tensor([63.9189]) tensor([66.3564]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 165, 2048]) ['clear_for_shock'] tensor([10]) tensor([1988]) tensor([2153]) tensor([66.3564]) tensor([71.8564]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 16, 2048]) ['no_action'] tensor([15]) tensor([2153]) tensor([2169]) tensor([71.8564]) tensor([72.3773]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2169]) tensor([2323]) tensor([72.3773]) tensor([77.5231]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 7, 2048]) ['no_action'] tensor([15]) tensor([2323]) tensor([2330]) tensor([77.5231]) tensor([77.7523]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 594, 2048]) ['chest_compressions'] tensor([4]) tensor([2330]) tensor([2924]) tensor([77.7523]) tensor([97.5856]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 12, 2048]) ['no_action'] tensor([15]) tensor([2924]) tensor([2936]) tensor([97.5856]) tensor([97.9814]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 87, 2048]) ['place_bvm'] tensor([13]) tensor([2936]) tensor([3023]) tensor([97.9814]) tensor([100.8773]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 3, 2048]) ['no_action'] tensor([15]) tensor([3023]) tensor([3026]) tensor([100.8773]) tensor([100.9814]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 127, 2048]) ['ventilate_patient'] tensor([14]) tensor([3026]) tensor([3153]) tensor([100.9814]) tensor([105.2106]) ['ng6'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([154]) tensor([0]) tensor([5.1404]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 112, 2048]) ['check_responsiveness'] tensor([1]) tensor([154]) tensor([266]) tensor([5.1400]) tensor([8.8780]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 106, 2048]) ['check_pulse'] tensor([2]) tensor([266]) tensor([372]) tensor([8.8780]) tensor([12.4450]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 100, 2048]) ['check_breathing'] tensor([3]) tensor([372]) tensor([472]) tensor([12.4450]) tensor([15.7654]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 533, 2048]) ['chest_compressions'] tensor([4]) tensor([472]) tensor([1005]) tensor([15.7650]) tensor([33.5430]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 90, 2048]) ['place_bvm'] tensor([13]) tensor([1005]) tensor([1095]) tensor([33.5430]) tensor([36.5527]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 181, 2048]) ['ventilate_patient'] tensor([14]) tensor([1095]) tensor([1276]) tensor([36.5530]) tensor([42.5999]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 537, 2048]) ['chest_compressions'] tensor([4]) tensor([1276]) tensor([1813]) tensor([42.6000]) tensor([60.4980]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 77, 2048]) ['place_bvm'] tensor([13]) tensor([1813]) tensor([1890]) tensor([60.4980]) tensor([63.0841]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 174, 2048]) ['ventilate_patient'] tensor([14]) tensor([1890]) tensor([2064]) tensor([63.0840]) tensor([68.8877]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 30, 2048]) ['request_assistance'] tensor([6]) tensor([2064]) tensor([2094]) tensor([68.8880]) tensor([69.9005]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 192, 2048]) ['turn_on_aed'] tensor([7]) tensor([2094]) tensor([2286]) tensor([69.9010]) tensor([76.2878]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 642, 2048]) ['attach_defib_pads'] tensor([8]) tensor([2286]) tensor([2928]) tensor([76.2880]) tensor([97.7167]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 432, 2048]) ['clear_for_analysis'] tensor([9]) tensor([2928]) tensor([3360]) tensor([97.7170]) tensor([112.1193]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 127, 2048]) ['clear_for_shock'] tensor([10]) tensor([3360]) tensor([3487]) tensor([112.1190]) tensor([116.3813]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 105, 2048]) ['administer_shock_aed'] tensor([11]) tensor([3487]) tensor([3592]) tensor([116.3810]) tensor([119.8625]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 645, 2048]) ['chest_compressions'] tensor([4]) tensor([3592]) tensor([4237]) tensor([119.8620]) tensor([141.3796]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 87, 2048]) ['place_bvm'] tensor([13]) tensor([4237]) tensor([4324]) tensor([141.3800]) tensor([144.2778]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 120, 2048]) ['ventilate_patient'] tensor([14]) tensor([4324]) tensor([4444]) tensor([144.2780]) tensor([148.2820]) ['ng6'] ['4']\n",
      "****==================================================****\n",
      "torch.Size([1, 123, 2048]) ['approach_patient'] tensor([0]) tensor([0]) tensor([123]) tensor([0]) tensor([4.1166]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 51, 2048]) ['check_responsiveness'] tensor([1]) tensor([123]) tensor([174]) tensor([4.1170]) tensor([5.8363]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 54, 2048]) ['check_pulse'] tensor([2]) tensor([174]) tensor([228]) tensor([5.8360]) tensor([7.6347]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 1484, 2048]) ['chest_compressions'] tensor([4]) tensor([228]) tensor([1712]) tensor([7.6350]) tensor([57.1318]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 71, 2048]) ['place_bvm'] tensor([13]) tensor([723]) tensor([794]) tensor([24.1490]) tensor([26.5128]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 137, 2048]) ['no_action'] tensor([15]) tensor([794]) tensor([931]) tensor([26.5128]) tensor([31.0880]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 109, 2048]) ['ventilate_patient'] tensor([14]) tensor([931]) tensor([1040]) tensor([31.0880]) tensor([34.7210]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 46, 2048]) ['turn_on_aed'] tensor([7]) tensor([1015]) tensor([1061]) tensor([33.8790]) tensor([35.4320]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 245, 2048]) ['no_action'] tensor([15]) tensor([1061]) tensor([1306]) tensor([35.4320]) tensor([43.5878]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 164, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1306]) tensor([1470]) tensor([43.5878]) tensor([49.0733]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 138, 2048]) ['ventilate_patient'] tensor([14]) tensor([1353]) tensor([1491]) tensor([45.1710]) tensor([49.7635]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 221, 2048]) ['no_action'] tensor([15]) tensor([1491]) tensor([1712]) tensor([49.7635]) tensor([57.1320]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 219, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1712]) tensor([1931]) tensor([57.1320]) tensor([64.4467]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 185, 2048]) ['clear_for_shock'] tensor([10]) tensor([1931]) tensor([2116]) tensor([64.4470]) tensor([70.6318]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 103, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2116]) tensor([2219]) tensor([70.6260]) tensor([74.0591]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 73, 2048]) ['no_action'] tensor([15]) tensor([2219]) tensor([2292]) tensor([74.0591]) tensor([76.5070]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 70, 2048]) ['check_pulse'] tensor([2]) tensor([2292]) tensor([2362]) tensor([76.5070]) tensor([78.8191]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 1796, 2048]) ['chest_compressions'] tensor([4]) tensor([2362]) tensor([4158]) tensor([78.8190]) tensor([138.7656]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 46, 2048]) ['place_bvm'] tensor([13]) tensor([2389]) tensor([2435]) tensor([79.7240]) tensor([81.2544]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 380, 2048]) ['no_action'] tensor([15]) tensor([2435]) tensor([2815]) tensor([81.2544]) tensor([93.9450]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 127, 2048]) ['ventilate_patient'] tensor([14]) tensor([2815]) tensor([2942]) tensor([93.9450]) tensor([98.1890]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 307, 2048]) ['no_action'] tensor([15]) tensor([2942]) tensor([3249]) tensor([98.1890]) tensor([108.4170]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 130, 2048]) ['ventilate_patient'] tensor([14]) tensor([3249]) tensor([3379]) tensor([108.4170]) tensor([112.7564]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 300, 2048]) ['no_action'] tensor([15]) tensor([3379]) tensor([3679]) tensor([112.7564]) tensor([122.7640]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 157, 2048]) ['ventilate_patient'] tensor([14]) tensor([3679]) tensor([3836]) tensor([122.7640]) tensor([128.0090]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 272, 2048]) ['no_action'] tensor([15]) tensor([3836]) tensor([4108]) tensor([128.0090]) tensor([137.0770]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 50, 2048]) ['ventilate_patient'] tensor([14]) tensor([4108]) tensor([4158]) tensor([137.0770]) tensor([138.7656]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 322, 2048]) ['clear_for_analysis'] tensor([9]) tensor([4158]) tensor([4480]) tensor([138.7660]) tensor([149.5135]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 87, 2048]) ['clear_for_shock'] tensor([10]) tensor([4480]) tensor([4567]) tensor([149.5140]) tensor([152.3885]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 11, 2048]) ['no_action'] tensor([15]) tensor([4567]) tensor([4578]) tensor([152.3885]) tensor([152.7640]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 120, 2048]) ['administer_shock_aed'] tensor([11]) tensor([4578]) tensor([4698]) tensor([152.7640]) tensor([156.7635]) ['ng7'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 271, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([271]) tensor([0]) tensor([9.0490]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 24, 2048]) ['chest_compressions'] tensor([4]) tensor([271]) tensor([295]) tensor([9.0490]) tensor([9.8490]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 104, 2048]) ['check_pulse'] tensor([2]) tensor([295]) tensor([399]) tensor([9.8490]) tensor([13.3359]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 531, 2048]) ['chest_compressions'] tensor([4]) tensor([399]) tensor([930]) tensor([13.3360]) tensor([31.0435]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 57, 2048]) ['place_bvm'] tensor([13]) tensor([930]) tensor([987]) tensor([31.0430]) tensor([32.9600]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 105, 2048]) ['ventilate_patient'] tensor([14]) tensor([987]) tensor([1092]) tensor([32.9600]) tensor([36.4662]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 272, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1092]) tensor([1364]) tensor([36.4660]) tensor([45.5410]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 436, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1364]) tensor([1800]) tensor([45.5410]) tensor([60.0638]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 129, 2048]) ['clear_for_shock'] tensor([10]) tensor([1800]) tensor([1929]) tensor([60.0640]) tensor([64.3753]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 146, 2048]) ['administer_shock_aed'] tensor([11]) tensor([1929]) tensor([2075]) tensor([64.3750]) tensor([69.2590]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 13, 2048]) ['no_action'] tensor([15]) tensor([2075]) tensor([2088]) tensor([69.2590]) tensor([69.6920]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 532, 2048]) ['chest_compressions'] tensor([4]) tensor([2088]) tensor([2620]) tensor([69.6920]) tensor([87.4257]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 67, 2048]) ['place_bvm'] tensor([13]) tensor([2620]) tensor([2687]) tensor([87.4260]) tensor([89.6795]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 180, 2048]) ['ventilate_patient'] tensor([14]) tensor([2687]) tensor([2867]) tensor([89.6800]) tensor([95.6956]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 1, 2048]) ['no_action'] tensor([15]) tensor([2867]) tensor([2868]) tensor([95.6956]) tensor([95.6960]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 477, 2048]) ['chest_compressions'] tensor([4]) tensor([2868]) tensor([3345]) tensor([95.6960]) tensor([111.6287]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 65, 2048]) ['place_bvm'] tensor([13]) tensor([3345]) tensor([3410]) tensor([111.6290]) tensor([113.7964]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 177, 2048]) ['ventilate_patient'] tensor([14]) tensor([3410]) tensor([3587]) tensor([113.7960]) tensor([119.6956]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 479, 2048]) ['chest_compressions'] tensor([4]) tensor([3587]) tensor([4066]) tensor([119.6960]) tensor([135.6996]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 53, 2048]) ['place_bvm'] tensor([13]) tensor([4066]) tensor([4119]) tensor([135.7000]) tensor([137.4464]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 87, 2048]) ['ventilate_patient'] tensor([14]) tensor([4119]) tensor([4206]) tensor([137.4460]) tensor([140.3736]) ['ng8'] ['2']\n",
      "****==================================================****\n",
      "torch.Size([1, 152, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([152]) tensor([0]) tensor([5.0910]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 74, 2048]) ['check_breathing'] tensor([3]) tensor([152]) tensor([226]) tensor([5.0910]) tensor([7.5554]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 74, 2048]) ['check_pulse'] tensor([2]) tensor([152]) tensor([226]) tensor([5.0910]) tensor([7.5554]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 103, 2048]) ['no_action'] tensor([15]) tensor([226]) tensor([329]) tensor([7.5554]) tensor([10.9830]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 122, 2048]) ['check_breathing'] tensor([3]) tensor([329]) tensor([451]) tensor([10.9830]) tensor([15.0554]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 122, 2048]) ['check_pulse'] tensor([2]) tensor([329]) tensor([451]) tensor([10.9830]) tensor([15.0554]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 596, 2048]) ['chest_compressions'] tensor([4]) tensor([451]) tensor([1047]) tensor([15.0550]) tensor([34.9478]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 426, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1047]) tensor([1473]) tensor([34.9480]) tensor([49.1606]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 302, 2048]) ['turn_on_aed'] tensor([7]) tensor([1473]) tensor([1775]) tensor([49.1610]) tensor([59.2300]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 427, 2048]) ['clear_for_analysis'] tensor([9]) tensor([1775]) tensor([2202]) tensor([59.2300]) tensor([73.4916]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 164, 2048]) ['clear_for_shock'] tensor([10]) tensor([2202]) tensor([2366]) tensor([73.4920]) tensor([78.9650]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 190, 2048]) ['administer_shock_aed'] tensor([11]) tensor([2366]) tensor([2556]) tensor([78.9650]) tensor([85.3131]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 574, 2048]) ['chest_compressions'] tensor([4]) tensor([2556]) tensor([3130]) tensor([85.3130]) tensor([104.4543]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 86, 2048]) ['place_bvm'] tensor([13]) tensor([3130]) tensor([3216]) tensor([104.4540]) tensor([107.3298]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 170, 2048]) ['ventilate_patient'] tensor([14]) tensor([3216]) tensor([3386]) tensor([107.3300]) tensor([113.0049]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 435, 2048]) ['chest_compressions'] tensor([4]) tensor([3386]) tensor([3821]) tensor([113.0050]) tensor([127.5076]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 75, 2048]) ['place_bvm'] tensor([13]) tensor([3821]) tensor([3896]) tensor([127.5080]) tensor([130.0053]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 165, 2048]) ['ventilate_patient'] tensor([14]) tensor([3896]) tensor([4061]) tensor([130.0050]) tensor([135.5288]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 462, 2048]) ['chest_compressions'] tensor([4]) tensor([4061]) tensor([4523]) tensor([135.5290]) tensor([150.9295]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['place_bvm'] tensor([13]) tensor([4523]) tensor([4583]) tensor([150.9300]) tensor([152.9420]) ['ng8'] ['0']\n",
      "****==================================================****\n",
      "torch.Size([1, 174, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([174]) tensor([0]) tensor([5.8370]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 133, 2048]) ['check_pulse'] tensor([2]) tensor([174]) tensor([307]) tensor([5.8370]) tensor([10.2527]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 133, 2048]) ['check_responsiveness'] tensor([1]) tensor([174]) tensor([307]) tensor([5.8370]) tensor([10.2527]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 603, 2048]) ['chest_compressions'] tensor([4]) tensor([307]) tensor([910]) tensor([10.2530]) tensor([30.3920]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 58, 2048]) ['place_bvm'] tensor([13]) tensor([910]) tensor([968]) tensor([30.3920]) tensor([32.3193]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 136, 2048]) ['ventilate_patient'] tensor([14]) tensor([968]) tensor([1104]) tensor([32.3190]) tensor([36.8621]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 593, 2048]) ['chest_compressions'] tensor([4]) tensor([1104]) tensor([1697]) tensor([36.8620]) tensor([56.6295]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 271, 2048]) ['attach_defib_pads'] tensor([8]) tensor([1697]) tensor([1968]) tensor([56.6300]) tensor([65.6712]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 102, 2048]) ['turn_on_aed'] tensor([7]) tensor([1968]) tensor([2070]) tensor([65.6710]) tensor([69.0849]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 321, 2048]) ['chest_compressions'] tensor([4]) tensor([2070]) tensor([2391]) tensor([69.0850]) tensor([79.7874]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 63, 2048]) ['place_bvm'] tensor([13]) tensor([2391]) tensor([2454]) tensor([79.7870]) tensor([81.8847]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 96, 2048]) ['ventilate_patient'] tensor([14]) tensor([2454]) tensor([2550]) tensor([81.8850]) tensor([85.0915]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 554, 2048]) ['chest_compressions'] tensor([4]) tensor([2550]) tensor([3104]) tensor([85.0920]) tensor([103.5949]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 62, 2048]) ['place_bvm'] tensor([13]) tensor([3104]) tensor([3166]) tensor([103.5950]) tensor([105.6467]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 140, 2048]) ['ventilate_patient'] tensor([14]) tensor([3166]) tensor([3306]) tensor([105.6470]) tensor([110.3366]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 493, 2048]) ['clear_for_analysis'] tensor([9]) tensor([3306]) tensor([3799]) tensor([110.3370]) tensor([126.7688]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 154, 2048]) ['clear_for_shock'] tensor([10]) tensor([3799]) tensor([3953]) tensor([126.7690]) tensor([131.9257]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 166, 2048]) ['administer_shock_aed'] tensor([11]) tensor([3953]) tensor([4119]) tensor([131.9260]) tensor([137.4649]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 526, 2048]) ['chest_compressions'] tensor([4]) tensor([4119]) tensor([4645]) tensor([137.4650]) tensor([155.0135]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 67, 2048]) ['place_bvm'] tensor([13]) tensor([4645]) tensor([4712]) tensor([155.0140]) tensor([157.2375]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 99, 2048]) ['ventilate_patient'] tensor([14]) tensor([4712]) tensor([4811]) tensor([157.2380]) tensor([160.5604]) ['ng8'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 95, 2048]) ['approach_patient'] tensor([0]) tensor([0]) tensor([95]) tensor([0]) tensor([3.1821]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 68, 2048]) ['check_responsiveness'] tensor([1]) tensor([95]) tensor([163]) tensor([3.1820]) tensor([5.4552]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 123, 2048]) ['check_pulse'] tensor([2]) tensor([163]) tensor([286]) tensor([5.4550]) tensor([9.5614]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 1841, 2048]) ['chest_compressions'] tensor([4]) tensor([286]) tensor([2127]) tensor([9.5610]) tensor([71]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 31, 2048]) ['request_assistance'] tensor([6]) tensor([888]) tensor([919]) tensor([29.6550]) tensor([30.6810]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 7, 2048]) ['no_action'] tensor([15]) tensor([919]) tensor([926]) tensor([30.6810]) tensor([30.9054]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 51, 2048]) ['place_bvm'] tensor([13]) tensor([926]) tensor([977]) tensor([30.9054]) tensor([32.6090]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 118, 2048]) ['no_action'] tensor([15]) tensor([977]) tensor([1095]) tensor([32.6090]) tensor([36.5420]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 462, 2048]) ['ventilate_patient'] tensor([14]) tensor([1095]) tensor([1557]) tensor([36.5420]) tensor([51.9671]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 133, 2048]) ['no_action'] tensor([15]) tensor([1557]) tensor([1690]) tensor([51.9671]) tensor([56.4054]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 66, 2048]) ['ventilate_patient'] tensor([14]) tensor([1690]) tensor([1756]) tensor([56.4054]) tensor([58.6070]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 381, 2048]) ['no_action'] tensor([15]) tensor([1756]) tensor([2137]) tensor([58.6070]) tensor([71.3054]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 50, 2048]) ['ventilate_patient'] tensor([14]) tensor([2137]) tensor([2187]) tensor([71.3054]) tensor([72.9930]) ['ng9'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 1435, 2048]) ['no_action'] tensor([15]) tensor([0]) tensor([1435]) tensor([0]) tensor([47.9106]) ['wa1'] ['1']\n",
      "****==================================================****\n",
      "torch.Size([1, 60, 2048]) ['approach_patient'] tensor([0]) tensor([1435]) tensor([1495]) tensor([47.9110]) tensor([49.8994]) ['wa1'] ['1']\n",
      "****==================================================****\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the data loader and print the shape of the batch\n",
    "for batch in data_loader:\n",
    "    # print(batch['frames'].shape, batch['audio'].shape,batch['resnet'].shape,batch['resnet_exo'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\n",
    "    print(batch['resnet'].shape, batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\n",
    "    print(\"*\"*4 + \"=\"*50 + \"*\"*4)\n",
    "    # break\n",
    "    \n",
    "    # audio_tensor = batch['audio'][0]\n",
    "    # #transpose\n",
    "    # audio_tensor = audio_tensor.transpose(0,1)\n",
    "    # torchaudio.save(\"./visualizations/audio.wav\", audio_tensor,48000)\n",
    "    # break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchaudio feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "# Example batch of audio clips (batch, samples, channels)\n",
    "audio_clips = batch['audio']  # Assume shape [batch, samples, channels]\n",
    "\n",
    "# Parameters for feature extraction\n",
    "sample_rate = 48000  # Adjust based on your dataset\n",
    "n_mels = 64  # Number of Mel filter banks\n",
    "hop_length = 512\n",
    "n_fft = 1024\n",
    "\n",
    "# MelSpectrogram transform\n",
    "mel_spectrogram = transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mels=n_mels,\n",
    "    hop_length=hop_length,\n",
    "    n_fft=n_fft\n",
    ")\n",
    "\n",
    "# Process audio for one channel (if you want stereo/multi-channel, handle each channel accordingly)\n",
    "batch_size, num_samples, num_channels = audio_clips.shape\n",
    "\n",
    "# If using mono audio (process first channel as an example)\n",
    "mel_features = mel_spectrogram(audio_clips[:, :, 0])  # Shape: [batch, n_mels, time]\n",
    "\n",
    "# To get the desired shape [batch, samples, feature_dim], we treat the time axis as the \"samples\"\n",
    "# Here, n_mels will be the feature dimension and time will be the new samples axis\n",
    "mel_features = mel_features.permute(0, 2, 1)  # Shape: [batch, time(samples), n_mels(feature_dim)]\n",
    "\n",
    "print(f\"Mel-spectrogram features shape: {mel_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual channel mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example batch of audio clips (batch, samples, channels)\n",
    "audio_clips = batch['audio']  # Assume shape [batch, samples, channels]\n",
    "\n",
    "# Parameters for feature extraction\n",
    "sample_rate = 48000  # Adjust based on your dataset\n",
    "n_mels = 64  # Number of Mel filter banks\n",
    "hop_length = 512\n",
    "n_fft = 1024\n",
    "\n",
    "# MelSpectrogram transform\n",
    "mel_spectrogram = transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mels=n_mels,\n",
    "    hop_length=hop_length,\n",
    "    n_fft=n_fft\n",
    ")\n",
    "\n",
    "# Extract Mel-spectrogram for both channels\n",
    "mel_spec_left = mel_spectrogram(audio_clips[:, :, 0])  # Left channel\n",
    "mel_spec_right = mel_spectrogram(audio_clips[:, :, 1])  # Right channel\n",
    "\n",
    "mel_spec_combined = torch.cat((mel_spec_left, mel_spec_right), dim=-1)  # Shape: [n_mels, time*2]\n",
    "print(f\"Mel-spectrogram combined shape: {mel_spec_combined.shape}\")\n",
    "\n",
    "\n",
    "# Convert to log scale\n",
    "mel_spec_left_db = transforms.AmplitudeToDB()(mel_spec_left)\n",
    "mel_spec_right_db = transforms.AmplitudeToDB()(mel_spec_right)\n",
    "\n",
    "\n",
    "# Concatenate the spectrograms side by side (along the time axis)\n",
    "mel_spec_combined_db = torch.cat((mel_spec_left_db, mel_spec_right_db), dim=-1)  # Shape: [n_mels, time*2]\n",
    "print(f\"Mel-spectrogram combined shape: {mel_spec_combined_db.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example batch of audio clips (batch, samples, channels)\n",
    "audio_clips = batch['audio']  # Assume shape [batch, samples, channels]\n",
    "\n",
    "# Parameters for feature extraction\n",
    "sample_rate = 16000  # Adjust based on your dataset\n",
    "n_mels = 64  # Number of Mel filter banks\n",
    "hop_length = 512\n",
    "n_fft = 1024\n",
    "\n",
    "# MelSpectrogram transform\n",
    "mel_spectrogram = transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mels=n_mels,\n",
    "    hop_length=hop_length,\n",
    "    n_fft=n_fft\n",
    ")\n",
    "\n",
    "# Extract Mel-spectrogram for a single channel (first sample, first channel as an example)\n",
    "mel_spec = mel_spectrogram(audio_clips[0, :, 0])  # Shape: [n_mels, time]\n",
    "\n",
    "# Convert to log scale for better visualization\n",
    "mel_spec_db = transforms.AmplitudeToDB()(mel_spec)\n",
    "\n",
    "# Plotting the Mel-spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(mel_spec_db.numpy(), cmap='viridis', aspect='auto', origin='lower')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel-Spectrogram (Log-Scale)\")\n",
    "plt.xlabel(\"Time (frames)\")\n",
    "plt.ylabel(\"Mel Frequency Bins\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert frames tensor to video\n",
    "frames = batch['frames'][0]\n",
    "print(frames.shape) # (num_frames, 3, 224, 224)\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Example tensor (num_frames, 3, 224, 224)\n",
    "frames = batch['frames'][0]\n",
    "\n",
    "# Convert from (num_frames, 3, 224, 224) to (num_frames, 224, 224, 3)\n",
    "frames = frames.permute(0, 2, 3, 1).cpu().numpy()  # (num_frames, 224, 224, 3)\n",
    "\n",
    "# Normalize pixel values from [0, 1] or [-1, 1] if necessary\n",
    "# frames = (frames * 255).astype(np.uint8)\n",
    "\n",
    "# convert bgr to rgb\n",
    "# Define the codec and create a VideoWriter object\n",
    "output_file = './visualizations/video.mp4'\n",
    "fps = 30  # Frames per second\n",
    "height, width = frames.shape[1:3]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "\n",
    "video_writer = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "# Write each frame to the video\n",
    "for frame in frames:\n",
    "    video_writer.write(frame)\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n",
    "\n",
    "print(f\"Video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_rgb_flow_imu_depth(rgb_frames, flow_frames, rgb_feature, imu_data, depth_data):\n",
    "    # Assume rgb_frames is of shape (frames, height, width, 3) and flow_frames is (frames, 1024)\n",
    "    # imu_data is of shape (frames, 3) and depth_data is (frames, 1)\n",
    "    print(rgb_frames.shape, flow_frames.shape, rgb_feature.shape, imu_data.shape, depth_data.shape)\n",
    "    num_frames = rgb_frames.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots( 5, num_frames, figsize=(num_frames * 5, 25))\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        rgb_image = rgb_frames[i].permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        # Plot RGB frame\n",
    "        axes[0, i].imshow(rgb_image)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(f\"RGB Frame {i+1}\")\n",
    "        \n",
    "        # Plot flow data as a heatmap for the corresponding frame\n",
    "        axes[1, i].imshow(flow_frames[i].reshape(32, 32), cmap='viridis', aspect='auto')  # assuming 1024 is reshaped to 32x32\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(f\"Flow Feature {i+1}\")\n",
    "        \n",
    "        # Plot the RGB feature as a heatmap\n",
    "        rgb_feature_image = rgb_feature[i].cpu().numpy().reshape(32, 32)  # Reshape to 32x32\n",
    "        axes[2, i].imshow(rgb_feature_image, cmap='plasma', aspect='auto')\n",
    "        axes[2, i].axis('off')\n",
    "        axes[2, i].set_title(f\"RGB Feature {i+1}\")\n",
    "        \n",
    "        # Plot smartwatch IMU data (3-axis)\n",
    "        # Plot smartwatch IMU data (3-axis: x, y, z)\n",
    "        imu_time_series = imu_data[i].cpu().numpy()  # Shape (3,)\n",
    "        axes[3, i].plot([0, 1, 2], imu_time_series, marker='o', label=['X', 'Y', 'Z'])\n",
    "        axes[3, i].set_xticks([0, 1, 2])\n",
    "        axes[3, i].set_xticklabels(['X', 'Y', 'Z'])\n",
    "        axes[3, i].set_title(f\"IMU Data {i+1}\")\n",
    "        \n",
    "        # Plot depth sensor data\n",
    "        depth_value = depth_data[i].cpu().numpy()\n",
    "        axes[4, i].bar(0, depth_value, width=0.5)\n",
    "        axes[4, i].set_ylim(0, np.max(depth_data.cpu().numpy()))  # Adjust y-axis based on max depth value\n",
    "        axes[4, i].set_title(f\"Depth Sensor {i+1}\")\n",
    "        axes[4, i].set_xticks([])  # No x-ticks since it's a single bar\n",
    "\n",
    "        # Save each figure\n",
    "        plt.savefig(f\"./visualizations/frame_{i}.png\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with your batch data\n",
    "# batch = next(iter(data_loader))\n",
    "print(batch['frames'].shape, batch['audio'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch_imu'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\n",
    "# torch.Size([1, 82, 3, 224, 224]) torch.Size([1, 133120, 2]) torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024]) torch.Size([1, 82, 3]) torch.Size([1, 82, 1]) ['place_bvm'] tensor([13]) tensor([2416]) tensor([2498]) tensor([80.6273]) tensor([83.3773]) ['ng8'] ['7']\n",
    "\n",
    "rgb_frames= batch['frames'][0]\n",
    "flow_frames = batch['flow'][0]\n",
    "rgb_feature = batch['rgb'][0]\n",
    "imu_data = batch['smartwatch_imu'][0]\n",
    "depth_data = batch['depth_sensor'][0]\n",
    "\n",
    "plot_index = min(rgb_frames.shape[0], flow_frames.shape[0], rgb_feature.shape[0], imu_data.shape[0], depth_data.shape[0])\n",
    "\n",
    "if(plot_index > 1):\n",
    "    plot_index = 15\n",
    "    plot_rgb_flow_imu_depth(rgb_frames[0:plot_index], flow_frames[0:plot_index], rgb_feature[0:plot_index],imu_data[0:plot_index], depth_data[0:plot_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def animate_rgb_flow_imu_depth(rgb_frames, flow_frames, additional_rgb, imu_data, depth_data):\n",
    "    num_frames = rgb_frames.shape[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(6, 15))  # 5 rows for RGB, Flow, Additional RGB, IMU, and Depth\n",
    "\n",
    "    # Initialize the images that will be updated\n",
    "    rgb_im = axes[0].imshow(np.zeros((rgb_frames.shape[2], rgb_frames.shape[3], 3)))\n",
    "    flow_im = axes[1].imshow(np.zeros((32, 32)), cmap='viridis')\n",
    "    add_rgb_im = axes[2].imshow(np.zeros((32, 32)), cmap='plasma')\n",
    "    \n",
    "    # For IMU and Depth, we initialize placeholders\n",
    "    imu_plot_x, = axes[3].plot([], [], 'r-', label='X')\n",
    "    imu_plot_y, = axes[3].plot([], [], 'g-', label='Y')\n",
    "    imu_plot_z, = axes[3].plot([], [], 'b-', label='Z')\n",
    "    depth_plot = axes[4].bar([0], [0], width=0.5)  # Single bar for depth value\n",
    "\n",
    "    axes[0].set_title('RGB Frame')\n",
    "    axes[1].set_title('Flow Feature')\n",
    "    axes[2].set_title('Additional RGB Feature')\n",
    "    axes[3].set_title('IMU Data (X, Y, Z)')\n",
    "    axes[4].set_title('Depth Sensor Data')\n",
    "    \n",
    "        # Set a fixed Y-axis range for IMU data\n",
    "    imu_y_range = (-10, 10)  # Adjust this range based on your IMU data values\n",
    "    axes[3].set_ylim(imu_y_range)  # Set a fixed range for the IMU Y-axis\n",
    "\n",
    "\n",
    "    # Turn off axis for cleaner visuals\n",
    "    for ax in axes:\n",
    "        ax.axis('off') if ax != axes[3] else ax.set_xticks([])  # Don't turn off axis for IMU\n",
    "\n",
    "    # IMU axis should show the three axes, so enable labels for this plot\n",
    "    axes[3].legend(loc='upper right')\n",
    "\n",
    "    def update(frame):\n",
    "        # Update RGB data\n",
    "        rgb_image = rgb_frames[frame].permute(1, 2, 0).cpu().numpy()\n",
    "        rgb_im.set_data(rgb_image)\n",
    "        \n",
    "        # Update flow data\n",
    "        flow_image = flow_frames[frame].cpu().numpy().reshape(32, 32)\n",
    "        flow_im.set_data(flow_image)\n",
    "        flow_im.set_clim(vmin=np.min(flow_image), vmax=np.max(flow_image))  # Set dynamic color range\n",
    "        \n",
    "        # Update additional RGB data\n",
    "        additional_rgb_image = additional_rgb[frame].cpu().numpy().reshape(32, 32)\n",
    "        add_rgb_im.set_data(additional_rgb_image)\n",
    "        add_rgb_im.set_clim(vmin=np.min(additional_rgb_image), vmax=np.max(additional_rgb_image))  # Set dynamic color range\n",
    "        \n",
    "        # Update IMU data\n",
    "        imu_values = imu_data[frame].cpu().numpy()  # shape (3,)\n",
    "        imu_plot_x.set_data([0, 1], [0, imu_values[0]])  # X-axis value\n",
    "        imu_plot_y.set_data([0, 1], [0, imu_values[1]])  # Y-axis value\n",
    "        imu_plot_z.set_data([0, 1], [0, imu_values[2]])  # Z-axis value\n",
    "\n",
    "        # Update depth sensor data\n",
    "        depth_value = depth_data[frame].cpu().numpy().item()  # Assuming depth_data has shape (num_frames, 1)\n",
    "        depth_plot[0].set_height(depth_value)\n",
    "        depth_plot[0].set_y(depth_value)\n",
    "\n",
    "        return [rgb_im, flow_im, add_rgb_im, imu_plot_x, imu_plot_y, imu_plot_z] + list(depth_plot)\n",
    "\n",
    "    # Create animation\n",
    "    ani = animation.FuncAnimation(fig, update, frames=num_frames, interval=200, blit=True)\n",
    "    \n",
    "    # Save as GIF using Pillow backend\n",
    "    ani.save('./visualizations/animated_video_with_imu_depth.gif', writer='pillow', fps=30)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_index = min(rgb_frames.shape[0], flow_frames.shape[0], rgb_feature.shape[0], imu_data.shape[0], depth_data.shape[0])\n",
    "\n",
    "# Example usage with your batch data\n",
    "animate_rgb_flow_imu_depth(rgb_frames[0:plot_index], flow_frames[0:plot_index], rgb_feature[0:plot_index], imu_data[0:plot_index], depth_data[0:plot_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumbling window frame wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import math\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from torchvision import transforms\n",
    "# from collections import OrderedDict\n",
    "# import itertools\n",
    "# from torchvision.io import VideoReader\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "# ])\n",
    "\n",
    "# def collate_fn(batch, frames_per_clip=30):\n",
    "#     # Initialize empty lists for all possible modalities\n",
    "#     padded_audio_clips = []\n",
    "#     padded_flow_clips = []\n",
    "#     padded_rgb_clips = []\n",
    "#     padded_resnet_clips = []\n",
    "#     padded_resnet_exo_clips = []  # Added for resnet_exo modality\n",
    "#     padded_smartwatch_clips = []\n",
    "#     padded_depth_sensor_clips = []\n",
    "#     keystep_labels = []\n",
    "#     keystep_ids = []\n",
    "#     start_frames = []\n",
    "#     end_frames = []\n",
    "#     start_ts = []\n",
    "#     end_ts = []\n",
    "#     subject_ids = []\n",
    "#     trial_ids = []\n",
    "\n",
    "#     # Initialize max lengths for each modality, check if each is available\n",
    "#     max_flow_len = max([clip['flow'].shape[0] for clip in batch if isinstance(clip.get('flow', None), torch.Tensor)], default=0)\n",
    "#     max_audio_len = max([clip['audio'].shape[-1] for clip in batch if isinstance(clip.get('audio', None), torch.Tensor)], default=0)\n",
    "#     max_rgb_len = max([clip['rgb'].shape[0] for clip in batch if isinstance(clip.get('rgb', None), torch.Tensor)], default=0)\n",
    "#     max_resnet_len = max([clip['resnet'].shape[0] for clip in batch if isinstance(clip.get('resnet', None), torch.Tensor)], default=0)\n",
    "#     max_resnet_exo_len = max([clip['resnet_exo'].shape[0] for clip in batch if isinstance(clip.get('resnet_exo', None), torch.Tensor)], default=0)  # Added for resnet_exo modality\n",
    "#     max_smartwatch_len = max([clip['smartwatch'].shape[0] for clip in batch if isinstance(clip.get('smartwatch', None), torch.Tensor)], default=0)\n",
    "#     max_depth_sensor_len = max([clip['depth_sensor'].shape[0] for clip in batch if isinstance(clip.get('depth_sensor', None), torch.Tensor)], default=0)\n",
    "\n",
    "#     # print(\"max_flow_len:\",max_flow_len)\n",
    "#     # print(\"max_audio_len:\",max_audio_len)\n",
    "#     # print(\"max_rgb_len:\",max_rgb_len)\n",
    "#     # print(\"max_resnet_len:\",max_resnet_len)\n",
    "#     # print(\"max_resnet_exo_len:\",max_resnet_exo_len)\n",
    "#     # print(\"max_smartwatch_len:\",max_smartwatch_len)\n",
    "#     # print(\"max_depth_sensor_len:\",max_depth_sensor_len)\n",
    "    \n",
    "#     pad_length = 0\n",
    "#     for b in batch:\n",
    "#         # print(\"b:\",b)\n",
    "#         # Pad audio if available\n",
    "#         if 'audio' in b and isinstance(b['audio'], torch.Tensor):\n",
    "#             audio_clip = b['audio']\n",
    "#             audio_pad_size = max_audio_len - audio_clip.shape[0]\n",
    "#             if audio_pad_size > 0:\n",
    "#                 audio_pad = torch.zeros((audio_pad_size, *audio_clip.shape[1:]))\n",
    "#                 audio_clip = torch.cat([audio_clip, audio_pad], dim=0)\n",
    "#             padded_audio_clips.append(audio_clip)\n",
    "\n",
    "\n",
    "#         # Pad flow data if available\n",
    "#         if 'flow' in b and isinstance(b['flow'], torch.Tensor):\n",
    "#             flow_clip = b['flow']\n",
    "#             flow_pad_size = max_flow_len - flow_clip.shape[0]\n",
    "#             if flow_pad_size > 0:\n",
    "#                 flow_pad = torch.zeros((flow_pad_size, *flow_clip.shape[1:]))\n",
    "#                 flow_clip = torch.cat([flow_clip, flow_pad], dim=0)\n",
    "#             padded_flow_clips.append(flow_clip)\n",
    "\n",
    "#         # Pad rgb data if available\n",
    "#         if 'rgb' in b and isinstance(b['rgb'], torch.Tensor):\n",
    "#             rgb_clip = b['rgb']\n",
    "#             rgb_pad_size = max_rgb_len - rgb_clip.shape[0]\n",
    "#             if rgb_pad_size > 0:\n",
    "#                 rgb_pad = torch.zeros((rgb_pad_size, *rgb_clip.shape[1:]))\n",
    "#                 rgb_clip = torch.cat([rgb_clip, rgb_pad], dim=0)\n",
    "#             padded_rgb_clips.append(rgb_clip)\n",
    "\n",
    "#         # Pad resnet data if available\n",
    "#         if 'resnet' in b and isinstance(b['resnet'], torch.Tensor):\n",
    "#             resnet_clip = b['resnet']\n",
    "#             resnet_pad_size = max_resnet_len - resnet_clip.shape[0]\n",
    "#             if resnet_pad_size > 0:\n",
    "#                 resnet_pad = torch.zeros((resnet_pad_size, *resnet_clip.shape[1:]))\n",
    "#                 resnet_clip = torch.cat([resnet_clip, resnet_pad], dim=0)\n",
    "#             padded_resnet_clips.append(resnet_clip)\n",
    "\n",
    "#         # Pad resnet_exo data if available\n",
    "#         if 'resnet_exo' in b and isinstance(b['resnet_exo'], torch.Tensor):\n",
    "#             resnet_exo_clip = b['resnet_exo']\n",
    "#             resnet_exo_pad_size = max_resnet_exo_len - resnet_exo_clip.shape[0]\n",
    "#             if resnet_exo_pad_size > 0:\n",
    "#                 resnet_exo_pad = torch.zeros((resnet_exo_pad_size, *resnet_exo_clip.shape[1:]))\n",
    "#                 resnet_exo_clip = torch.cat([resnet_exo_clip, resnet_exo_pad], dim=0)\n",
    "#             padded_resnet_exo_clips.append(resnet_exo_clip)\n",
    "\n",
    "#         # Pad smartwatch data if available\n",
    "#         if 'smartwatch' in b and isinstance(b['smartwatch'], torch.Tensor):\n",
    "#             smartwatch_clip = b['smartwatch']\n",
    "#             if max_smartwatch_len > 0:\n",
    "#                 smartwatch_pad_size = max_smartwatch_len - smartwatch_clip.shape[0]\n",
    "#                 if smartwatch_pad_size > 0:\n",
    "#                     smartwatch_pad = torch.zeros((smartwatch_clip.shape[0], smartwatch_pad_size))\n",
    "#                     smartwatch_clip = torch.cat([smartwatch_clip, smartwatch_pad], dim=0)\n",
    "#             padded_smartwatch_clips.append(smartwatch_clip)\n",
    "\n",
    "#         # Pad depth_sensor data if available\n",
    "#         if 'depth_sensor' in b and isinstance(b['depth_sensor'], torch.Tensor):\n",
    "#             depth_sensor_clip = b['depth_sensor']\n",
    "#             if max_depth_sensor_len > 0:\n",
    "#                 depth_sensor_pad_size = max_depth_sensor_len - depth_sensor_clip.shape[0]\n",
    "#                 if depth_sensor_pad_size > 0:\n",
    "#                     depth_sensor_pad = torch.zeros((depth_sensor_clip.shape[0], depth_sensor_pad_size))\n",
    "#                     depth_sensor_clip = torch.cat([depth_sensor_clip, depth_sensor_pad], dim=0)\n",
    "#             padded_depth_sensor_clips.append(depth_sensor_clip)\n",
    "\n",
    "\n",
    "#         pad_length = frames_per_clip - len(b['keystep_id']) \n",
    "        \n",
    "#         if pad_length > 0:\n",
    "#             # repeat last element of keystep_id and keystep_label\n",
    "#             b['keystep_id'] = b['keystep_id'] + [b['keystep_id'][-1]]*pad_length\n",
    "#             b['start_frame'] = b['start_frame'] + [b['start_frame'][-1]]*pad_length\n",
    "#             b['end_frame'] = b['end_frame'] + [b['end_frame'][-1]]*pad_length\n",
    "#             b['start_t'] = b['start_t'] + [b['start_t'][-1]]*pad_length\n",
    "#             b['end_t'] = b['end_t'] + [b['end_t'][-1]]*pad_length\n",
    "        \n",
    "#         # Collect other fields\n",
    "#         keystep_labels.append(b['keystep_label'])\n",
    "#         keystep_ids.append(b['keystep_id'])\n",
    "#         start_frames.append(b['start_frame'])\n",
    "#         end_frames.append(b['end_frame'])\n",
    "#         start_ts.append(b['start_t'])\n",
    "#         end_ts.append(b['end_t'])\n",
    "#         subject_ids.append(b['subject_id'])\n",
    "#         trial_ids.append(b['trial_id'])\n",
    "\n",
    "#     output = {\n",
    "#         'keystep_label': keystep_labels,\n",
    "#         'keystep_id': torch.tensor(keystep_ids),\n",
    "#         'start_frame': torch.tensor(start_frames),\n",
    "#         'end_frame': torch.tensor(end_frames),\n",
    "#         'start_t': torch.tensor(start_ts),\n",
    "#         'end_t': torch.tensor(end_ts),\n",
    "#         'subject_id': subject_ids,\n",
    "#         'trial_id': trial_ids\n",
    "#     }\n",
    "\n",
    "#     # Only include modality data if it exists\n",
    "#     output['audio'] = torch.stack(padded_audio_clips) if padded_audio_clips else torch.zeros(0)\n",
    "#     output['flow'] = torch.stack(padded_flow_clips) if padded_flow_clips else torch.zeros(0)\n",
    "#     output['rgb'] = torch.stack(padded_rgb_clips) if padded_rgb_clips else torch.zeros(0)\n",
    "#     output['resnet'] = torch.stack(padded_resnet_clips) if padded_resnet_clips else torch.zeros(0)\n",
    "#     output['resnet_exo'] = torch.stack(padded_resnet_exo_clips) if padded_resnet_exo_clips else torch.zeros(0)  # Added for resnet_exo\n",
    "#     output['smartwatch'] = torch.stack(padded_smartwatch_clips) if padded_smartwatch_clips else torch.zeros(0)\n",
    "#     output['depth_sensor'] = torch.stack(padded_depth_sensor_clips) if padded_depth_sensor_clips else torch.zeros(0)\n",
    "\n",
    "#     return output\n",
    "\n",
    "\n",
    "# class WindowEgoExoEMSDataset(Dataset):\n",
    "#     def __init__(self, annotation_file, data_base_path, fps, \n",
    "#                 frames_per_clip=30, transform=None,\n",
    "#                 data_types=['resnet']):\n",
    "        \n",
    "#         self.annotation_file = annotation_file\n",
    "#         self.data_base_path = data_base_path\n",
    "#         self.fps = fps\n",
    "#         self.frames_per_clip = frames_per_clip  # Store frames_per_clip\n",
    "#         self.transform = transform\n",
    "#         self.data = []\n",
    "#         self.clip_indices = []  # This will store (item_idx, clip_idx) tuples\n",
    "#         self.data_types = data_types\n",
    "        \n",
    "#         self.data_dict = None\n",
    "#         self._load_annotations()\n",
    "#         self._split_windows()\n",
    "\n",
    "#     def _load_annotations(self):\n",
    "#         with open(self.annotation_file, 'r') as f:\n",
    "#             annotations = json.load(f)\n",
    "        \n",
    "#         subject_dict = {}\n",
    "#         for subject in annotations['subjects']:\n",
    "#             trial_dict ={}\n",
    "#             for trial in subject['trials']:\n",
    "#                 avail_streams = trial['streams']\n",
    "                \n",
    "#                 # Initialize paths to None by default\n",
    "#                 audio_path = None\n",
    "#                 flow_path = None\n",
    "#                 rgb_path = None\n",
    "#                 resnet_path = None\n",
    "#                 resnet_exo_path = None  # Added for resnet_exo modality\n",
    "#                 smartwatch_path = None\n",
    "#                 depth_sensor_path = None\n",
    "\n",
    "#                 # Check for each data type and retrieve the corresponding file path\n",
    "#                 if 'audio' in self.data_types:\n",
    "#                     audio_path = avail_streams.get('egocam_rgb_audio', {}).get('file_path', None)\n",
    "#                 if 'flow' in self.data_types:\n",
    "#                     flow_path = avail_streams.get('i3d_flow', {}).get('file_path', None)\n",
    "#                 if 'rgb' in self.data_types:\n",
    "#                     rgb_path = avail_streams.get('i3d_rgb', {}).get('file_path', None)\n",
    "#                 if 'resnet' in self.data_types:\n",
    "#                     resnet_path = avail_streams.get('resnet50', {}).get('file_path', None)\n",
    "#                 if 'resnet_exo' in self.data_types:\n",
    "#                     resnet_exo_path = avail_streams.get('resnet50-exo', {}).get('file_path', None)  # Adjust key as needed\n",
    "#                 if 'smartwatch' in self.data_types:\n",
    "#                     smartwatch_path = avail_streams.get('smartwatch_imu', {}).get('file_path', None)\n",
    "#                 if 'depth_sensor' in self.data_types:\n",
    "#                     depth_sensor_path = avail_streams.get('vl6180_ToF_depth', {}).get('file_path', None)\n",
    "\n",
    "#                 # Skip the trial if any required data type is not available\n",
    "#                 if ('flow' in self.data_types and not flow_path) or \\\n",
    "#                 ('audio' in self.data_types and not audio_path) or \\\n",
    "#                 ('rgb' in self.data_types and not rgb_path) or \\\n",
    "#                 ('resnet' in self.data_types and not resnet_path) or \\\n",
    "#                 ('resnet_exo' in self.data_types and not resnet_exo_path) or \\\n",
    "#                 ('smartwatch' in self.data_types and not smartwatch_path) or \\\n",
    "#                 ('depth_sensor' in self.data_types and not depth_sensor_path):\n",
    "#                     print(f\"[Warning] Skipping trial {trial['trial_id']} for subject {subject['subject_id']} due to missing data\")\n",
    "#                     continue\n",
    "                \n",
    "#                 if audio_path or flow_path or rgb_path or resnet_path or resnet_exo_path or smartwatch_path or depth_sensor_path:\n",
    "#                     keysteps = trial['keysteps']\n",
    "#                     keysteps_dict = []\n",
    "#                     for step in keysteps:\n",
    "#                         start_frame = math.floor(step['start_t'] * self.fps)\n",
    "#                         end_frame = math.floor(step['end_t'] * self.fps)\n",
    "#                         label = step['label']\n",
    "#                         keystep_id = step['class_id']\n",
    "\n",
    "#                         data_dict = {}\n",
    "#                         if 'audio' in self.data_types:\n",
    "#                             data_dict['audio_path'] = os.path.join(self.data_base_path, audio_path)\n",
    "#                         if 'flow' in self.data_types:\n",
    "#                             data_dict['flow_path'] = os.path.join(self.data_base_path, flow_path)\n",
    "#                         if 'rgb' in self.data_types:\n",
    "#                             data_dict['rgb_path'] = os.path.join(self.data_base_path, rgb_path)\n",
    "#                         if 'resnet' in self.data_types:\n",
    "#                             data_dict['resnet_path'] = os.path.join(self.data_base_path, resnet_path)\n",
    "#                         if 'resnet_exo' in self.data_types:\n",
    "#                             data_dict['resnet_exo_path'] = os.path.join(self.data_base_path, resnet_exo_path)\n",
    "#                         if 'smartwatch' in self.data_types:\n",
    "#                             data_dict['smartwatch_path'] = os.path.join(self.data_base_path, smartwatch_path)\n",
    "#                         if 'depth_sensor' in self.data_types:\n",
    "#                             data_dict['depth_sensor_path'] = os.path.join(self.data_base_path, depth_sensor_path)\n",
    "#                         data_dict['start_frame'] = start_frame\n",
    "#                         data_dict['end_frame'] = end_frame\n",
    "#                         data_dict['start_t'] = step['start_t']\n",
    "#                         data_dict['end_t'] = step['end_t']\n",
    "#                         data_dict['keystep_label'] = label\n",
    "#                         data_dict['keystep_id'] = keystep_id\n",
    "#                         data_dict['subject'] = subject['subject_id']\n",
    "#                         data_dict['trial'] = trial['trial_id']\n",
    "\n",
    "#                         keysteps_dict.append(data_dict)\n",
    "#                         self.data.append(data_dict)\n",
    "\n",
    "#                         trial_dict[trial['trial_id']] = keysteps_dict\n",
    "#                 subject_dict[subject['subject_id']] = trial_dict\n",
    "\n",
    "#         self.data_dict = subject_dict\n",
    "\n",
    "#     def _split_windows(self):\n",
    "#         print(\"Splitting data to windows\")\n",
    "#         windowed_clips = []\n",
    "#         current_window = []  # Initialize an empty current window\n",
    "#         accumulated_frames = 0  # Track how many frames have been accumulated in the current window\n",
    "\n",
    "#         current_subject = None\n",
    "#         current_trial = None\n",
    "\n",
    "\n",
    "#         for i, item in enumerate(self.data):\n",
    "#             start_frame = item['start_frame']\n",
    "#             end_frame = item['end_frame']\n",
    "#             keystep_id = item['keystep_id']\n",
    "#             keystep_label = item['keystep_label']\n",
    "#             subject_id = item['subject']\n",
    "#             trial_id = item['trial']\n",
    "#             num_frames_total = end_frame - start_frame\n",
    "\n",
    "                \n",
    "#         # If the subject or trial changes, store the current window and reset it\n",
    "#             if subject_id != current_subject or trial_id != current_trial:\n",
    "#                 if len(current_window) > 0:\n",
    "#                     windowed_clips.append(current_window)\n",
    "#                 current_window = []  # Reset the current window\n",
    "#                 accumulated_frames = 0  # Reset the frame counter\n",
    "#                 current_subject = subject_id  # Update current subject\n",
    "#                 current_trial = trial_id  # Update current trial\n",
    "\n",
    "#             # Loop through frames from the start to the end of the current keystep\n",
    "#             for j in range(start_frame, end_frame):\n",
    "#                 frame_data = {}\n",
    "#                 frame_data['frame'] = j\n",
    "\n",
    "#                 # Copy the relevant data for the current frame\n",
    "#                 for key, value in item.items():\n",
    "#                     if isinstance(value, (int, float, str)):\n",
    "#                         frame_data[key] = value\n",
    "#                     elif isinstance(value, (list, np.ndarray)):\n",
    "#                         if len(value) == num_frames_total:\n",
    "#                             frame_data[key] = value[j - start_frame]\n",
    "#                     else:\n",
    "#                         frame_data[key] = value\n",
    "\n",
    "#                 # Append the current frame data to the window\n",
    "#                 current_window.append(frame_data)\n",
    "#                 accumulated_frames += 1\n",
    "\n",
    "\n",
    "#                 # Once we reach the window size, store the window and reset\n",
    "#                 if accumulated_frames == self.frames_per_clip:\n",
    "#                     windowed_clips.append(current_window)\n",
    "#                     current_window = []  # Reset the current window\n",
    "#                     accumulated_frames = 0  # Reset the frame counter\n",
    "\n",
    "#         # # dump the data to a file\n",
    "#         # with open('data.json', 'w') as f:\n",
    "#         #     json.dump(windowed_clips, f)\n",
    "            \n",
    "#         self.data = windowed_clips\n",
    "#         print(f\"Total windowed clips: {len(windowed_clips)}\")\n",
    "\n",
    "            \n",
    "\n",
    "#     def __len__(self):\n",
    "#         # The length should now be based on the number of clips, not items\n",
    "#         # total_clips = len(self.data) // self.frames_per_clip if self.frames_per_clip else len(self.data)\n",
    "#         # dump the data to a file\n",
    "#         # with open('data.json', 'w') as f:\n",
    "#         #     json.dump(self.data, f)\n",
    "#         total_clips = len(self.data)\n",
    "#         return total_clips\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         window = self.data[idx]\n",
    "#         # print(\"window\", window)\n",
    "\n",
    "#         first_frame_of_clip = window[0]['frame']\n",
    "#         last_frame_of_clip = window[-1]['frame']+1\n",
    "        \n",
    "#         # print(f\"getting clip {idx} with frame {first_frame_of_clip} to {last_frame_of_clip} of length ({last_frame_of_clip - first_frame_of_clip})\")\n",
    "\n",
    "#         # Initialize dictionaries to hold accumulated frames for each modality\n",
    "#         batch_audio = []\n",
    "#         batch_flow = []\n",
    "#         batch_rgb = []\n",
    "#         batch_resnet = []\n",
    "#         batch_resnet_exo = []\n",
    "#         batch_sw_acc = []\n",
    "#         batch_depth_sensor = []\n",
    "\n",
    "#         # Initialize lists for metadata\n",
    "#         keystep_labels = []\n",
    "#         keystep_ids = []\n",
    "#         start_frames = []\n",
    "#         end_frames = []\n",
    "#         start_ts = []\n",
    "#         end_ts = []\n",
    "#         subject_ids = []\n",
    "#         trial_ids = []\n",
    "\n",
    "\n",
    "#         # Initialize variables\n",
    "#         flow = torch.zeros(0)\n",
    "#         rgb = torch.zeros(0)\n",
    "#         resnet = torch.zeros(0)\n",
    "#         resnet_exo = torch.zeros(0)  # Added for resnet_exo modality\n",
    "#         sw_acc = torch.zeros(0)\n",
    "#         depth_sensor_readings = torch.zeros(0)\n",
    "\n",
    "#         # Load flow if available\n",
    "#         if 'audio' in self.data_types:\n",
    "#             audio_path = window[0]['audio_path']\n",
    "#             clip_start_t = first_frame_of_clip / self.fps\n",
    "#             clip_end_t = last_frame_of_clip / self.fps\n",
    "\n",
    "#             # print(f\"loading audio from {clip_start_t} to {clip_end_t} from file {audio_path}\")\n",
    "\n",
    "#             audio_reader = VideoReader(audio_path, \"audio\")\n",
    "#             audio_clips = []\n",
    "#             for audio_frame in itertools.takewhile(lambda x: x['pts'] <= clip_end_t, audio_reader.seek(clip_start_t)):\n",
    "#                 audio_clips.append(audio_frame['data'])\n",
    "#             audio_clips = torch.cat(audio_clips, dim=0) if audio_clips else torch.zeros(1, 0)\n",
    "\n",
    "#             # pad the flow tensor to the i\n",
    "#             batch_audio.append(audio_clips)\n",
    "\n",
    "\n",
    "#         if 'flow' in self.data_types:\n",
    "#             flow_path = window[0]['flow_path']\n",
    "#             flow_npy = np.load(flow_path)\n",
    "#             flow_length = len(flow_npy)\n",
    "#             flow = torch.from_numpy(np.load(flow_path))[first_frame_of_clip:last_frame_of_clip]\n",
    "#                 # pad the flow tensor to the i\n",
    "#             batch_flow.append(flow)\n",
    "\n",
    "#         # Load rgb if available\n",
    "#         if 'rgb' in self.data_types:\n",
    "#             rgb_path =  window[0]['rgb_path']\n",
    "#             rgb_npy = np.load(rgb_path)\n",
    "#             rgb_length = len(rgb_npy)\n",
    "#             rgb = torch.from_numpy(np.load(rgb_path))[first_frame_of_clip:last_frame_of_clip]\n",
    "#                 # pad the rgb tensor to the i\n",
    "#             batch_rgb.append(rgb)\n",
    "\n",
    "#         # Load resnet if available\n",
    "#         if 'resnet' in self.data_types:\n",
    "#             resnet_path =  window[0]['resnet_path']\n",
    "#             resnet_npy = np.load(resnet_path)\n",
    "#             resnet_length = len(resnet_npy)\n",
    "#             resnet = torch.from_numpy(np.load(resnet_path))[first_frame_of_clip:last_frame_of_clip]\n",
    "#             batch_resnet.append(resnet)\n",
    "\n",
    "#         # Load resnet_exo if available\n",
    "#         if 'resnet_exo' in self.data_types:\n",
    "#             resnet_exo_path =  window[0]['resnet_exo_path']\n",
    "#             resnet_exo = torch.from_numpy(np.load(resnet_exo_path))[first_frame_of_clip:last_frame_of_clip]\n",
    "#             batch_resnet_exo.append(resnet_exo)\n",
    "\n",
    "#         # Load smartwatch data if available\n",
    "#         if 'smartwatch' in self.data_types:\n",
    "#             smartwatch_path =  window[0]['smartwatch_path']\n",
    "#             with open(smartwatch_path, 'r') as f:\n",
    "#                 lines = f.readlines()[1:]\n",
    "#             sw_acc = [line.strip() for line in lines][first_frame_of_clip:last_frame_of_clip]\n",
    "#             acc_x = [float(l.split(',')[0]) for l in sw_acc]\n",
    "#             acc_y = [float(l.split(',')[1]) for l in sw_acc]\n",
    "#             acc_z = [float(l.split(',')[2]) for l in sw_acc]\n",
    "#             sw_acc = torch.from_numpy(np.array([acc_x, acc_y, acc_z])).float()\n",
    "#             sw_acc = sw_acc.permute(1, 0)  # (frames, channels)\n",
    "#             batch_sw_acc.append(sw_acc)\n",
    "\n",
    "#         # Load depth_sensor data if available\n",
    "#         if 'depth_sensor' in self.data_types:\n",
    "#             depth_sensor_path =  window[0]['depth_sensor_path']\n",
    "#             with open(depth_sensor_path, 'r') as f:\n",
    "#                 lines = f.readlines()[1:]\n",
    "#             depth_sensor_readings = [line.strip() for line in lines][first_frame_of_clip:last_frame_of_clip]\n",
    "#             depth_reading = [float(l.split(',')[0]) for l in depth_sensor_readings]\n",
    "#             depth_sensor_readings = torch.from_numpy(np.array([depth_reading])).float()\n",
    "#             depth_sensor_readings = depth_sensor_readings.permute(1, 0)\n",
    "#             batch_depth_sensor.append(depth_sensor_readings)\n",
    "\n",
    "#         for frame in window:\n",
    "#             # Accumulate metadata for each frame\n",
    "#             keystep_labels.append( frame['keystep_label'])\n",
    "#             keystep_ids.append( frame['keystep_id'])\n",
    "#             start_frames.append( frame['start_frame'])\n",
    "#             end_frames.append( frame['end_frame'])\n",
    "#             start_ts.append( frame['start_t'])\n",
    "#             end_ts.append( frame['end_t'])\n",
    "#             subject_ids.append( frame['subject'])\n",
    "#             trial_ids.append( frame['trial'])\n",
    "\n",
    "#         # print(\"batch_resnet:\",batch_resnet[0].shape)\n",
    "#         # Stack frames to form a batch of frames_per_clip\n",
    "#         output = {\n",
    "#             'audio': (batch_audio[0]) if batch_audio else torch.zeros(1,0),\n",
    "#             'flow': (batch_flow[0]) if batch_flow else torch.zeros(0),\n",
    "#             'rgb': (batch_rgb[0]) if batch_rgb else torch.zeros(0),\n",
    "#             'resnet': (batch_resnet[0]) if batch_resnet else torch.zeros(0),\n",
    "#             'resnet_exo': (batch_resnet_exo[0]) if batch_resnet_exo else torch.zeros(0),\n",
    "#             'smartwatch': (batch_sw_acc[0]) if batch_sw_acc else torch.zeros(0),\n",
    "#             'depth_sensor': (batch_depth_sensor[0]) if batch_depth_sensor else torch.zeros(0),\n",
    "\n",
    "#             # Metadata (individual per frame)\n",
    "#             'keystep_label': keystep_labels,\n",
    "#             'keystep_id': keystep_ids,\n",
    "#             'start_frame': start_frames,\n",
    "#             'end_frame': end_frames,\n",
    "#             'start_t': start_ts,\n",
    "#             'end_t': end_ts,\n",
    "#             'subject_id': subject_ids,\n",
    "#             'trial_id': trial_ids\n",
    "#         }\n",
    "\n",
    "#         return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data to windows\n",
      "Class stats: {'check_responsiveness': 28, 'check_pulse': 30, 'chest_compressions': 447, 'no_action': 170, 'request_aed': 6, 'turn_on_aed': 47, 'attach_defib_pads': 122, 'clear_for_analysis': 113, 'clear_for_shock': 50, 'administer_shock_aed': 42, 'open_airway': 1, 'ventilate_patient': 151, 'approach_patient': 3, 'place_bvm': 85, 'check_breathing': 26, 'request_assistance': 6}\n",
      "Total windowed clips: 1366\n",
      "Size of dataset: 1366\n",
      "Size of data loader: 1366\n",
      "loading video from 0.0 to 4.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torchvision/io/video_reader.py:233: UserWarning: Accurate seek is not implemented for pyav backend\n",
      "  warnings.warn(\"Accurate seek is not implemented for pyav backend\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([0]) tensor([120])\n",
      "loading video from 4.0 to 8.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([120]) tensor([240])\n",
      "loading video from 8.0 to 12.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([240]) tensor([360])\n",
      "loading video from 12.0 to 16.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([360]) tensor([480])\n",
      "loading video from 16.0 to 20.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([480]) tensor([600])\n",
      "loading video from 20.0 to 24.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([600]) tensor([720])\n",
      "loading video from 24.0 to 28.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([720]) tensor([840])\n",
      "loading video from 28.0 to 32.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([840]) tensor([960])\n",
      "loading video from 32.0 to 36.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([960]) tensor([1080])\n",
      "loading video from 36.0 to 40.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1080]) tensor([1200])\n",
      "loading video from 40.0 to 44.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1200]) tensor([1320])\n",
      "loading video from 44.0 to 48.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1320]) tensor([1440])\n",
      "loading video from 48.0 to 52.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1440]) tensor([1560])\n",
      "loading video from 52.0 to 56.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1560]) tensor([1680])\n",
      "loading video from 56.0 to 60.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1680]) tensor([1800])\n",
      "loading video from 60.0 to 64.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1800]) tensor([1920])\n",
      "loading video from 64.0 to 68.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([1920]) tensor([2040])\n",
      "loading video from 68.0 to 72.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2040]) tensor([2160])\n",
      "loading video from 72.0 to 76.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2160]) tensor([2280])\n",
      "loading video from 76.0 to 80.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2280]) tensor([2400])\n",
      "loading video from 80.0 to 84.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2400]) tensor([2520])\n",
      "loading video from 84.0 to 88.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2520]) tensor([2640])\n",
      "loading video from 88.0 to 92.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2640]) tensor([2760])\n",
      "loading video from 92.0 to 96.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2760]) tensor([2880])\n",
      "loading video from 96.0 to 100.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([2880]) tensor([3000])\n",
      "loading video from 100.0 to 104.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3000]) tensor([3120])\n",
      "loading video from 104.0 to 108.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3120]) tensor([3240])\n",
      "loading video from 108.0 to 112.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3240]) tensor([3360])\n",
      "loading video from 112.0 to 116.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3360]) tensor([3480])\n",
      "loading video from 116.0 to 120.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3480]) tensor([3600])\n",
      "loading video from 120.0 to 124.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3600]) tensor([3720])\n",
      "loading video from 124.0 to 128.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3720]) tensor([3840])\n",
      "loading video from 128.0 to 129.6 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/3/GoPro/GX010394_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([3840]) tensor([3888])\n",
      "loading video from 0.0 to 4.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/1/GoPro/GX010392_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([0]) tensor([120])\n",
      "loading video from 4.0 to 8.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/1/GoPro/GX010392_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([120]) tensor([240])\n",
      "loading video from 8.0 to 12.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/1/GoPro/GX010392_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([240]) tensor([360])\n",
      "loading video from 12.0 to 16.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/1/GoPro/GX010392_encoded_trimmed.mp4\n",
      "batch torch.Size([1, 120, 3, 224, 224]) torch.Size([1, 120]) 120 tensor([360]) tensor([480])\n",
      "loading video from 16.0 to 20.0 from file /standard/UVA-DSA/NIST EMS Project Data/EgoExoEMS_CVPR2025/Dataset/Final/ms1/cardiac_arrest/1/GoPro/GX010392_encoded_trimmed.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of data loader:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(data_loader))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# # Access a sample\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# # batch = next(iter(data_loader))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# # print(batch['resnet'].shape, batch['resnet_exo'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeystep_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeystep_label\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_start_frame\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_end_frame\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# print(\"batch\", batch['video'].shape, batch['keystep_id'].shape,batch['window_start_frame'], batch['window_end_frame'])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# print(batch['resnet'].shape, batch['audio'].shape, batch['resnet_exo'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# print(batch['resnet'].shape)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/sfs/weka/scratch/cjh9fw/Rivanna/2024/repos/EgoExoEMS/Dataset/pytorch_implementation/EgoExoEMS/EgoExoEMS/EgoExoEMS.py:944\u001b[0m, in \u001b[0;36mWindowEgoExoEMSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    942\u001b[0m video_reader \u001b[38;5;241m=\u001b[39m VideoReader(video_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    943\u001b[0m video_reader\u001b[38;5;241m.\u001b[39mseek(clip_start_t)\n\u001b[0;32m--> 944\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mtakewhile(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m clip_end_t, video_reader):\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m clip_start_t:\n\u001b[1;32m    946\u001b[0m         img_tensor \u001b[38;5;241m=\u001b[39m transform(frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/scratch/cjh9fw/conda/egoexoems/lib/python3.8/site-packages/torchvision/io/video_reader.py:192\u001b[0m, in \u001b[0;36mVideoReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m         frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m         pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(frame\u001b[38;5;241m.\u001b[39mpts \u001b[38;5;241m*\u001b[39m frame\u001b[38;5;241m.\u001b[39mtime_base)\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyav_stream:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "from EgoExoEMS.EgoExoEMS import *\n",
    "\n",
    "annotation_file = \"../../Annotations/splits/trials/train_split_segmentation.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "\n",
    "# train_annotation_file = \"../../Annotations/splits/keysteps/train_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "# val_annotation_file = \"../../Annotations/splits/keysteps/val_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "# test_annotation_file = \"../../Annotations/splits/keysteps/test_split.json\"  # A row for each video sample as: (VIDEO_PATH START_FRAME END_FRAME CLASS_ID)\n",
    "\n",
    "train_dataset = WindowEgoExoEMSDataset(annotation_file=annotation_file,\n",
    "                                data_base_path='',\n",
    "                                fps=30, frames_per_clip=120, transform=transform, data_types=[ 'video'])\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your dataset has a 'targets' attribute with class labels\n",
    "\n",
    "\n",
    "print(\"Size of dataset:\",len(train_dataset))\n",
    "\n",
    "# Use a partial function or lambda to pass the frames_per_clip argument\n",
    "collate_fn_with_args = partial(window_collate_fn, frames_per_clip=120)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_with_args)\n",
    "\n",
    "print(\"Size of data loader:\",len(data_loader))\n",
    "\n",
    "# # Access a sample\n",
    "# # batch = next(iter(data_loader))\n",
    "# # print(batch['resnet'].shape, batch['resnet_exo'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\n",
    "\n",
    "for idx,batch in enumerate(data_loader):\n",
    "    print(\"batch\", batch['video'].shape, batch['keystep_id'].shape, len(batch['keystep_label'][0]), batch['window_start_frame'], batch['window_end_frame'])\n",
    "    # print(\"batch\", batch['video'].shape, batch['keystep_id'].shape,batch['window_start_frame'], batch['window_end_frame'])\n",
    "    # print(batch['resnet'].shape, batch['audio'].shape, batch['resnet_exo'].shape, batch['flow'].shape, batch['rgb'].shape, batch['smartwatch'].shape, batch['depth_sensor'].shape , batch['keystep_label'], batch['keystep_id'], batch['start_frame'], batch['end_frame'],batch['start_t'], batch['end_t'],  batch['subject_id'], batch['trial_id'])\n",
    "    # print(batch['resnet'].shape)\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egoexoems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
