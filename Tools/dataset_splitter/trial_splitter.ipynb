{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train split to ../../Annotations/splits/trials/aaai26_train_split_cpr_quality.json\n",
      "Saved val split to ../../Annotations/splits/trials/aaai26_val_split_cpr_quality.json\n",
      "Saved test split to ../../Annotations/splits/trials/aaai26_test_split_cpr_quality.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# reproducibility\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "# task and paths\n",
    "task = \"classification\"  # \"classification\" or \"segmentation\"\n",
    "task = \"segmentation\"  # \"classification\" or \"segmentation\"\n",
    "task = \"cpr_quality\"  # \"classification\" or \"segmentation\"\n",
    "input_json_path = f'../../Annotations/aaai26_main_annotation_{task}.json'\n",
    "output_dir = '../../Annotations/splits/trials/'\n",
    "\n",
    "# ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# load the full annotation\n",
    "with open(input_json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# prepare split containers\n",
    "train_set = {\"subjects\": []}\n",
    "val_set   = {\"subjects\": []}\n",
    "test_set  = {\"subjects\": []}\n",
    "\n",
    "# split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio   = 0.2\n",
    "test_ratio  = 0.2\n",
    "\n",
    "def build_subject_split(subject, entries):\n",
    "    \"\"\"\n",
    "    Given a list of {'scenario_id', 'trial'} dicts, rebuild the nested subject entry.\n",
    "    \"\"\"\n",
    "    by_scenario = defaultdict(list)\n",
    "    for e in entries:\n",
    "        by_scenario[e['scenario_id']].append(e['trial'])\n",
    "    split_subj = {\n",
    "        \"subject_id\":      subject[\"subject_id\"],\n",
    "        \"expertise_level\": subject.get(\"expertise_level\", \"\"),\n",
    "        \"scenarios\":       []\n",
    "    }\n",
    "    for scen_id, trials in by_scenario.items():\n",
    "        split_subj[\"scenarios\"].append({\n",
    "            \"scenario_id\": scen_id,\n",
    "            \"trials\":      trials\n",
    "        })\n",
    "    return split_subj\n",
    "\n",
    "# iterate each subject, flatten their trials across scenarios, shuffle & split\n",
    "for subject in data.get('subjects', []):\n",
    "    # flatten scenarioâ†’trial into entries\n",
    "    entries = []\n",
    "    for scenario in subject.get('scenarios', []):\n",
    "        scen_id = scenario['scenario_id']\n",
    "        for trial in scenario.get('trials', []):\n",
    "            entries.append({\n",
    "                \"scenario_id\": scen_id,\n",
    "                \"trial\":       trial\n",
    "            })\n",
    "\n",
    "    random.shuffle(entries)\n",
    "    n_total = len(entries)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val   = int(val_ratio * n_total)\n",
    "    # rest goes to test\n",
    "    n_test  = n_total - n_train - n_val\n",
    "\n",
    "    train_entries = entries[:n_train]\n",
    "    val_entries   = entries[n_train:n_train + n_val]\n",
    "    test_entries  = entries[n_train + n_val:]\n",
    "\n",
    "    # build & append subject splits if nonempty\n",
    "    if train_entries:\n",
    "        train_set['subjects'].append(build_subject_split(subject, train_entries))\n",
    "    if val_entries:\n",
    "        val_set['subjects'].append(build_subject_split(subject, val_entries))\n",
    "    if test_entries:\n",
    "        test_set['subjects'].append(build_subject_split(subject, test_entries))\n",
    "\n",
    "# helper to save each split\n",
    "def save_split(split_data, name):\n",
    "    path = os.path.join(output_dir, f'aaai26_{name}_split_{task}.json')\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(split_data, f, indent=4)\n",
    "    print(f\"Saved {name} split to {path}\")\n",
    "\n",
    "# write out all three\n",
    "save_split(train_set, 'train')\n",
    "save_split(val_set,   'val')\n",
    "save_split(test_set,  'test')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egoexoems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
