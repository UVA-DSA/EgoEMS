{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Generation Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import fnmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map stream names to stream types\n",
    "def get_stream_type(directory_name):\n",
    "    stream_mapping = {\n",
    "        'RGBD_camera': 'exocam_rgbd',\n",
    "        'depth_sensor': 'vl6180_ToF_depth',\n",
    "        'ego_camera': 'egocam_rgb_audio',\n",
    "        # Add more mappings if necessary\n",
    "    }\n",
    "    return stream_mapping.get(directory_name, directory_name)\n",
    "\n",
    "def parse_video_file(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    video_id, ext = os.path.splitext(file_name)\n",
    "    if ext.lower() not in ['.mp4', '.mov', '.mkv', '.txt','.npy' ]: #\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"file_id\": video_id,\n",
    "        \"file_path\": file_path,\n",
    "        \"protocol\": \"Cardiac Arrest - 2-1\",\n",
    "        \"interventions\": [],\n",
    "        \"keysteps\": []\n",
    "    }\n",
    "\n",
    "def normalize_subject_key(subject_key):\n",
    "    if '_' in subject_key:\n",
    "        return subject_key.split('_')[0]\n",
    "    return subject_key\n",
    "\n",
    "# Assuming `files` is a list of filenames in the current directory\n",
    "def process_files(files):\n",
    "    # Use fnmatch to check for the presence of .txt and .mkv files\n",
    "    has_txt = any(fnmatch.fnmatch(file, '*.txt') for file in files)\n",
    "    has_mkv = any(fnmatch.fnmatch(file, '*.mkv') for file in files)\n",
    "    has_mp4 = any(fnmatch.fnmatch(file, '*.MP4') for file in files)\n",
    "\n",
    "    if (has_txt and has_mkv) or (has_txt and has_mp4):\n",
    "        # Remove all .txt files from the list\n",
    "        files = [file for file in files if not fnmatch.fnmatch(file, '*.txt')]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def process_directory(path):\n",
    "    subjects = []\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path does not exist: {path}\")\n",
    "        return subjects\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        parts = root.split(os.sep)\n",
    "        stream_type = get_stream_type(parts[-3]) if len(parts) > 3 else None\n",
    "        subject_key = None\n",
    "        trial_key = None\n",
    "        \n",
    "        if 'ng' in parts[-2]:  # Handling subject folders\n",
    "            subject_key = parts[-2]\n",
    "            trial_key = parts[-1]\n",
    "        elif 'ng' in parts[-3]:  # Handling trial folders within subject\n",
    "            subject_key = parts[-3]\n",
    "            trial_key = parts[-2]\n",
    "        \n",
    "        if subject_key:\n",
    "            subject_key = normalize_subject_key(subject_key)\n",
    "        \n",
    "        if not subject_key:\n",
    "            continue\n",
    "        \n",
    "        # Find or create the subject entry in the list\n",
    "        subject_entry = next((subject for subject in subjects if subject['subject_id'] == subject_key), None)\n",
    "        if not subject_entry:\n",
    "            subject_entry = OrderedDict({\n",
    "                \"subject_id\": subject_key,\n",
    "                \"trials\": [],\n",
    "                \"expertise_level\": \"EMT\"\n",
    "            })\n",
    "            subjects.append(subject_entry)\n",
    "        \n",
    "        current_level = subject_entry[\"trials\"]\n",
    "        \n",
    "        # Find or create the trial entry in the trials array\n",
    "        trial_entry = next((trial for trial in current_level if trial['trial_id'] == trial_key), None)\n",
    "        if not trial_entry:\n",
    "            trial_entry = OrderedDict({\n",
    "                \"trial_id\": trial_key,\n",
    "                \"streams\": OrderedDict()\n",
    "            })\n",
    "            current_level.append(trial_entry)\n",
    "        \n",
    "        # Access or create the stream level within the trial\n",
    "        if stream_type:\n",
    "            if stream_type not in trial_entry['streams']:\n",
    "                trial_entry['streams'][stream_type] = OrderedDict()\n",
    "            stream_level = trial_entry['streams'][stream_type]\n",
    "        else:\n",
    "            stream_level = trial_entry['streams']\n",
    "        \n",
    "        # Check if both txt and mkv files are present in the files list\n",
    "        files = process_files(files)\n",
    "        \n",
    "        for file in sorted(files):\n",
    "            file_info = parse_video_file(os.path.join(root, file))\n",
    "            if file_info:\n",
    "                trial_entry['streams'][stream_type] = file_info\n",
    "\n",
    "    # Sort the subjects array by subject_id for consistency\n",
    "    subjects = sorted(subjects, key=lambda x: x['subject_id'])\n",
    "    \n",
    "    # Sort the trials array by trial_id for consistency\n",
    "    for subject in subjects:\n",
    "        subject['trials'] = sorted(subject['trials'], key=lambda x: x['trial_id'])\n",
    "\n",
    "    return subjects\n",
    "\n",
    "\n",
    "def generate_json_structure(root_directory, version=\"v1.2024.08.10\"):\n",
    "    json_structure = OrderedDict({\n",
    "        \"subjects\": process_directory(root_directory),\n",
    "        \"version\": version\n",
    "    })\n",
    "    return json_structure\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON structure saved to ../Annotations/main_annotation.json\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure'  # Replace with your directory path\n",
    "output_file = f'{output_dir}/main_annotation.json'\n",
    "\n",
    "json_data = generate_json_structure(root_dir)\n",
    "\n",
    "# sort the json structure\n",
    "json_data = dict(sorted(json_data.items()))\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON structure saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Key Steps using VIA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON structure saved to output_structure.json\n"
     ]
    }
   ],
   "source": [
    "def add_keysteps_to_json(existing_json, keystep_json_path, subject_id=\"ng1\", trial_id=\"1\", stream=\"vl6180_ToF_depth\"):\n",
    "    # Load the keystep annotation JSON file\n",
    "    with open(keystep_json_path, 'r') as f:\n",
    "        keystep_data = json.load(f)\n",
    "    \n",
    "    # Extract the relevant metadata from the keystep JSON\n",
    "    keysteps = []\n",
    "    metadata = keystep_data['metadata']\n",
    "    \n",
    "    for key, value in metadata.items():\n",
    "        start_t, end_t = value['z']\n",
    "        label = value['av']['1']\n",
    "        keysteps.append({\n",
    "            \"keystep_id\": key,\n",
    "            \"start_t\": start_t,\n",
    "            \"end_t\": end_t,\n",
    "            \"label\": label\n",
    "        })\n",
    "    \n",
    "    # Add keysteps to the existing JSON structure\n",
    "    for subject in existing_json['subjects']:\n",
    "        if subject['subject_id'] == subject_id:\n",
    "            for trial in subject['trials']:\n",
    "                if trial['trial_id'] == trial_id:\n",
    "                    if stream in trial['streams']:\n",
    "                        trial['streams'][stream]['keysteps'] = keysteps\n",
    "        \n",
    "    return existing_json\n",
    "\n",
    "\n",
    "# Add keysteps to the existing JSON structure\n",
    "updated_json = add_keysteps_to_json(json_data, './via_video_annotator/via-3.0.13/via_project_28Aug2024_11h02m15s.json', trial_id=\"1\", stream=\"egocam_rgb_audio\")\n",
    "\n",
    "# Print or save the updated JSON structure\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON structure saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial ID: 3\n",
      "  Stream Type: vl6180_ToF_depth\n",
      "    File ID: depth_sensor_2024-05-23-20_14_15\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/3/depth_sensor_2024-05-23-20_14_15.txt\n",
      "  Stream Type: exocam_rgbd\n",
      "    File ID: 2024-05-23-20-14-12\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/3/2024-05-23-20-14-12.mkv\n",
      "Trial ID: 2\n",
      "  Stream Type: vl6180_ToF_depth\n",
      "    File ID: depth_sensor_2024-05-23-20_10_58\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/2/depth_sensor_2024-05-23-20_10_58.txt\n",
      "  Stream Type: exocam_rgbd\n",
      "    File ID: 2024-05-23-20-10-54\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/2/2024-05-23-20-10-54.mkv\n",
      "Trial ID: 4\n",
      "  Stream Type: vl6180_ToF_depth\n",
      "    File ID: depth_sensor_2024-05-23-20_22_15\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/4/depth_sensor_2024-05-23-20_22_15.txt\n",
      "  Stream Type: exocam_rgbd\n",
      "    File ID: 2024-05-23-20-22-11\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/4/2024-05-23-20-22-11.mkv\n",
      "Trial ID: 1\n",
      "  Stream Type: vl6180_ToF_depth\n",
      "    File ID: depth_sensor_2024-05-23-20_05_23\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/1/depth_sensor_2024-05-23-20_05_23.txt\n",
      "  Stream Type: exocam_rgbd\n",
      "    File ID: 2024-05-23-20-04-48\n",
      "    File Path: /standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/1/2024-05-23-20-04-48.mkv\n",
      "Trial ID: 5\n",
      "  Stream Type: vl6180_ToF_depth\n",
      "    No file data found for stream type 'vl6180_ToF_depth in trial '5' of subject 'ng1'\n",
      "  Stream Type: exocam_rgbd\n",
      "    No file data found for stream type 'exocam_rgbd in trial '5' of subject 'ng1'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Load JSON data from file\n",
    "data = json.loads(open('output_structure.json').read())\n",
    "\n",
    "# Iterate through the trials of a specific subject (e.g., 'ng1')\n",
    "subject_id = 'ng1'  # Specify the subject ID you want to iterate through\n",
    "\n",
    "if subject_id in data['subject']:\n",
    "    trials = data['subject'][subject_id]['trials']\n",
    "    \n",
    "    for trial_id, trial_data in trials.items():\n",
    "        print(f\"Trial ID: {trial_id}\")\n",
    "        for stream_type, stream_data in trial_data.items():\n",
    "            try:\n",
    "                print(f\"  Stream Type: {stream_type}\")\n",
    "                print(f\"    File ID: {stream_data['file_id']}\")\n",
    "                print(f\"    File Path: {stream_data['file_path']}\")\n",
    "            except KeyError:\n",
    "                print(f\"    No file data found for stream type '{stream_type} in trial '{trial_id}' of subject '{subject_id}'\")\n",
    "else:\n",
    "    print(f\"Subject ID '{subject_id}' not found in the JSON data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keysteps have been extracted to ./video_annotations.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_keysteps_to_csv(json_file_path, output_csv_path, stream_name):\n",
    "    \"\"\"\n",
    "    Extract keysteps from the specified stream in the JSON annotation file and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON annotation file.\n",
    "        output_csv_path (str): Path to save the output CSV file.\n",
    "        stream_name (str): The stream from which to extract keystep annotations.\n",
    "    \"\"\"\n",
    "    # Load the JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write the header\n",
    "        writer.writerow(['VIDEO_PATH', 'START_TIME', 'END_TIME', 'LABEL'])\n",
    "\n",
    "        # Iterate through the subjects and trials in the JSON\n",
    "        for subject in data['subjects']:\n",
    "            for trial in subject['trials']:\n",
    "                if stream_name in trial['streams']:\n",
    "                    video_path = trial['streams'][stream_name]['file_path']\n",
    "                    keysteps = trial['streams'][stream_name].get('keysteps', [])\n",
    "                    # Write each keystep to the CSV file\n",
    "                    for keystep in keysteps:\n",
    "                        writer.writerow([\n",
    "                            video_path,\n",
    "                            keystep['start_t'],\n",
    "                            keystep['end_t'],\n",
    "                            keystep['label']\n",
    "                        ])\n",
    "\n",
    "    print(f\"Keysteps have been extracted to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "json_file_path = './output_structure.json'  # Path to your JSON file\n",
    "output_csv_path = './video_annotations.json'  # Path to save the CSV file\n",
    "stream_name = 'egocam_rgb_audio'  # Replace with your specific stream name\n",
    "\n",
    "extract_keysteps_to_csv(json_file_path, output_csv_path, stream_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keysteps with frame numbers have been extracted to ./video_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "def extract_keysteps_to_csv_with_frames(json_file_path, output_csv_path, stream_name):\n",
    "    \"\"\"\n",
    "    Extract keysteps from the specified stream in the JSON annotation file,\n",
    "    convert start/end times to frame numbers, and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON annotation file.\n",
    "        output_csv_path (str): Path to save the output CSV file.\n",
    "        stream_name (str): The stream from which to extract keystep annotations.\n",
    "    \"\"\"\n",
    "    # Load the JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write the header\n",
    "        writer.writerow(['VIDEO_PATH', 'START_FRAME', 'END_FRAME', 'LABEL'])\n",
    "\n",
    "        # Iterate through the subjects and trials in the JSON\n",
    "        for subject in data['subjects']:\n",
    "            for trial in subject['trials']:\n",
    "                if stream_name in trial['streams']:\n",
    "                    video_path = trial['streams'][stream_name]['file_path']\n",
    "\n",
    "                    # Retrieve the video frame rate using OpenCV\n",
    "                    video_capture = cv2.VideoCapture(video_path)\n",
    "                    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_capture.release()\n",
    "\n",
    "                    keysteps = trial['streams'][stream_name].get('keysteps', [])\n",
    "                    # Write each keystep to the CSV file with converted frame numbers\n",
    "                    for keystep in keysteps:\n",
    "                        start_frame = int(keystep['start_t'] * fps)\n",
    "                        end_frame = int(keystep['end_t'] * fps)\n",
    "                        writer.writerow([\n",
    "                            video_path,\n",
    "                            start_frame,\n",
    "                            end_frame,\n",
    "                            keystep['label']\n",
    "                        ])\n",
    "\n",
    "    print(f\"Keysteps with frame numbers have been extracted to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "# Example usage\n",
    "json_file_path = './output_structure.json'  # Path to your JSON file\n",
    "output_csv_path = './video_annotations.csv'  # Path to save the CSV file\n",
    "stream_name = 'egocam_rgb_audio'  # Replace with your specific stream name\n",
    "\n",
    "extract_keysteps_to_csv_with_frames(json_file_path, output_csv_path, stream_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
