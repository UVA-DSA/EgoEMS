{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import cv2\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip, CompositeVideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import random\n",
    "\n",
    "\n",
    "def timeline_creator(video_file, keysteps, subject_id, trial_id):\n",
    "        \n",
    "    # Extract temporal segments from 'keysteps'\n",
    "    segments = []\n",
    "    for keystep in keysteps:\n",
    "        start, end = keystep['start_t'], keystep['end_t']\n",
    "        label = keystep['label']\n",
    "        segments.append((start, end, label))\n",
    "\n",
    "\n",
    "    video_file_name = video_file.split('/')[-1]\n",
    "\n",
    "    print(\"Video file:\", video_file)\n",
    "    print(\"Segments:\", segments)\n",
    "\n",
    "    # Generate a custom color palette for unique labels\n",
    "    unique_labels = sorted(set([label for _, _, label in segments]))\n",
    "    palette = sns.color_palette(\"muted\", len(unique_labels))\n",
    "\n",
    "    # Shuffle the palette to randomize the color assignment\n",
    "    random.shuffle(palette)\n",
    "\n",
    "    color_map = {label: palette[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "\n",
    "    plot_output_dir = f\"./output/plot/{subject_id}/{trial_id}\"\n",
    "    os.makedirs(plot_output_dir, exist_ok=True)\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    else:\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        if fps == 0:\n",
    "            print(\"Error: FPS value is zero, which might indicate an issue with the video file.\")\n",
    "        else:\n",
    "            # Plot timeline\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            ax.set_xlim(0, max([end for _, end, _ in segments]))\n",
    "            ax.set_ylim(0, 1)\n",
    "\n",
    "            # Remove y-axis ticks, labels, and spines\n",
    "            ax.yaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "\n",
    "            # Set x-axis label\n",
    "            ax.set_xlabel(\"Time (seconds)\")\n",
    "\n",
    "            # Track labels added to the legend\n",
    "            labels_added = set()\n",
    "\n",
    "            # Draw bars for each segment\n",
    "            for start, end, label in segments:\n",
    "                color = color_map[label]\n",
    "                if label not in labels_added:\n",
    "                    ax.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color, label=label)\n",
    "                    labels_added.add(label)\n",
    "                else:\n",
    "                    ax.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color)\n",
    "\n",
    "            # Add legend below the x-axis\n",
    "            ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.30), ncol=4, frameon=False)\n",
    "\n",
    "            # Sync video playback\n",
    "            def update(frame):\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "                ret, frame_img = cap.read()\n",
    "                if ret:\n",
    "                    plt.imshow(cv2.cvtColor(frame_img, cv2.COLOR_BGR2RGB))\n",
    "                return frame_img\n",
    "\n",
    "            ani = FuncAnimation(fig, update, frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), interval=1000/fps)\n",
    "\n",
    "            \n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the timeline plot\n",
    "            \n",
    "            file_name = f\"{video_file_name.split('.')[0]}_video_timeline\"\n",
    "            fig.savefig(f'{plot_output_dir}/{file_name}_timeline.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # Transparent version\n",
    "\n",
    "            #         # Now create the transparent version with only the color bars\n",
    "            # fig_transparent, ax_transparent = plt.subplots(figsize=(10, 4))\n",
    "            # ax_transparent.set_xlim(0, max([end for _, end, _ in segments]))\n",
    "            # ax_transparent.set_ylim(0, 1)\n",
    "\n",
    "            # # Remove all axis elements for transparent version\n",
    "            # ax_transparent.axis('off')\n",
    "\n",
    "            # # Draw bars for each segment\n",
    "            # for start, end, label in segments:\n",
    "            #     color = color_map[label]\n",
    "            #     ax_transparent.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color)\n",
    "\n",
    "            \n",
    "            # # Save the transparent version as PNG\n",
    "            # fig_transparent.savefig(f'{plot_output_dir}/{file_name}_bars_only.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "            # plt.show()\n",
    "\n",
    "            \n",
    "            # Now create another figure with x-axis and no legend\n",
    "            fig_no_legend, ax_no_legend = plt.subplots(figsize=(16, 2))\n",
    "            ax_no_legend.set_xlim(0, max([end for _, end, _ in segments]))\n",
    "            ax_no_legend.set_ylim(0, 1)\n",
    "\n",
    "            \n",
    "            # Remove y-axis ticks, labels, and spines\n",
    "            ax_no_legend.yaxis.set_ticks([])\n",
    "            ax_no_legend.yaxis.set_ticklabels([])\n",
    "            ax_no_legend.spines['left'].set_visible(False)\n",
    "            ax_no_legend.spines['right'].set_visible(False)\n",
    "            ax_no_legend.spines['top'].set_visible(False)\n",
    "\n",
    "            # Set x-axis label\n",
    "            ax_no_legend.set_xlabel(\"Time (seconds)\")\n",
    "\n",
    "            # Draw bars for each segment (same as before, but without the legend)\n",
    "            for start, end, label in segments:\n",
    "                color = color_map[label]\n",
    "                ax_no_legend.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color)\n",
    "\n",
    "            # Save the no-legend plot\n",
    "            file_name_no_legend = f\"{video_file_name.split('.')[0]}video_timeline_no_legend\"\n",
    "            fig_no_legend.savefig(f'{plot_output_dir}/{file_name_no_legend}_timeline.png', bbox_inches='tight', transparent=True)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m gopro_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# check if file['file_path'] ends with '.json'\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     23\u001b[0m         annotation_file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_trimmed.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Main annotation file\n",
    "annotation_file = '../../Annotations/main_annotation_classification.json'\n",
    "\n",
    "# load the annotation file\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "    # iterate over each subject\n",
    "    for subject in annotations['subjects']:\n",
    "        print(\"*\" * 50)\n",
    "        subject_id = subject['subject_id']\n",
    "        for trial in subject['trials']:\n",
    "            trial_id = trial['trial_id']\n",
    "            for stream_type, files in trial['streams'].items():\n",
    "                if(stream_type == 'egocam_rgb_audio'):\n",
    "\n",
    "                    gopro_file_name = None\n",
    "                    gopro_file_path = None\n",
    "\n",
    "                    for file in files:\n",
    "                        # check if file['file_path'] ends with '.json'\n",
    "                        if file['file_path'].endswith('.json'):\n",
    "                            annotation_file = file['file_path']\n",
    "\n",
    "                        if file['file_path'].endswith('encoded_trimmed.mp4'):\n",
    "                            gopro_file_name = file['file_id']+ '.mp4'\n",
    "                            gopro_file_path = file['file_path']\n",
    "\n",
    "            if annotation_file and gopro_file_name:\n",
    "                print(f\"Subject: {subject['subject_id']}, Trial: {trial['trial_id']}\")\n",
    "                print(f\"GoPro file name: {gopro_file_name}, GoPro file path: {gopro_file_path}\")\n",
    "                \n",
    "                keysteps = trial['keysteps']\n",
    "                \n",
    "                # check if keysteps is not empty\n",
    "                if not keysteps:\n",
    "                    print(\"No keysteps found\")\n",
    "                else:\n",
    "                    print(f\"Keysteps: {keysteps}\")\n",
    "                    # timeline_creator(gopro_file_path, keysteps, subject_id, trial_id)\n",
    "\n",
    "                # print(f\"Keysteps: {keysteps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = 'output'\n",
    "# plot_output_dir = f'{output_dir}/plot'\n",
    "# video_output_dir = f'{output_dir}/visualized_video'\n",
    "\n",
    "# data_dir = '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/DO_NOT_DELETE/ego_camera/clipped_with_audio/GX010305_clipped_with_audio.mp4'\n",
    "# # annotations_file = '../../../Annotations/keysteps/GX010306_clipped_with_audio_KEYSTEP_ANNOTATION.json'\n",
    "# annotations_file = '../../Annotations/keysteps/LATEST_KEYSTEPS.json'\n",
    "# # annotations_file = '../../Annotations/main_annotation.json'\n",
    "\n",
    "# # strip the file extension and add _with_timeline.mp4\n",
    "# video_file = data_dir\n",
    "# file_name = video_file.split('/')[-1]\n",
    "# output_file = file_name.split('.')[0] + \"_with_timeline_interventions.mp4\"\n",
    "# timeline_output_file = file_name.split('.')[0] + \"_timeline_only.mp4\"\n",
    "# final_output_path = f'{video_output_dir}/{output_file}'\n",
    "# print(f'output file: {final_output_path}')\n",
    "\n",
    "# # make dirs if not exists\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "# if not os.path.exists(plot_output_dir):\n",
    "#     os.makedirs(plot_output_dir)\n",
    "# if not os.path.exists(video_output_dir):\n",
    "#     os.makedirs(video_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize above on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the video with MoviePy\n",
    "video_clip = VideoFileClip(video_file)\n",
    "fps = video_clip.fps\n",
    "duration = video_clip.duration\n",
    "\n",
    "# Prepare to create timeline frames\n",
    "frames = []\n",
    "\n",
    "for t in np.linspace(0, duration, int(fps * duration)):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.set_xlim(0, max([end for _, end, _ in segments]))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Remove y-axis ticks, labels, and spines\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # set x axis label\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    # Track which labels have been added to the legend\n",
    "    labels_added = set()\n",
    "\n",
    "    for start, end, label in segments:\n",
    "        color = color_map[label]\n",
    "        if label not in labels_added:\n",
    "            ax.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color, label=label)\n",
    "            labels_added.add(label)\n",
    "        else:\n",
    "            ax.broken_barh([(start, end - start)], (0.25, 0.5), facecolors=color)\n",
    "\n",
    "    # Add legend below the x-axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.30), ncol=4, frameon=False)\n",
    "    # Add a moving cursor\n",
    "    ax.axvline(t, color='red', linewidth=2)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    img_plot = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    frames.append(img_plot)\n",
    "    plt.close(fig)\n",
    "    # break\n",
    "\n",
    "\n",
    "# Create a clip from the frames\n",
    "timeline_clip = ImageSequenceClip(frames, fps=fps)\n",
    "timeline_clip = timeline_clip.set_duration(duration).resize(width=video_clip.w)\n",
    "\n",
    "timeline_output_path = f'{video_output_dir}/{timeline_output_file}'\n",
    "timeline_clip.write_videofile(timeline_output_path, fps=fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ffmpeg to combine videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute shell commmand\n",
    "original_file = data_dir\n",
    "timeline_output_path = f'{video_output_dir}/{timeline_output_file}'\n",
    "\n",
    "\n",
    "# replace spaces with \\ in the file path\n",
    "original_file = original_file.replace(' ', '\\ ')\n",
    "# update command to forcefully overwrite the output file\n",
    "command = f'module load ffmpeg && ffmpeg -i {original_file} -i {timeline_output_path} -filter_complex \"[1:v]fps=fps=30[v1];[0:v][v1]vstack=inputs=2\" -c:v libx264 -c:a copy -r 30 -y {final_output_path}'\n",
    "\n",
    "# import subprocess to execute the command\n",
    "! {command}\n",
    "# import subprocess as sp\n",
    "\n",
    "# # execute the command\n",
    "# sp.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[0].shape\n",
    "# convert to pil image\n",
    "from PIL import Image\n",
    "img = Image.fromarray(frames[0])\n",
    "\n",
    "# save image\n",
    "img.save('test.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to visualize label on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load VIA annotation file\n",
    "annotation_file = './via_project_28Aug2024_11h02m15s.json'\n",
    "\n",
    "with open(annotation_file, 'r') as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "# Extract relevant information from the JSON\n",
    "video_info = annotations['file']['1']\n",
    "video_filename = video_info['fname']\n",
    "metadata = annotations['metadata']\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_filename)\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "output_filename = 'annotated_video_output.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
    "out = cv2.VideoWriter(output_filename, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "# Function to add annotation text on frames\n",
    "def add_annotation(frame, text):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (50, 50)\n",
    "    font_scale = 1\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    frame = cv2.putText(frame, text, org, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "# Process each annotation and save to video\n",
    "for key, value in metadata.items():\n",
    "    # Extract start time, end time, and label\n",
    "    start_time = value['z'][0]\n",
    "    end_time = value['z'][1]\n",
    "    label = value['av']['1']\n",
    "    \n",
    "    # Convert times to frame numbers\n",
    "    start_frame = int(start_time * frame_rate)\n",
    "    end_frame = int(end_time * frame_rate)\n",
    "    \n",
    "    # Set the video to the start frame of the segment\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    \n",
    "    # Write frames with annotation to output video\n",
    "    for frame_num in range(start_frame, end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Add annotation text to frame\n",
    "            annotated_frame = add_annotation(frame, f\"Label: {label}\")\n",
    "            # Write the frame to the output video\n",
    "            out.write(annotated_frame)\n",
    "        else:\n",
    "            print(f\"Failed to read frame at {frame_num}.\")\n",
    "            break\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Annotated video saved to {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
