{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Generation Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import fnmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map stream names to stream types\n",
    "def get_stream_type(directory_name):\n",
    "    stream_mapping = {\n",
    "        'RGBD_camera': 'exocam_rgbd',\n",
    "        'depth_sensor': 'vl6180_ToF_depth',\n",
    "        'ego_camera': 'egocam_rgb_audio',\n",
    "        # Add more mappings if necessary\n",
    "    }\n",
    "    return stream_mapping.get(directory_name, directory_name)\n",
    "\n",
    "def parse_file(file_path, stream_type):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_id, ext = os.path.splitext(file_name)\n",
    "    \n",
    "    # handle different stream_type\n",
    "    if stream_type == 'exocam_rgbd' or stream_type == 'egocam_rgb_audio':\n",
    "        if ext.lower() not in ['.mp4', '.mov', '.mkv' ]: #\n",
    "            return None\n",
    "    \n",
    "    elif stream_type == 'vl6180_ToF_depth':\n",
    "        if ext.lower() not in ['.txt']:\n",
    "            return None\n",
    "            \n",
    "    elif stream_type == 'smartwatch_imu':\n",
    "        if ext.lower() not in ['.csv']:\n",
    "            return None\n",
    "        \n",
    "    elif stream_type == 'i3d_flow':\n",
    "        if ext.lower() not in ['.npy']:\n",
    "            return None\n",
    "        if 'flow' not in file_id:\n",
    "            return None\n",
    "        \n",
    "    elif stream_type == 'i3d_rgb':\n",
    "        if ext.lower() not in ['.npy']:\n",
    "            return None\n",
    "        if 'rgb' not in file_id:\n",
    "            return None\n",
    "    \n",
    "    return {\n",
    "        \"file_id\": file_id,\n",
    "        \"file_path\": file_path,\n",
    "        \"protocol\": \"Cardiac Arrest - 2-1\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "def parse_video_file(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    video_id, ext = os.path.splitext(file_name)\n",
    "    if ext.lower() not in ['.mp4', '.mov', '.mkv', '.txt','.npy' ]: #\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"file_id\": video_id,\n",
    "        \"file_path\": file_path,\n",
    "        \"protocol\": \"Cardiac Arrest - 2-1\",\n",
    "    }\n",
    "\n",
    "def normalize_subject_key(subject_key):\n",
    "    if '_' in subject_key:\n",
    "        return subject_key.split('_')[0]\n",
    "    return subject_key\n",
    "\n",
    "# Assuming `files` is a list of filenames in the current directory\n",
    "def process_files(files):\n",
    "    # Use fnmatch to check for the presence of .txt and .mkv files\n",
    "    has_txt = any(fnmatch.fnmatch(file, '*.txt') for file in files)\n",
    "    has_mkv = any(fnmatch.fnmatch(file, '*.mkv') for file in files)\n",
    "    has_mp4 = any(fnmatch.fnmatch(file, '*.MP4') for file in files)\n",
    "\n",
    "    if (has_txt and has_mkv) or (has_txt and has_mp4):\n",
    "        # Remove all .txt files from the list\n",
    "        files = [file for file in files if not fnmatch.fnmatch(file, '*.txt')]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def process_directory(path):\n",
    "    subjects = []\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path does not exist: {path}\")\n",
    "        return subjects\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        parts = root.split(os.sep)\n",
    "        stream_type = get_stream_type(parts[-3]) if len(parts) > 3 else None\n",
    "        subject_key = None\n",
    "        trial_key = None\n",
    "        \n",
    "        if 'ng' in parts[-2]:  # Handling subject folders\n",
    "            subject_key = parts[-2]\n",
    "            trial_key = parts[-1]\n",
    "        elif 'ng' in parts[-3]:  # Handling trial folders within subject\n",
    "            subject_key = parts[-3]\n",
    "            trial_key = parts[-2]\n",
    "        \n",
    "        if subject_key:\n",
    "            subject_key = normalize_subject_key(subject_key)\n",
    "        \n",
    "        if not subject_key:\n",
    "            continue\n",
    "        \n",
    "        # Find or create the subject entry in the list\n",
    "        subject_entry = next((subject for subject in subjects if subject['subject_id'] == subject_key), None)\n",
    "        if not subject_entry:\n",
    "            subject_entry = OrderedDict({\n",
    "                \"subject_id\": subject_key,\n",
    "                \"trials\": [],\n",
    "                \"expertise_level\": \"EMT\"\n",
    "            })\n",
    "            subjects.append(subject_entry)\n",
    "        \n",
    "        current_level = subject_entry[\"trials\"]\n",
    "        \n",
    "        # Find or create the trial entry in the trials array\n",
    "        trial_entry = next((trial for trial in current_level if trial['trial_id'] == trial_key), None)\n",
    "        if not trial_entry:\n",
    "            trial_entry = OrderedDict({\n",
    "                \"trial_id\": trial_key,\n",
    "                \"streams\": OrderedDict(),\n",
    "                \"keysteps\": OrderedDict(),\n",
    "                \"interventions\": OrderedDict()\n",
    "\n",
    "            })\n",
    "            current_level.append(trial_entry)\n",
    "        \n",
    "        # Access or create the stream level within the trial\n",
    "        if stream_type:\n",
    "            if stream_type not in trial_entry['streams']:\n",
    "                trial_entry['streams'][stream_type] = OrderedDict()\n",
    "            stream_level = trial_entry['streams'][stream_type]\n",
    "        else:\n",
    "            stream_level = trial_entry['streams']\n",
    "        \n",
    "        # Check if both txt and mkv files are present in the files list\n",
    "        files = process_files(files)\n",
    "        \n",
    "        for file in sorted(files):\n",
    "            # file_info = parse_video_file(os.path.join(root, file))\n",
    "            file_info = parse_file(os.path.join(root, file), stream_type)\n",
    "            if file_info:\n",
    "                trial_entry['streams'][stream_type] = file_info\n",
    "\n",
    "    # Sort the subjects array by subject_id for consistency\n",
    "    subjects = sorted(subjects, key=lambda x: x['subject_id'])\n",
    "    \n",
    "    # Sort the trials array by trial_id for consistency\n",
    "    for subject in subjects:\n",
    "        subject['trials'] = sorted(subject['trials'], key=lambda x: x['trial_id'])\n",
    "\n",
    "    return subjects\n",
    "\n",
    "\n",
    "def generate_json_structure(root_directory, version=\"v1.2024.08.10\"):\n",
    "    json_structure = OrderedDict({\n",
    "        \"subjects\": process_directory(root_directory),\n",
    "        \"version\": version\n",
    "    })\n",
    "    return json_structure\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/weka/scratch/cjh9fw/Rivanna/2024/repos/EgoExoEMS/Tools/annotation_generation\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON structure saved to ../../Annotations/main_annotation.json\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure'  # Replace with your directory path\n",
    "output_file = f'{output_dir}/main_annotation.json'\n",
    "\n",
    "json_data = generate_json_structure(root_dir)\n",
    "\n",
    "# sort the json structure\n",
    "json_data = dict(sorted(json_data.items()))\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON structure saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Key Steps using VIA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON structure saved to ../../Annotations/main_annotation.json\n"
     ]
    }
   ],
   "source": [
    "def add_keysteps_to_json(existing_json, keystep_json_path, subject_id=\"ng1\", trial_id=\"1\", stream=\"vl6180_ToF_depth\"):\n",
    "    # Load the keystep annotation JSON file\n",
    "    with open(keystep_json_path, 'r') as f:\n",
    "        keystep_data = json.load(f)\n",
    "        \n",
    "    # Load class id mapping json\n",
    "    with open('./class_id_mappings.json', 'r') as f:\n",
    "        class_id_mapping = json.load(f)\n",
    "    \n",
    "    # Extract the relevant metadata from the keystep JSON\n",
    "    keysteps = []\n",
    "    metadata = keystep_data['metadata']\n",
    "    \n",
    "    for key, value in metadata.items():\n",
    "        vid_id = value['vid']\n",
    "\n",
    "        if vid_id != trial_id:\n",
    "            continue\n",
    "        start_t, end_t = value['z']\n",
    "        label = value['av']['1']\n",
    "        keysteps.append({\n",
    "            \"keystep_id\": key,\n",
    "            \"start_t\": start_t,\n",
    "            \"end_t\": end_t,\n",
    "            \"label\": label,\n",
    "            \"class_id\": class_id_mapping[label]\n",
    "        })\n",
    "    \n",
    "    # Add keysteps to the existing JSON structure\n",
    "    for subject in existing_json['subjects']:\n",
    "        if subject['subject_id'] == subject_id:\n",
    "            for trial in subject['trials']:\n",
    "                if trial['trial_id'] == trial_id:\n",
    "                    trial['keysteps'] = keysteps\n",
    "                    # if stream in trial['streams']:\n",
    "                        # trial['streams'][stream]['keysteps'] = keysteps\n",
    "        \n",
    "    return existing_json\n",
    "\n",
    "\n",
    "# Add keysteps to the existing JSON structure\n",
    "updated_json = add_keysteps_to_json(json_data, f'{output_dir}/keysteps/GX010305_clipped_with_audio_KEYSTEP_ANNOTATION.json', trial_id=\"1\", stream=\"egocam_rgb_audio\")\n",
    "\n",
    "# Print or save the updated JSON structure\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON structure saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'trial_id': '1', 'streams': {'vl6180_ToF_depth': {'file_id': 'depth_sensor_2024-05-23-20_05_23', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/1/depth_sensor_2024-05-23-20_05_23.txt', 'fps': 60, 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'egocam_rgb_audio': {'file_id': 'GX010305', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/ego_camera/ng1/1/GX010305.MP4', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': [{'keystep_id': '1_gpOXHjPd', 'start_t': 0.008, 'end_t': 2.88275, 'label': 'approach_patient', 'class_id': 1}, {'keystep_id': '1_4W1h7RPK', 'start_t': 2.79942, 'end_t': 5.13275, 'label': 'check_responsiveness', 'class_id': 2}, {'keystep_id': '1_BrKnaWXP', 'start_t': 5.133, 'end_t': 7.52858, 'label': 'check_pulse_breathing', 'class_id': 3}, {'keystep_id': '1_9p0HnWaO', 'start_t': 7.52858, 'end_t': 53.40358, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_3OiNeIks', 'start_t': 53.404, 'end_t': 54.90358, 'label': 'no_action', 'class_id': 5}, {'keystep_id': '1_h0Yo4fiA', 'start_t': 54.96608, 'end_t': 57.90358, 'label': 'take_defib_pads', 'class_id': 6}, {'keystep_id': '1_2s86Yd2m', 'start_t': 58.02858, 'end_t': 60.46608, 'label': 'attach_defib_pads', 'class_id': 7}, {'keystep_id': '1_BFRQXfD5', 'start_t': 60.46608, 'end_t': 61.19525, 'label': 'take_defib_pads', 'class_id': 6}, {'keystep_id': '1_lXGfY9LE', 'start_t': 61.21608, 'end_t': 63.34, 'label': 'attach_defib_pads', 'class_id': 7}, {'keystep_id': '1_NOzgpig0', 'start_t': 63.36192, 'end_t': 79.17442, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_irbrX69Q', 'start_t': 79.40358, 'end_t': 88.19525, 'label': 'administer_shock_aed', 'class_id': 8}, {'keystep_id': '1_beZ1Njdq', 'start_t': 88.23692, 'end_t': 106.29942, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_D3qXugyU', 'start_t': 106.299, 'end_t': 107.44525, 'label': 'place_bvm', 'class_id': 9}, {'keystep_id': '1_gbMXdr1R', 'start_t': 107.445, 'end_t': 112.23692, 'label': 'compress_bvm', 'class_id': 10}, {'keystep_id': '1_eXdfBRR6', 'start_t': 112.121, 'end_t': 125.76034, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_PsSZXfoi', 'start_t': 126.28811, 'end_t': 127.70478, 'label': 'place_bvm', 'class_id': 9}, {'keystep_id': '1_9oLXZzZ9', 'start_t': 127.773, 'end_t': 131.37145, 'label': 'compress_bvm', 'class_id': 10}, {'keystep_id': '1_b5w6teD5', 'start_t': 127.773, 'end_t': 128.773, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_lCtyTuRy', 'start_t': 131.258, 'end_t': 145.34937, 'label': 'begin_chest_compression', 'class_id': 4}, {'keystep_id': '1_PHHevV23', 'start_t': 145.349, 'end_t': 154.53118, 'label': 'administer_shock_aed', 'class_id': 8}]}, 'exocam_rgbd': {'file_id': '2024-05-23-20-04-48', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/1/2024-05-23-20-04-48.mkv', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}}}, {'trial_id': '2', 'streams': {'vl6180_ToF_depth': {'file_id': 'depth_sensor_2024-05-23-20_10_58', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/2/depth_sensor_2024-05-23-20_10_58.txt', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'egocam_rgb_audio': {'file_id': 'GX010306', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/ego_camera/ng1/2/GX010306.MP4', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'exocam_rgbd': {'file_id': '2024-05-23-20-10-54', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/2/2024-05-23-20-10-54.mkv', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}}}, {'trial_id': '3', 'streams': {'vl6180_ToF_depth': {'file_id': 'depth_sensor_2024-05-23-20_14_15', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/3/depth_sensor_2024-05-23-20_14_15.txt', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'egocam_rgb_audio': {'file_id': 'GX010307', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/ego_camera/ng1/3/GX010307.MP4', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'exocam_rgbd': {'file_id': '2024-05-23-20-14-12', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/3/2024-05-23-20-14-12.mkv', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}}}, {'trial_id': '4', 'streams': {'vl6180_ToF_depth': {'file_id': 'depth_sensor_2024-05-23-20_17_53', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/4/depth_sensor_2024-05-23-20_17_53.txt', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'egocam_rgb_audio': {'file_id': 'GX010308', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/ego_camera/ng1/4/GX010308.MP4', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'exocam_rgbd': {'file_id': '2024-05-23-20-17-59', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/4/2024-05-23-20-17-59.mkv', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}}}, {'trial_id': '5', 'streams': {'vl6180_ToF_depth': {'file_id': 'depth_sensor_2024-05-23-20_22_15', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/depth_sensor/ng1/5/depth_sensor_2024-05-23-20_22_15.txt', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'egocam_rgb_audio': {'file_id': 'GX010309', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/ego_camera/ng1/5/GX010309.MP4', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}, 'exocam_rgbd': {'file_id': '2024-05-23-20-22-11', 'file_path': '/standard/UVA-DSA/NIST EMS Project Data/CognitiveEMS_Datasets/North_Garden/May_2024/May24_updated_structure/RGBD_camera/ng1/5/2024-05-23-20-22-11.mkv', 'protocol': 'Cardiac Arrest - 2-1', 'interventions': [], 'keysteps': []}}}]\n",
      "Trial ID: 1\n",
      "Trial ID: 2\n",
      "Trial ID: 3\n",
      "Trial ID: 4\n",
      "Trial ID: 5\n",
      "Skipping ng3\n",
      "Skipping ng5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Load JSON data from file\n",
    "data = json.loads(open('output_structure.json').read())\n",
    "\n",
    "# Iterate through the trials of a specific subject (e.g., 'ng1')\n",
    "subject_id = 'ng1'  # Specify the subject ID you want to iterate through\n",
    "\n",
    "\n",
    "for subject in data['subjects']:\n",
    "    if subject_id == subject['subject_id']:\n",
    "        trials = subject['trials']\n",
    "        print(trials)\n",
    "        \n",
    "        for trial in trials:\n",
    "            print(f\"Trial ID: {trial['trial_id']}\")\n",
    "            # for stream_type, stream_data in trial_data.items():\n",
    "            #     try:\n",
    "            #         print(f\"  Stream Type: {stream_type}\")\n",
    "            #         print(f\"    File ID: {stream_data['file_id']}\")\n",
    "            #         print(f\"    File Path: {stream_data['file_path']}\")\n",
    "            #     except KeyError:\n",
    "            #         print(f\"    No file data found for stream type '{stream_type} in trial '{trial_id}' of subject '{subject_id}'\")\n",
    "    else:\n",
    "        print(f\"Skipping {subject['subject_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keysteps have been extracted to ./video_annotations.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_keysteps_to_csv(json_file_path, output_csv_path, stream_name):\n",
    "    \"\"\"\n",
    "    Extract keysteps from the specified stream in the JSON annotation file and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON annotation file.\n",
    "        output_csv_path (str): Path to save the output CSV file.\n",
    "        stream_name (str): The stream from which to extract keystep annotations.\n",
    "    \"\"\"\n",
    "    # Load the JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write the header\n",
    "        writer.writerow(['VIDEO_PATH', 'START_TIME', 'END_TIME', 'LABEL'])\n",
    "\n",
    "        # Iterate through the subjects and trials in the JSON\n",
    "        for subject in data['subjects']:\n",
    "            for trial in subject['trials']:\n",
    "                if stream_name in trial['streams']:\n",
    "                    video_path = trial['streams'][stream_name]['file_path']\n",
    "                    keysteps = trial['streams'][stream_name].get('keysteps', [])\n",
    "                    # Write each keystep to the CSV file\n",
    "                    for keystep in keysteps:\n",
    "                        writer.writerow([\n",
    "                            video_path,\n",
    "                            keystep['start_t'],\n",
    "                            keystep['end_t'],\n",
    "                            keystep['label']\n",
    "                        ])\n",
    "\n",
    "    print(f\"Keysteps have been extracted to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "json_file_path = './output_structure.json'  # Path to your JSON file\n",
    "output_csv_path = './video_annotations.json'  # Path to save the CSV file\n",
    "stream_name = 'egocam_rgb_audio'  # Replace with your specific stream name\n",
    "\n",
    "extract_keysteps_to_csv(json_file_path, output_csv_path, stream_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keysteps with frame numbers have been extracted to ./video_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "def extract_keysteps_to_csv_with_frames(json_file_path, output_csv_path, stream_name):\n",
    "    \"\"\"\n",
    "    Extract keysteps from the specified stream in the JSON annotation file,\n",
    "    convert start/end times to frame numbers, and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON annotation file.\n",
    "        output_csv_path (str): Path to save the output CSV file.\n",
    "        stream_name (str): The stream from which to extract keystep annotations.\n",
    "    \"\"\"\n",
    "    # Load the JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write the header\n",
    "        writer.writerow(['VIDEO_PATH', 'START_FRAME', 'END_FRAME', 'LABEL'])\n",
    "\n",
    "        # Iterate through the subjects and trials in the JSON\n",
    "        for subject in data['subjects']:\n",
    "            for trial in subject['trials']:\n",
    "                if stream_name in trial['streams']:\n",
    "                    video_path = trial['streams'][stream_name]['file_path']\n",
    "\n",
    "                    # Retrieve the video frame rate using OpenCV\n",
    "                    video_capture = cv2.VideoCapture(video_path)\n",
    "                    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_capture.release()\n",
    "\n",
    "                    keysteps = trial['streams'][stream_name].get('keysteps', [])\n",
    "                    # Write each keystep to the CSV file with converted frame numbers\n",
    "                    for keystep in keysteps:\n",
    "                        start_frame = int(keystep['start_t'] * fps)\n",
    "                        end_frame = int(keystep['end_t'] * fps)\n",
    "                        writer.writerow([\n",
    "                            video_path,\n",
    "                            start_frame,\n",
    "                            end_frame,\n",
    "                            keystep['label']\n",
    "                        ])\n",
    "\n",
    "    print(f\"Keysteps with frame numbers have been extracted to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "# Example usage\n",
    "json_file_path = './output_structure.json'  # Path to your JSON file\n",
    "output_csv_path = './video_annotations.csv'  # Path to save the CSV file\n",
    "stream_name = 'egocam_rgb_audio'  # Replace with your specific stream name\n",
    "\n",
    "extract_keysteps_to_csv_with_frames(json_file_path, output_csv_path, stream_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
